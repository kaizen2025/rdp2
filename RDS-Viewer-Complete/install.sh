#!/bin/bash

# =============================================================================
# Script d'installation automatique DocuCortex IA - Ollama Integration
# =============================================================================

set -e  # Arr√™t en cas d'erreur

# Couleurs pour l'affichage
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
MAGENTA='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m' # No Color

# Fonctions d'affichage
print_header() {
    echo -e "\n${MAGENTA}========================================${NC}"
    echo -e "${BLUE}$1${NC}"
    echo -e "${MAGENTA}========================================${NC}\n"
}

print_success() {
    echo -e "${GREEN}‚úÖ $1${NC}"
}

print_warning() {
    echo -e "${YELLOW}‚ö†Ô∏è  $1${NC}"
}

print_error() {
    echo -e "${RED}‚ùå $1${NC}"
}

print_info() {
    echo -e "${CYAN}‚ÑπÔ∏è  $1${NC}"
}

print_step() {
    echo -e "\n${BLUE}üîÑ $1${NC}"
}

# V√©rification des pr√©requis
check_prerequisites() {
    print_step "V√©rification des pr√©requis"
    
    # Node.js
    if ! command -v node &> /dev/null; then
        print_error "Node.js n'est pas install√©"
        echo "Veuillez installer Node.js 18+ depuis https://nodejs.org"
        exit 1
    fi
    
    NODE_VERSION=$(node -v | cut -d'v' -f2)
    MAJOR_VERSION=$(echo $NODE_VERSION | cut -d'.' -f1)
    
    if [ "$MAJOR_VERSION" -lt 18 ]; then
        print_error "Node.js version $NODE_VERSION d√©tect√©e (minimum requis: 18)"
        exit 1
    fi
    
    print_success "Node.js $NODE_VERSION d√©tect√©"
    
    # npm
    if ! command -v npm &> /dev/null; then
        print_error "npm n'est pas install√©"
        exit 1
    fi
    
    NPM_VERSION=$(npm -v)
    print_success "npm $NPM_VERSION disponible"
    
    # Git
    if ! command -v git &> /dev/null; then
        print_warning "Git n'est pas install√© (optionnel pour ce projet)"
    else
        print_success "Git disponible"
    fi
}

# Installation d'Ollama
install_ollama() {
    print_step "Installation d'Ollama"
    
    if command -v ollama &> /dev/null; then
        print_success "Ollama d√©j√† install√©: $(ollama --version)"
        return 0
    fi
    
    print_info "Installation d'Ollama en cours..."
    
    # D√©tecter l'OS
    if [[ "$OSTYPE" == "linux-gnu"* ]]; then
        # Linux
        if command -v apt &> /dev/null; then
            print_info "D√©tect√©: Ubuntu/Debian"
            curl -fsSL https://ollama.ai/install.sh | sh
        elif command -v yum &> /dev/null; then
            print_info "D√©tect√©: RHEL/CentOS"
            curl -fsSL https://ollama.ai/install.sh | sh
        else
            print_info "Linux g√©n√©rique d√©tect√©"
            curl -fsSL https://ollama.ai/install.sh | sh
        fi
    elif [[ "$OSTYPE" == "darwin"* ]]; then
        # macOS
        if command -v brew &> /dev/null; then
            print_info "Installation via Homebrew..."
            brew install ollama
        else
            print_info "Homebrew non trouv√©. Veuillez installer Ollama manuellement depuis https://ollama.ai"
            open https://ollama.ai
            read -p "Appuyez sur Entr√©e apr√®s avoir install√© Ollama..."
        fi
    else
        print_error "OS non support√© pour l'installation automatique: $OSTYPE"
        print_info "Veuillez installer Ollama manuellement depuis https://ollama.ai"
        exit 1
    fi
    
    # V√©rifier l'installation
    if command -v ollama &> /dev/null; then
        print_success "Ollama install√© avec succ√®s"
    else
        print_error "√âchec de l'installation d'Ollama"
        exit 1
    fi
}

# Configuration du projet
setup_project() {
    print_step "Configuration du projet"
    
    # V√©rifier que nous sommes dans le bon dossier
    if [ ! -f "package.json" ]; then
        print_error "package.json non trouv√©"
        print_info "Assurez-vous d'√™tre dans le dossier du projet rdp2"
        exit 1
    fi
    
    # Installer les d√©pendances Node.js
    print_info "Installation des d√©pendances Node.js..."
    npm install
    
    if [ $? -eq 0 ]; then
        print_success "D√©pendances install√©es"
    else
        print_error "√âchec de l'installation des d√©pendances"
        exit 1
    fi
    
    # Cr√©er le fichier .env
    if [ ! -f ".env" ]; then
        print_info "Cr√©ation du fichier .env..."
        cp .env.example .env
        print_success "Fichier .env cr√©√©"
    else
        print_info "Fichier .env existant pr√©serv√©"
    fi
    
    # Cr√©er les dossiers n√©cessaires
    mkdir -p uploads data logs
    print_success "Dossiers de travail cr√©√©s"
}

# Installation des mod√®les Ollama
install_models() {
    print_step "Installation des mod√®les Ollama"
    
    # V√©rifier qu'Ollama fonctionne
    if ! ollama list &> /dev/null; then
        print_error "Ollama n'est pas accessible"
        print_info "Assurez-vous qu'Ollama est d√©marr√©: ollama serve"
        exit 1
    fi
    
    # D√©marrer Ollama en arri√®re-plan si n√©cessaire
    if ! curl -s http://localhost:11434/api/tags &> /dev/null; then
        print_info "D√©marrage d'Ollama en arri√®re-plan..."
        ollama serve &
        OLLAMA_PID=$!
        
        # Attendre qu'Ollama soit pr√™t
        print_info "Attente du d√©marrage d'Ollama..."
        for i in {1..30}; do
            if curl -s http://localhost:11434/api/tags &> /dev/null; then
                print_success "Ollama d√©marr√©"
                break
            fi
            sleep 1
        done
        
        if [ $i -eq 30 ]; then
            print_error "Timeout: Ollama n'a pas d√©marr√©"
            exit 1
        fi
    fi
    
    # Installer les mod√®les recommand√©s
    MODELS=("llama2" "mistral" "llava")
    
    for model in "${MODELS[@]}"; do
        print_info "Installation du mod√®le $model..."
        
        if ollama list | grep -q "$model"; then
            print_success "Mod√®le $model d√©j√† install√©"
        else
            ollama pull "$model"
            if [ $? -eq 0 ]; then
                print_success "Mod√®le $model install√©"
            else
                print_warning "√âchec de l'installation du mod√®le $model"
            fi
        fi
    done
    
    # Afficher la liste des mod√®les
    print_info "Mod√®les install√©s:"
    ollama list
}

# Configuration des permissions
setup_permissions() {
    print_step "Configuration des permissions"
    
    # Rendre les scripts ex√©cutables
    chmod +x scripts/*.js 2>/dev/null || true
    print_success "Permissions configur√©es"
}

# Test de l'installation
test_installation() {
    print_step "Test de l'installation"
    
    # Test Node.js
    if command -v node &> /dev/null; then
        print_success "Node.js op√©rationnel"
    fi
    
    # Test npm
    if command -v npm &> /dev/null; then
        print_success "npm op√©rationnel"
    fi
    
    # Test Ollama
    if command -v ollama &> /dev/null; then
        print_success "Ollama install√©"
        
        # Test connectivit√© Ollama
        if curl -s http://localhost:11434/api/tags &> /dev/null; then
            print_success "Connexion Ollama r√©ussie"
        else
            print_warning "Ollama install√© mais non accessible (normal si pas d√©marr√©)"
        fi
    fi
    
    # Test projet
    if [ -f ".env" ] && [ -d "node_modules" ]; then
        print_success "Configuration projet termin√©e"
    fi
}

# Affichage des instructions finales
show_final_instructions() {
    print_header "INSTALLATION TERMIN√âE"
    
    echo -e "${GREEN}üéâ DocuCortex IA avec Ollama a √©t√© install√© avec succ√®s !${NC}\n"
    
    echo -e "${CYAN}üìã PROCHAINES √âTAPES:${NC}"
    echo -e "1. ${YELLOW}D√©marrer Ollama (si pas d√©j√† fait):${NC}"
    echo -e "   ${BLUE}ollama serve${NC}"
    echo ""
    echo -e "2. ${YELLOW}D√©marrer l'application:${NC}"
    echo -e "   ${BLUE}npm run electron:dev${NC}"
    echo ""
    echo -e "3. ${YELLOW}Tester la connectivit√©:${NC}"
    echo -e "   ${BLUE}npm run ollama:test${NC}"
    echo ""
    
    echo -e "${CYAN}üöÄ COMMANDES UTILES:${NC}"
    echo -e "‚Ä¢ ${BLUE}npm run electron:dev${NC}     - D√©marrage complet (dev)"
    echo -e "‚Ä¢ ${BLUE}npm run server:dev${NC}       - Serveur seulement"
    echo -e "‚Ä¢ ${BLUE}npm start${NC}                - Frontend seulement"
    echo -e "‚Ä¢ ${BLUE}npm run ollama:test${NC}      - Test de connectivit√©"
    echo -e "‚Ä¢ ${BLUE}ollama serve${NC}             - D√©marrer Ollama"
    echo -e "‚Ä¢ ${BLUE}ollama list${NC}              - Voir les mod√®les"
    echo ""
    
    echo -e "${CYAN}üìñ DOCUMENTATION:${NC}"
    echo -e "‚Ä¢ ${BLUE}docs/quick-start.md${NC}      - Guide de d√©marrage rapide"
    echo -e "‚Ä¢ ${BLUE}docs/installation.md${NC}     - Installation d√©taill√©e"
    echo -e "‚Ä¢ ${BLUE}docs/utilisation.md${NC}      - Guide d'utilisation"
    echo -e "‚Ä¢ ${BLUE}README.md${NC}                - Vue d'ensemble"
    echo ""
    
    echo -e "${YELLOW}‚ö° DANS LE NAVIGATEUR:${NC}"
    echo -e "1. Ouvrir l'application DocuCortex"
    echo -e "2. Cliquer sur l'onglet 'DocuCortex IA'"
    echo -e "3. V√©rifier le statut dans 'Statut & Tests'"
    echo -e "4. Essayer la g√©n√©ration dans 'G√©n√©ration de Texte'"
    echo ""
    
    echo -e "${GREEN}‚ú® Profitez de DocuCortex IA avec l'intelligence artificielle !${NC}\n"
}

# Fonction de nettoyage en cas d'erreur
cleanup() {
    print_error "Installation interrompue"
    print_info "Nettoyage en cours..."
    
    # Arr√™ter Ollama si on l'avons d√©marr√©
    if [ ! -z "$OLLAMA_PID" ]; then
        kill $OLLAMA_PID 2>/dev/null || true
    fi
    
    exit 1
}

# Gestion des signaux
trap cleanup INT TERM

# Main
main() {
    print_header "INSTALLATION DOCUCORTEX IA - OLLAMA"
    
    echo -e "${CYAN}Ce script va installer et configurer DocuCortex IA avec Ollama.${NC}"
    echo -e "${CYAN}Dur√©e estim√©e: 5-15 minutes selon votre connexion.${NC}\n"
    
    # Demander confirmation
    read -p "Continuer l'installation ? (y/N): " -n 1 -r
    echo
    if [[ ! $REPLY =~ ^[Yy]$ ]]; then
        print_info "Installation annul√©e"
        exit 0
    fi
    
    # Ex√©cution des √©tapes
    check_prerequisites
    install_ollama
    setup_project
    install_models
    setup_permissions
    test_installation
    show_final_instructions
}

# V√©rifier si le script est ex√©cut√© directement
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    main "$@"
fi