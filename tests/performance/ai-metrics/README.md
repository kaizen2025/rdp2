# Syst√®me de M√©triques IA - DocuCortex

## üìä Vue d'ensemble

Ce syst√®me complet de m√©triques pour les temps de r√©ponse IA/OCR sous charge permet de mesurer, analyser et surveiller les performances des services IA de DocuCortex en conditions r√©elles d'utilisation.

### üéØ Objectifs

- **Tests de performance** sous charge pour tous les services IA
- **Monitoring en temps r√©el** des temps de r√©ponse et m√©triques syst√®me
- **Alertes automatiques** bas√©es sur des seuils configurables
- **Tableaux de bord interactifs** pour la visualisation des donn√©es
- **Rapports d√©taill√©s** avec recommandations d'optimisation

### üöÄ Services Test√©s

1. **Ollama IA** (llama3.2:3b) - Temps de r√©ponse, d√©bit, utilisation m√©moire
2. **EasyOCR** - Performance multi-langues, pr√©cision, traitement
3. **DocuCortex IA** - Chat, recherche, traitement de documents
4. **GED Services** - Upload, indexation, recherche volum√©trique
5. **R√©seau** - Latence, bande passante, connectivit√©
6. **D√©gradation Gracieuse** - R√©silience sous charge excessive

## üìÅ Structure du Projet

```
ai-metrics/
‚îú‚îÄ‚îÄ scripts/                    # Scripts de tests de performance
‚îÇ   ‚îú‚îÄ‚îÄ ollama-load-test.js     # Test Ollama sous charge
‚îÇ   ‚îú‚îÄ‚îÄ easyocr-load-test.js    # Test EasyOCR multi-langues
‚îÇ   ‚îú‚îÄ‚îÄ docucortex-ai-load-test.js # Test DocuCortex IA
‚îÇ   ‚îú‚îÄ‚îÄ ged-volume-load-test.js # Test GED volum√©trique
‚îÇ   ‚îú‚îÄ‚îÄ network-latency-test.js # Test latence r√©seau
‚îÇ   ‚îî‚îÄ‚îÄ graceful-degradation-test.js # Test d√©gradation
‚îú‚îÄ‚îÄ shared/                     # Modules partag√©s
‚îÇ   ‚îú‚îÄ‚îÄ performance-monitor.js  # Monitoring syst√®me
‚îÇ   ‚îú‚îÄ‚îÄ load-generator.js       # G√©n√©ration de charge
‚îÇ   ‚îî‚îÄ‚îÄ metrics-collector.js    # Collecte de m√©triques
‚îú‚îÄ‚îÄ dashboards/                 # Tableaux de bord
‚îÇ   ‚îî‚îÄ‚îÄ metrics-dashboard.html  # Dashboard temps r√©el
‚îú‚îÄ‚îÄ alerts/                     # Syst√®me d'alertes
‚îÇ   ‚îú‚îÄ‚îÄ alert-thresholds.js     # Gestion des seuils
‚îÇ   ‚îî‚îÄ‚îÄ alert-config.json       # Configuration des alertes
‚îú‚îÄ‚îÄ configs/                    # Configurations
‚îú‚îÄ‚îÄ results/                    # R√©sultats des tests
‚îú‚îÄ‚îÄ ai-metrics-orchestrator.js  # Orchestrateur principal
‚îú‚îÄ‚îÄ start-ai-metrics.sh         # Script de d√©marrage
‚îî‚îÄ‚îÄ README.md                   # Cette documentation
```

## üõ†Ô∏è Installation

### Pr√©requis

- **Node.js** >= 14.x
- **npm** >= 6.x
- **Python3** (pour EasyOCR, optionnel)
- **Ollama** (pour les tests IA, optionnel)

### Installation Rapide

```bash
# Cloner le projet
git clone <repository-url>
cd rdp/tests/performance/ai-metrics

# Utiliser le script de d√©marrage automatique
./start-ai-metrics.sh --quick
```

### Installation Manuelle

```bash
# 1. Installer les d√©pendances Node.js
npm install

# 2. Installer EasyOCR (optionnel)
pip3 install easyocr

# 3. Configurer l'environnement
cp .env.example .env
# √âditer .env avec vos configurations

# 4. Cr√©er les dossiers de travail
mkdir -p results temp logs
```

## üöÄ Utilisation

### D√©marrage Rapide

```bash
# Ex√©cution rapide (Ollama + EasyOCR)
./start-ai-metrics.sh --quick

# Tests complets (tous les services)
./start-ai-metrics.sh --full

# D√©marrer le dashboard
./start-ai-metrics.sh --dashboard
```

### Mode Interactif

```bash
# Lancer le menu interactif
./start-ai-metrics.sh

# Puis choisir dans le menu:
# 1) Ex√©cution rapide
# 2) Tests complets
# 3-8) Tests individuels
# 9) Dashboard
# etc.
```

### Utilisation Programmatique

```javascript
const AIPerformanceOrchestrator = require('./ai-metrics-orchestrator');

const orchestrator = new AIPerformanceOrchestrator();

// Tests en parall√®le
await orchestrator.runAllTests({
    parallel: true,
    tests: ['ollama', 'easyocr', 'network']
});

// Tests sp√©cifiques
await orchestrator.runAllTests({
    tests: ['docucortex', 'ged'],
    config: {
        docucortex: { concurrentUsers: 10 },
        ged: { totalDocuments: 200 }
    }
});
```

### Options de Ligne de Commande

```bash
# Aide compl√®te
node ai-metrics-orchestrator.js --help

# Tests sp√©cifiques en parall√®le
node ai-metrics-orchestrator.js --tests ollama,easyocr --parallel

# Tests avec configuration personnalis√©e
node ai-metrics-orchestrator.js --tests all --config my-config.json

# Mode silencieux
node ai-metrics-orchestrator.js --tests all --quiet
```

## üìä Tests de Performance

### 1. Test Ollama IA

Mesure les performances du mod√®le llama3.2:3b sous charge :

- **M√©triques** : Temps de r√©ponse, d√©bit (tokens/sec), utilisation m√©moire
- **Charge** : 5 utilisateurs concurrents, mont√©e progressive
- **Duraci√≥n** : 5 minutes
- **Seuils** : 
  - Temps de r√©ponse critique : > 5s
  - D√©bit critique : < 15 tokens/sec
  - M√©moire critique : > 90%

```javascript
// Exemple de configuration
{
  "ollama": {
    "baseUrl": "http://localhost:11434",
    "model": "llama3.2:3b",
    "concurrentUsers": 5,
    "requestsPerUser": 20
  }
}
```

### 2. Test EasyOCR Multi-langues

√âvalue les performances OCR sur plusieurs langues :

- **Langues** : Fran√ßais, Anglais, Espagnol, Allemand, Italien
- **M√©triques** : Temps de traitement, pr√©cision, confiance
- **Types** : Images PNG/JPG, documents texte
- **Seuils** :
  - Traitement critique : > 10s
  - Pr√©cision critique : < 85%
  - Confiance critique : < 0.7

### 3. Test DocuCortex IA

Test complet des fonctionnalit√©s IA :

- **Modules** : Chat IA, Recherche s√©mantique, Traitement
- **M√©triques** : Temps par module, throughput, erreurs
- **Charge** : 8 utilisateurs concurrents
- **Seuils** :
  - Chat critique : > 8s
  - Recherche critique : > 3s
  - Traitement critique : > 6s

### 4. Test GED Volumineux

Performance de gestion documentaire :

- **Documents** : 100 fichiers (PDF, DOCX, images)
- **Op√©rations** : Upload, indexation, recherche
- **M√©triques** : Vitesse upload, temps indexation, d√©bit recherche
- **Seuils** :
  - Upload critique : < 1 MB/s
  - Indexation critique : < 10 docs/min
  - Recherche critique : > 1s

### 5. Test Latence R√©seau

Analyse de la connectivit√© r√©seau :

- **Tests** : Ping, TCP, HTTP, bande passante, jitter
- **M√©triques** : Latence, perte paquets, score r√©seau
- **Cibles** : Ollama, DocuCortex, EasyOCR
- **Seuils** :
  - Latence critique : > 1000ms
  - Perte paquets critique : > 10%
  - Score r√©seau critique : < 70

### 6. Test D√©gradation Gracieuse

R√©silience sous charge excessive :

- **Charge** : 5 √† 50 utilisateurs progressifs
- **M√©canismes** : Fallback, mise en file, d√©gradation
- **M√©triques** : Score r√©silience, √©v√©nements d√©gradation
- **Seuils** :
  - R√©silience critique : < 70%
  - Taux fallback critique : > 20%

## üîî Syst√®me d'Alertes

### Configuration des Seuils

Les seuils d'alerte sont configur√©s dans `alerts/alert-config.json` :

```json
{
  "global": {
    "responseTime": {
      "critical": 5000,
      "high": 3000,
      "warning": 2000,
      "good": 1000
    },
    "successRate": {
      "critical": 80,
      "high": 85,
      "warning": 90,
      "good": 95
    }
  },
  "services": {
    "ollama": {
      "responseTime": {
        "multiplier": 1.5,
        "critical": 7500
      }
    }
  }
}
```

### Niveaux d'Alerte

- **üî¥ CRITICAL** : Action imm√©diate requise
- **üü° HIGH** : Intervention sous 1 heure
- **üü† WARNING** : Surveillance sous 4 heures
- **üü¢ LOW** : Information

### Escalade Automatique

```javascript
const alertThresholds = new AlertThresholds({
    configPath: './alerts/alert-config.json'
});

// V√©rifier une m√©trique
const result = alertThresholds.checkThreshold(
    'responseTime', 
    3500, // valeur mesur√©e
    'ollama' // service
);

if (result.triggered) {
    console.log(`Alerte ${result.level} d√©clench√©e`);
}
```

## üìà Dashboard de Monitoring

### Dashboard Temps R√©el

Le dashboard interactif (`dashboards/metrics-dashboard.html`) offre :

- **M√©triques en temps r√©el** : RPS, temps r√©ponse, taux succ√®s
- **√âtat des services** : Ollama, EasyOCR, DocuCortex, GED
- **Graphiques interactifs** : Temps r√©ponse, d√©bit, erreurs
- **Alertes visuelles** : Notifications en temps r√©el

### D√©marrage du Dashboard

```bash
# Mode simple
./start-ai-metrics.sh --dashboard

# Ou avec serveur HTTP
cd dashboards
python3 -m http.server 8080
# Ouvrir: http://localhost:8080/metrics-dashboard.html
```

### Personnalisation

Le dashboard peut √™tre personnalis√© dans `metrics-dashboard.html` :

```javascript
// Configuration des seuils d'alerte
const alertThresholds = {
    responseTime: 2000,
    successRate: 95,
    cpuUsage: 85
};

// Couleurs personnalis√©es
const colors = {
    critical: '#e74c3c',
    high: '#f39c12',
    warning: '#f1c40f',
    good: '#27ae60'
};
```

## üìÑ Rapports et Analyse

### Types de Rapports

1. **Rapport JSON D√©taill√©** : Donn√©es compl√®tes pour analyse
2. **Rapport Markdown** : Format lisible avec recommandations
3. **Export CSV** : Donn√©es tabulaires pour Excel/BI
4. **Dashboard HTML** : Visualisation interactive

### G√©n√©ration de Rapports

```javascript
// Rapport consolid√© automatique
const report = await orchestrator.generateConsolidatedReport(testResults);

// Export CSV des m√©triques
metricsCollector.exportToCSV();

// Rapport sant√© des seuils
const healthReport = alertThresholds.generateHealthReport();
```

### Analyse Automatique

Le syst√®me g√©n√®re automatiquement :

- **Score de performance global** (0-100)
- **Goulots d'√©tranglement** identifi√©s
- **Recommandations d'optimisation**
- **Tendances de performance**
- **Pr√©visions de capacit√©**

## ‚öôÔ∏è Configuration

### Configuration Globale

Cr√©er `config/test-config.json` :

```json
{
  "ollama": {
    "baseUrl": "http://localhost:11434",
    "model": "llama3.2:3b",
    "concurrentUsers": 5,
    "enabled": true
  },
  "docucortex": {
    "baseUrl": "http://localhost:3000",
    "concurrentUsers": 8,
    "enabled": true
  },
  "general": {
    "parallel": false,
    "outputDir": "./results",
    "alertThresholds": "./alerts/alert-config.json"
  }
}
```

### Variables d'Environnement

Cr√©er `.env` :

```env
# Services IA
OLLAMA_HOST=localhost
OLLAMA_PORT=11434
DOCUCORTEX_HOST=localhost
DOCUCORTEX_PORT=3000

# Alertes
SLACK_WEBHOOK_URL=https://hooks.slack.com/services/...
EMAIL_NOTIFICATIONS=admin@docucortex.com

# R√©seau
NETWORK_TIMEOUT=5000
PING_COUNT=100

# Dashboard
DASHBOARD_PORT=8080
REFRESH_INTERVAL=2000
```

### Configuration Avanc√©e

```javascript
// Configuration personnalis√©e des tests
const customConfig = {
    ollama: {
        concurrentUsers: 10,
        testDuration: 600,
        customPrompts: [
            "Expliquez l'IA en 2 phrases",
            "R√©sumez ce document",
            "Traduisez ce texte"
        ]
    },
    degradation: {
        enableFallback: true,
        maxUsers: 100,
        stepUsers: 10
    }
};

await orchestrator.runAllTests({
    config: customConfig
});
```

## üîß D√©pannage

### Probl√®mes Courants

#### 1. Services IA Non Accessible

```bash
# V√©rifier l'√©tat des services
curl http://localhost:11434/api/version  # Ollama
curl http://localhost:3000/api/health    # DocuCortex

# D√©marrer les services
./start-ai-metrics.sh --services
```

#### 2. Erreurs de D√©pendances

```bash
# R√©installer les d√©pendances
npm install --force

# V√©rifier Python/EasyOCR
python3 -c "import easyocr; print('OK')"
```

#### 3. Probl√®mes de Performance

```bash
# Tester en mode mock (sans services r√©els)
node ai-metrics-orchestrator.js --tests ollama --mock-mode

# R√©duire la charge
node ai-metrics-orchestrator.js --tests ollama --concurrent-users 2
```

### Logs et D√©bogage

```bash
# Logs en temps r√©el
tail -f logs/ai-metrics.log

# Mode verbeux
node ai-metrics-orchestrator.js --verbose --tests ollama

# Debug sp√©cifique
DEBUG=ai-metrics:* node ai-metrics-orchestrator.js
```

### Configuration R√©seau

```bash
# Test de connectivit√©
ping localhost
telnet localhost 11434  # Ollama
telnet localhost 3000   # DocuCortex

# Ports utilis√©s
netstat -tulpn | grep -E "(11434|3000)"
```

## üìö Exemples d'Utilisation

### 1. Test de Charge Quotidien

```bash
#!/bin/bash
# daily-load-test.sh

cd /path/to/ai-metrics

# Nettoyer les anciens r√©sultats
rm -f results/*.json

# Ex√©cuter les tests
./start-ai-metrics.sh --full

# G√©n√©rer un rapport quotidien
node -e "
const orchestrator = require('./ai-metrics-orchestrator');
orchestrator.runAllTests().then(() => {
    console.log('Tests quotidiens termin√©s');
});
"
```

### 2. Monitoring Continu

```javascript
// continuous-monitoring.js
const orchestrator = new AIPerformanceOrchestrator();

async function continuousMonitoring() {
    while (true) {
        try {
            // Tests rapides toutes les 5 minutes
            await orchestrator.runAllTests({
                tests: ['ollama', 'docucortex', 'network'],
                config: {
                    ollama: { concurrentUsers: 2 },
                    docucortex: { concurrentUsers: 3 }
                }
            });
            
            // Attendre 5 minutes
            await new Promise(resolve => setTimeout(resolve, 300000));
            
        } catch (error) {
            console.error('Erreur monitoring:', error);
            await new Promise(resolve => setTimeout(resolve, 60000)); // Attendre 1 minute
        }
    }
}

continuousMonitoring();
```

### 3. Test de R√©gression

```javascript
// regression-test.js
const baselineResults = require('./results/baseline-results.json');

async function regressionTest() {
    const currentResults = await orchestrator.runAllTests();
    
    // Comparer avec la baseline
    const regressions = [];
    
    Object.entries(currentResults).forEach(([service, current]) => {
        const baseline = baselineResults[service];
        
        if (baseline && current.avgResponseTime > baseline.avgResponseTime * 1.2) {
            regressions.push({
                service,
                metric: 'responseTime',
                baseline: baseline.avgResponseTime,
                current: current.avgResponseTime,
                degradation: ((current.avgResponseTime / baseline.avgResponseTime - 1) * 100).toFixed(1) + '%'
            });
        }
    });
    
    if (regressions.length > 0) {
        console.log('üö® R√âGRESSIONS D√âTECT√âES:');
        regressions.forEach(reg => {
            console.log(`- ${reg.service}: ${reg.degradation} plus lent`);
        });
        
        // Envoyer une alerte
        // await sendSlackAlert(regressions);
    }
}
```

## ü§ù Contribution

### Structure du Code

```javascript
// Template pour un nouveau test
class NewServiceLoadTest {
    constructor(config = {}) {
        this.config = {
            baseUrl: 'http://localhost:port',
            concurrentUsers: 5,
            testDuration: 300,
            ...config
        };
        
        this.monitor = new PerformanceMonitor('new-service');
        this.metrics = new MetricsCollector('new-service-load-test');
    }
    
    async run() {
        await this.initialize();
        await this.runTest();
        const summary = await this.generateReport();
        return summary;
    }
}
```

### Standards de Code

- **ESLint** : Configuration pour Node.js
- **Documentation** : JSDoc pour toutes les fonctions
- **Tests** : Chaque module doit avoir ses tests
- **Logs** : Utiliser console.log avec niveaux (INFO, WARN, ERROR)

### Ajout d'un Nouveau Test

1. Cr√©er `scripts/new-service-load-test.js`
2. √âtendre `PerformanceMonitor` et `MetricsCollector`
3. Ajouter la configuration dans `alert-config.json`
4. Mettre √† jour l'orchestrateur
5. Ajouter au menu du script de d√©marrage
6. Documenter dans ce README

## üìû Support

### Contacts

- **Documentation** : Ce README
- **Issues** : Syst√®me de tickets GitHub
- **Slack** : #ai-metrics-support
- **Email** : ai-metrics@docucortex.com

### Ressources

- **Wiki** : Documentation technique d√©taill√©e
- **API Reference** : Documentation des modules
- **Examples** : Exemples d'utilisation avanc√©s
- **Best Practices** : Guide d'optimisation

## üìÑ Licence

Ce projet est sous licence MIT. Voir le fichier LICENSE pour plus de d√©tails.

---

**D√©velopp√© avec ‚ù§Ô∏è par l'√©quipe DocuCortex**

*Derni√®re mise √† jour : 2025-11-04*