/**
 * Setup global pour les tests de performance UI
 * Configure l'environnement de test et les m√©triques globales
 */

const { PerformanceProfiler } = require('./utils/performance-utils');
const { testFixtures } = require('./fixtures/test-fixtures');
const fs = require('fs');
const path = require('path');

// Profiler global pour tous les tests
global.performanceProfiler = new PerformanceProfiler();

// R√©pertoire pour les r√©sultats
const resultsDir = path.join(__dirname, 'results');

// Cr√©er le r√©pertoire de r√©sultats s'il n'existe pas
if (!fs.existsSync(resultsDir)) {
  fs.mkdirSync(resultsDir, { recursive: true });
}

// Configuration globale des timeouts
jest.setTimeout(30000);

// Configuration des reporters personnalis√©s
const customReporters = [
  'default',
  ['jest-html-reporters', {
    publicPath: resultsDir,
    filename: 'ui-reactivity-performance-report.html',
    expand: true,
    inlineAssets: true,
    pageTitle: 'Rapport de Performance UI R√©activit√©',
    hideIcon: true,
    logoImgPath: '',
    customInfos: [
      {
        title: 'Tests de Performance UI',
        content: 'Tests de r√©activit√© de l\'interface utilisateur sous charge'
      }
    ]
  }]
];

// Configuration des m√©triques globales
const globalMetrics = {
  testSuite: 'UI R√©activit√© Performance',
  environment: process.env.NODE_ENV || 'test',
  nodeVersion: process.version,
  platform: process.platform,
  startTime: new Date().toISOString(),
  totalTests: 0,
  passedTests: 0,
  failedTests: 0,
  performanceBenchmarks: {},
  memoryUsage: {},
  timingMetrics: {}
};

// Fonction pour collecter les m√©triques de performance
function collectPerformanceMetrics() {
  const memUsage = process.memoryUsage();
  
  return {
    heapUsed: memUsage.heapUsed,
    heapTotal: memUsage.heapTotal,
    external: memUsage.external,
    rss: memUsage.rss,
    arrayBuffers: memUsage.arrayBuffers || 0,
    heapUsedMB: (memUsage.heapUsed / 1024 / 1024).toFixed(2),
    heapTotalMB: (memUsage.heapTotal / 1024 / 1024).toFixed(2)
  };
}

// Hook avant chaque test
beforeEach(() => {
  // D√©marrer le profiler pour ce test
  const testName = expect.getState().currentTestName || 'unknown';
  global.performanceProfiler.start(`test_${testName}`);
  
  // R√©initialiser les mocks WebSocket
  jest.clearAllMocks();
  
  // R√©initialiser les timers
  jest.useFakeTimers();
});

// Hook apr√®s chaque test
afterEach(() => {
  const testName = expect.getState().currentTestName || 'unknown';
  
  try {
    global.performanceProfiler.end(`test_${testName}`);
  } catch (error) {
    console.warn(`Could not end performance measurement for test: ${testName}`);
  }
  
  // Restaurer les timers
  jest.useRealTimers();
  
  // Nettoyer les intervals et timeouts
  jest.clearAllTimers();
});

// Hook avant tous les tests
beforeAll(() => {
  console.log('üöÄ Initialisation de la suite de tests de performance UI...');
  
  // Collecter les m√©triques initiales
  globalMetrics.initialMemory = collectPerformanceMetrics();
  
  // Pr√©parer les fixtures de test
  testFixtures.preloadData();
  
  // Configurer les handlers d'erreurs non captur√©es
  const originalErrorHandler = process.listeners('uncaughtException').pop();
  process.removeAllListeners('uncaughtException');
  
  process.on('uncaughtException', (error) => {
    console.error('Erreur non captur√©e dans les tests:', error);
    globalMetrics.uncaughtErrors = (globalMetrics.uncaughtErrors || 0) + 1;
    globalMetrics.lastError = error.message;
    
    // Restaurer le handler original et le relancer
    process.listeners('uncaughtException').forEach(listener => {
      process.removeListener('uncaughtException', listener);
    });
    if (originalErrorHandler) {
      process.on('uncaughtException', originalErrorHandler);
    }
    throw error;
  });
  
  // Configurer les handlers de promesses rejet√©es
  process.on('unhandledRejection', (reason, promise) => {
    console.error('Promesse rejet√©e non g√©r√©e:', reason);
    globalMetrics.unhandledRejections = (globalMetrics.unhandledRejections || 0) + 1;
    globalMetrics.lastRejection = reason;
  });
  
  console.log('‚úÖ Suite de tests initialis√©e');
});

// Hook apr√®s tous les tests
afterAll(async () => {
  console.log('üìä Finalisation de la suite de tests...');
  
  // Collecter les m√©triques finales
  globalMetrics.finalMemory = collectPerformanceMetrics();
  globalMetrics.endTime = new Date().toISOString();
  
  // Calculer la m√©moire utilis√©e pendant les tests
  globalMetrics.memoryIncrease = 
    globalMetrics.finalMemory.heapUsed - globalMetrics.initialMemory.heapUsed;
  
  // Exporter les m√©triques de performance globales
  const globalPerformanceData = global.performanceProfiler.export();
  
  // G√©n√©rer le rapport global
  await generateGlobalReport({
    ...globalMetrics,
    performanceData: globalPerformanceData,
    fixtureStats: {
      listItems: testFixtures.getDataStats('list', 'dashboard'),
      notifications: testFixtures.getDataStats('notifications', 'dashboard'),
      menus: testFixtures.getDataStats('menu', 'dashboard')
    }
  });
  
  // Nettoyer
  testFixtures.clearCache();
  
  console.log('‚úÖ Suite de tests finalis√©e');
});

// Fonction pour g√©n√©rer le rapport global
async function generateGlobalReport(metrics) {
  const reportPath = path.join(resultsDir, `global-performance-report-${Date.now()}.json`);
  const htmlPath = path.join(resultsDir, `global-performance-report-${Date.now()}.html`);
  
  const report = {
    ...metrics,
    summary: {
      totalTests: metrics.totalTests || 0,
      passedTests: metrics.passedTests || 0,
      failedTests: metrics.failedTests || 0,
      passRate: metrics.totalTests > 0 
        ? ((metrics.passedTests / metrics.totalTests) * 100).toFixed(1) + '%'
        : '0%',
      testDuration: new Date(metrics.endTime) - new Date(metrics.startTime),
      averageMemoryUsage: (metrics.memoryIncrease / 1024 / 1024).toFixed(2) + ' MB'
    },
    performance: {
      overallScore: calculateOverallScore(metrics.performanceData),
      benchmarks: metrics.performanceData,
      recommendations: generateRecommendations(metrics.performanceData)
    }
  };
  
  // Sauvegarder le rapport JSON
  fs.writeFileSync(reportPath, JSON.stringify(report, null, 2));
  
  // G√©n√©rer le rapport HTML
  const htmlReport = generateHTMLReport(report);
  fs.writeFileSync(htmlPath, htmlReport);
  
  console.log(`üìä Rapports g√©n√©r√©s:`);
  console.log(`   JSON: ${reportPath}`);
  console.log(`   HTML: ${htmlPath}`);
}

// Fonction pour calculer un score global de performance
function calculateOverallScore(performanceData) {
  const weights = {
    renderTime: 0.3,
    interactionTime: 0.3,
    memoryUsage: 0.2,
    errorRate: 0.2
  };
  
  let score = 0;
  let totalWeight = 0;
  
  for (const [test, data] of Object.entries(performanceData)) {
    if (data && data.average) {
      let testScore = 100;
      
      // P√©naliser les temps de r√©ponse √©lev√©s
      if (data.average > 100) testScore -= 50;
      else if (data.average > 50) testScore -= 25;
      else if (data.average > 20) testScore -= 10;
      
      // Ajouter des p√©nalit√©s pour les temps max √©lev√©s
      if (data.max > 500) testScore -= 20;
      else if (data.max > 200) testScore -= 10;
      
      score += testScore * weights.renderTime;
      totalWeight += weights.renderTime;
    }
  }
  
  return totalWeight > 0 ? Math.round(score / totalWeight) : 0;
}

// Fonction pour g√©n√©rer des recommandations
function generateRecommendations(performanceData) {
  const recommendations = [];
  
  for (const [test, data] of Object.entries(performanceData)) {
    if (data && data.average > 50) {
      recommendations.push({
        test,
        issue: `Temps de r√©ponse √©lev√© (${data.average.toFixed(2)}ms)`,
        recommendation: getRecommendationForTest(test, data.average),
        severity: data.average > 200 ? 'high' : data.average > 100 ? 'medium' : 'low'
      });
    }
    
    if (data && data.p95 > data.average * 3) {
      recommendations.push({
        test,
        issue: `Grande variabilit√© (P95: ${data.p95.toFixed(2)}ms vs Moyenne: ${data.average.toFixed(2)}ms)`,
        recommendation: 'Optimiser la consistence des performances - v√©rifier la gestion des √©tats',
        severity: 'medium'
      });
    }
  }
  
  return recommendations;
}

// Fonction pour obtenir des recommandations sp√©cifiques par test
function getRecommendationForTest(test, averageTime) {
  if (test.includes('render')) {
    return 'Consid√©rer l\'utilisation de React.memo, useMemo, et la virtualisation pour optimiser le rendu';
  } else if (test.includes('click')) {
    return 'Optimiser les gestionnaires d\'√©v√©nements et √©viter les calculs lourds dans les callbacks';
  } else if (test.includes('filter')) {
    return 'Impl√©menter la memoization des r√©sultats de filtrage et ajouter du debouncing';
  } else if (test.includes('menu')) {
    return 'Virtualiser les grandes listes de menu et optimiser la recherche';
  } else {
    return 'Analyser les goulots d\'√©tranglement avec les outils de profiling React';
  }
}

// Fonction pour g√©n√©rer le rapport HTML
function generateHTMLReport(report) {
  return `
<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Rapport Global de Performance UI</title>
    <style>
        body { font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; margin: 0; padding: 20px; background: #f5f5f5; }
        .container { max-width: 1200px; margin: 0 auto; background: white; padding: 20px; border-radius: 8px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }
        .header { text-align: center; margin-bottom: 30px; }
        .metrics-grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 20px; margin-bottom: 30px; }
        .metric-card { background: #f8f9fa; padding: 20px; border-radius: 8px; border-left: 4px solid #007bff; }
        .metric-title { font-size: 14px; color: #666; margin-bottom: 5px; }
        .metric-value { font-size: 24px; font-weight: bold; color: #333; }
        .score-card { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; }
        .score-value { font-size: 48px; font-weight: bold; }
        .recommendations { margin-top: 30px; }
        .recommendation { padding: 15px; margin: 10px 0; border-radius: 5px; }
        .recommendation.high { background-color: #f8d7da; border-left: 4px solid #dc3545; }
        .recommendation.medium { background-color: #fff3cd; border-left: 4px solid #ffc107; }
        .recommendation.low { background-color: #d1ecf1; border-left: 4px solid #17a2b8; }
        .performance-table { width: 100%; border-collapse: collapse; margin: 20px 0; }
        .performance-table th, .performance-table td { padding: 12px; text-align: left; border-bottom: 1px solid #ddd; }
        .performance-table th { background-color: #f8f9fa; }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üìä Rapport Global de Performance UI</h1>
            <p>G√©n√©r√© le ${new Date(report.summary.endTime || Date.now()).toLocaleString('fr-FR')}</p>
        </div>
        
        <div class="metrics-grid">
            <div class="metric-card score-card">
                <div class="metric-title">Score Global de Performance</div>
                <div class="score-value">${report.performance.overallScore || 0}/100</div>
            </div>
            <div class="metric-card">
                <div class="metric-title">Tests Totaux</div>
                <div class="metric-value">${report.summary.totalTests || 0}</div>
            </div>
            <div class="metric-card">
                <div class="metric-title">Taux de R√©ussite</div>
                <div class="metric-value">${report.summary.passRate || '0%'}</div>
            </div>
            <div class="metric-card">
                <div class="metric-title">Utilisation M√©moire</div>
                <div class="metric-value">${report.summary.averageMemoryUsage || '0 MB'}</div>
            </div>
        </div>
        
        ${report.performance.recommendations && report.performance.recommendations.length > 0 ? `
        <div class="recommendations">
            <h2>üí° Recommandations d'Am√©lioration</h2>
            ${report.performance.recommendations.map(rec => `
                <div class="recommendation ${rec.severity}">
                    <h4>${rec.test}</h4>
                    <p><strong>Probl√®me:</strong> ${rec.issue}</p>
                    <p><strong>Recommandation:</strong> ${rec.recommendation}</p>
                </div>
            `).join('')}
        </div>
        ` : ''}
        
        <div style="margin-top: 30px; padding: 20px; background: #e9ecef; border-radius: 8px;">
            <h3>üìà M√©triques d'Environnement</h3>
            <p><strong>Environnement:</strong> ${report.environment}</p>
            <p><strong>Version Node.js:</strong> ${report.nodeVersion}</p>
            <p><strong>Plateforme:</strong> ${report.platform}</p>
            <p><strong>Dur√©e des Tests:</strong> ${(report.summary.testDuration / 1000).toFixed(1)}s</p>
        </div>
    </div>
</body>
</html>`;
}

// Export des configurations
module.exports = {
  globalMetrics,
  resultsDir,
  customReporters,
  collectPerformanceMetrics,
  generateGlobalReport
};