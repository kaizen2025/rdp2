/**
 * Service d'int√©gration Ollama pour DocuCortex
 * Permet de communiquer avec Ollama local et Llama 3.2 3B
 * S'int√®gre avec aiService.js existant
 */

const axios = require('axios');
const path = require('path');

class OllamaService {
    constructor() {
        this.baseUrl = 'http://localhost:11434';
        this.model = 'llama3.2'; // Support Llama 3.2 (compatible avec toutes les variantes)
        this.initialized = false;
        this.availableModels = [];
        this.connectionStatus = {
            connected: false,
            lastCheck: null,
            responseTime: null
        };
        this.stats = {
            totalRequests: 0,
            successfulRequests: 0,
            failedRequests: 0,
            totalTokens: 0,
            averageResponseTime: 0
        };
    }

    /**
     * Initialise le service Ollama
     */
    async initialize() {
        if (this.initialized) return { success: true };

        try {
            console.log('üîó Initialisation du service Ollama...');
            
            // V√©rifier la connexion √† Ollama
            await this.testConnection();
            
            // Charger les mod√®les disponibles
            await this.loadAvailableModels();
            
            this.initialized = true;
            console.log('‚úÖ Service Ollama initialis√© avec succ√®s');
            
            return { success: true };
        } catch (error) {
            console.error('‚ùå Erreur initialisation Ollama:', error.message);
            return { 
                success: false, 
                error: error.message,
                connectionDetails: {
                    ollamaRunning: false,
                    url: this.baseUrl,
                    model: this.model
                }
            };
        }
    }

    /**
     * Teste la connexion √† Ollama
     */
    async testConnection() {
        try {
            const startTime = Date.now();
            
            // Test de base avec un appel simple
            const response = await axios.get(`${this.baseUrl}/api/tags`, {
                timeout: 10000
            });
            
            const responseTime = Date.now() - startTime;
            
            this.connectionStatus = {
                connected: response.status === 200,
                lastCheck: new Date().toISOString(),
                responseTime: responseTime
            };
            
            console.log(`‚úÖ Connexion Ollama OK (${responseTime}ms)`);
            return {
                success: true,
                connected: true,
                responseTime: responseTime,
                ollamaVersion: response.data?.version || 'unknown'
            };
            
        } catch (error) {
            this.connectionStatus = {
                connected: false,
                lastCheck: new Date().toISOString(),
                responseTime: null,
                error: error.message
            };
            
            console.error('‚ùå Connexion Ollama √©chou√©e:', error.message);
            return {
                success: false,
                connected: false,
                error: error.message
            };
        }
    }

    /**
     * Charge les mod√®les disponibles
     */
    async loadAvailableModels() {
        try {
            const response = await axios.get(`${this.baseUrl}/api/tags`);
            this.availableModels = response.data.models || [];
            
            console.log(`üì¶ ${this.availableModels.length} mod√®les disponibles`);
            this.availableModels.forEach(model => {
                console.log(`   - ${model.name} (${Math.round(model.size / 1024 / 1024)}MB)`);
            });
            
            return this.availableModels;
        } catch (error) {
            console.error('‚ùå Erreur chargement mod√®les:', error.message);
            return [];
        }
    }

    /**
     * G√©n√®re une r√©ponse avec Ollama (compatible avec aiService)
     */
    async generateResponse(prompt, options = {}) {
        const startTime = Date.now();
        this.stats.totalRequests++;
        
        try {
            if (!this.connectionStatus.connected) {
                await this.testConnection();
            }
            
            if (!this.connectionStatus.connected) {
                throw new Error('Ollama non disponible');
            }

            const requestOptions = {
                model: options.model || this.model,
                prompt: prompt,
                stream: false,
                options: {
                    temperature: options.temperature || 0.7,
                    top_p: options.top_p || 0.9,
                    top_k: options.top_k || 40,
                    num_predict: options.maxTokens || 512,
                    stop: options.stop || ['\n\n', '###'],
                    seed: options.seed || -1
                }
            };

            console.log(`ü§ñ G√©n√©ration r√©ponse Ollama (${requestOptions.model})...`);

            const response = await axios.post(
                `${this.baseUrl}/api/generate`,
                requestOptions,
                {
                    timeout: 30000, // 30 secondes
                    headers: {
                        'Content-Type': 'application/json'
                    }
                }
            );

            const responseTime = Date.now() - startTime;
            
            if (response.data && response.data.response) {
                this.stats.successfulRequests++;
                this.stats.totalTokens += response.data.eval_count || 0;
                this._updateAverageResponseTime(responseTime);
                
                console.log(`‚úÖ R√©ponse Ollama g√©n√©r√©e (${responseTime}ms, ${response.data.eval_count || 0} tokens)`);
                
                return {
                    success: true,
                    response: response.data.response.trim(),
                    model: requestOptions.model,
                    tokens: response.data.eval_count || 0,
                    time: responseTime,
                    promptTokens: response.data.prompt_eval_count || 0,
                    completionTokens: response.data.eval_count || 0
                };
            } else {
                throw new Error('R√©ponse invalide d\'Ollama');
            }

        } catch (error) {
            this.stats.failedRequests++;
            const responseTime = Date.now() - startTime;
            
            console.error('‚ùå Erreur g√©n√©ration Ollama:', error.message);
            
            return {
                success: false,
                error: error.message,
                responseTime: responseTime,
                fallbackUsed: false
            };
        }
    }

    /**
     * Traite une conversation avec contexte (compatible avec conversationService)
     */
    async processConversation(messages, options = {}) {
        try {
            // Convertir les messages en format Ollama
            const systemPrompt = options.systemPrompt || 'Tu es DocuCortex, un assistant IA intelligent pour la gestion de documents et la recherche d\'informations. R√©ponds de mani√®re claire et helpful.';
            
            // Construire le prompt avec contexte
            let contextPrompt = systemPrompt + '\n\n';
            
            if (options.context && options.context.length > 0) {
                contextPrompt += 'Contexte de la conversation:\n';
                options.context.slice(-5).forEach(msg => { // Garder seulement les 5 derniers messages
                    contextPrompt += `${msg.role}: ${msg.content}\n`;
                });
                contextPrompt += '\n';
            }
            
            contextPrompt += `Utilisateur: ${messages[messages.length - 1]?.content || messages[messages.length - 1] || messages}`;
            
            const result = await this.generateResponse(contextPrompt, options);
            
            if (result.success) {
                return {
                    success: true,
                    response: result.response,
                    conversationId: options.sessionId || 'default',
                    confidence: 0.85, // Ollama a g√©n√©ralement une bonne confiance
                    contextUsed: options.context || [],
                    modelUsed: result.model,
                    tokens: result.tokens,
                    responseTime: result.time
                };
            }
            
            return result;

        } catch (error) {
            console.error('‚ùå Erreur traitement conversation Ollama:', error.message);
            return {
                success: false,
                response: 'D√©sol√©, une erreur s\'est produite avec le service Ollama.',
                error: error.message
            };
        }
    }

    /**
     * Analyse de sentiment avec Ollama
     */
    async analyzeSentiment(text) {
        try {
            const prompt = `Analyse le sentiment de ce texte et r√©ponds uniquement par un JSON avec "sentiment" (positif/n√©gatif/neutre), "confidence" (0-1) et "emotions" (liste d'√©motions d√©tect√©es):

Texte: "${text}"

R√©ponse au format JSON uniquement:`;

            const result = await this.generateResponse(prompt, {
                maxTokens: 100,
                temperature: 0.1 // Plus d√©terministe pour l'analyse
            });

            if (result.success) {
                try {
                    const jsonMatch = result.response.match(/\{[\s\S]*\}/);
                    if (jsonMatch) {
                        const sentimentData = JSON.parse(jsonMatch[0]);
                        return {
                            success: true,
                            sentiment: sentimentData.sentiment || 'neutral',
                            confidence: sentimentData.confidence || 0.5,
                            emotions: sentimentData.emotions || []
                        };
                    }
                } catch (parseError) {
                    console.warn('‚ö†Ô∏è Erreur parsing sentiment:', parseError.message);
                }
            }

            return {
                success: false,
                error: 'Impossible d\'analyser le sentiment'
            };

        } catch (error) {
            console.error('‚ùå Erreur analyse sentiment:', error.message);
            return {
                success: false,
                error: error.message
            };
        }
    }

    /**
     * R√©sum√© intelligent d'un texte
     */
    async summarizeText(text, maxLength = 200) {
        try {
            const prompt = `R√©sume ce texte en maximum ${maxLength} caract√®res en conservant les points cl√©s:

${text}

R√©sum√©:`;

            const result = await this.generateResponse(prompt, {
                maxTokens: Math.ceil(maxLength / 4), // Approximation tokens pour la longueur
                temperature: 0.3
            });

            if (result.success) {
                return {
                    success: true,
                    summary: result.response.trim(),
                    originalLength: text.length,
                    summaryLength: result.response.length,
                    compression: Math.round((1 - result.response.length / text.length) * 100)
                };
            }

            return {
                success: false,
                error: 'Impossible de g√©n√©rer le r√©sum√©'
            };

        } catch (error) {
            console.error('‚ùå Erreur r√©sum√© texte:', error.message);
            return {
                success: false,
                error: error.message
            };
        }
    }

    /**
     * Extraction de mots-cl√©s
     */
    async extractKeywords(text, maxKeywords = 10) {
        try {
            const prompt = `Extrais ${maxKeywords} mots-cl√©s importants de ce texte. R√©ponds uniquement par une liste s√©par√©e par des virgules:

${text}

Mots-cl√©s:`;

            const result = await this.generateResponse(prompt, {
                maxTokens: 50,
                temperature: 0.2
            });

            if (result.success) {
                const keywords = result.response
                    .split(',')
                    .map(k => k.trim().toLowerCase())
                    .filter(k => k.length > 2)
                    .slice(0, maxKeywords);
                
                return {
                    success: true,
                    keywords: keywords,
                    count: keywords.length
                };
            }

            return {
                success: false,
                error: 'Impossible d\'extraire les mots-cl√©s'
            };

        } catch (error) {
            console.error('‚ùå Erreur extraction mots-cl√©s:', error.message);
            return {
                success: false,
                error: error.message
            };
        }
    }

    /**
     * Traduction avec Ollama
     */
    async translateText(text, targetLanguage = 'fran√ßais') {
        try {
            const prompt = `Traduis ce texte en ${targetLanguage}. R√©ponds uniquement par la traduction:

${text}

Traduction:`;

            const result = await this.generateResponse(prompt, {
                maxTokens: Math.ceil(text.length / 2), // Estimation
                temperature: 0.2
            });

            if (result.success) {
                return {
                    success: true,
                    translation: result.response.trim(),
                    originalText: text,
                    targetLanguage: targetLanguage
                };
            }

            return {
                success: false,
                error: 'Impossible de traduire le texte'
            };

        } catch (error) {
            console.error('‚ùå Erreur traduction:', error.message);
            return {
                success: false,
                error: error.message
            };
        }
    }

    /**
     * Q&A sur un document
     */
    async answerQuestion(documentText, question) {
        try {
            const prompt = `R√©ponds √† la question en te basant UNIQUEMENT sur le document fourni. Si la r√©ponse n'est pas dans le document, dis-le clairement.

Document:
${documentText}

Question: ${question}

R√©ponse:`;

            const result = await this.generateResponse(prompt, {
                maxTokens: 300,
                temperature: 0.1
            });

            if (result.success) {
                return {
                    success: true,
                    answer: result.response.trim(),
                    question: question,
                    confidence: this._calculateConfidence(result.response),
                    source: 'document'
                };
            }

            return {
                success: false,
                error: 'Impossible de r√©pondre √† la question'
            };

        } catch (error) {
            console.error('‚ùå Erreur Q&A document:', error.message);
            return {
                success: false,
                error: error.message
            };
        }
    }

    /**
     * Obtient les informations du mod√®le
     */
    getModelInfo() {
        return {
            name: this.model,
            available: this.availableModels.some(m => m.name === this.model),
            allModels: this.availableModels.map(m => ({
                name: m.name,
                size: m.size,
                sizeFormatted: `${Math.round(m.size / 1024 / 1024)}MB`,
                modifiedAt: m.modified_at
            }))
        };
    }

    /**
     * Change le mod√®le actif
     */
    async setModel(modelName) {
        try {
            // V√©rifier que le mod√®le existe
            const modelExists = this.availableModels.some(m => m.name === modelName);
            
            if (!modelExists) {
                throw new Error(`Mod√®le ${modelName} non disponible`);
            }
            
            this.model = modelName;
            console.log(`üîÑ Mod√®le Ollama chang√© vers: ${modelName}`);
            
            return {
                success: true,
                model: modelName,
                previousModel: this.previousModel
            };
        } catch (error) {
            console.error('‚ùå Erreur changement mod√®le:', error.message);
            return {
                success: false,
                error: error.message
            };
        }
    }

    /**
     * Obtient les statistiques du service
     */
    getStatistics() {
        const successRate = this.stats.totalRequests > 0 
            ? (this.stats.successfulRequests / this.stats.totalRequests * 100).toFixed(1)
            : 0;

        return {
            initialized: this.initialized,
            connection: this.connectionStatus,
            stats: {
                totalRequests: this.stats.totalRequests,
                successfulRequests: this.stats.successfulRequests,
                failedRequests: this.stats.failedRequests,
                successRate: `${successRate}%`,
                totalTokens: this.stats.totalTokens,
                averageResponseTime: Math.round(this.stats.averageResponseTime)
            },
            model: this.getModelInfo(),
            timestamp: new Date().toISOString()
        };
    }

    /**
     * Reset les statistiques
     */
    resetStatistics() {
        this.stats = {
            totalRequests: 0,
            successfulRequests: 0,
            failedRequests: 0,
            totalTokens: 0,
            averageResponseTime: 0
        };
        
        console.log('üìä Statistiques Ollama r√©initialis√©es');
        return { success: true };
    }

    // ==================== M√âTHODES PRIV√âES ====================

    /**
     * Met √† jour le temps de r√©ponse moyen
     */
    _updateAverageResponseTime(responseTime) {
        if (this.stats.averageResponseTime === 0) {
            this.stats.averageResponseTime = responseTime;
        } else {
            // Moyenne mobile simple
            this.stats.averageResponseTime = 
                (this.stats.averageResponseTime + responseTime) / 2;
        }
    }

    /**
     * Calcule un score de confiance bas√© sur la r√©ponse
     */
    _calculateConfidence(response) {
        // Heuristiques simples pour estimer la confiance
        let confidence = 0.5;
        
        if (response.includes('Je ne sais pas') || response.includes('inconnu')) {
            confidence = 0.2;
        } else if (response.length > 50) {
            confidence = 0.8;
        } else if (response.length > 20) {
            confidence = 0.6;
        }
        
        return confidence;
    }

    /**
     * Formatte les erreurs pour la compatibilit√© avec aiService
     */
    _formatError(error) {
        return {
            success: false,
            response: 'Une erreur s\'est produite avec le service Ollama.',
            error: error.message,
            confidence: 0,
            timestamp: new Date().toISOString()
        };
    }
}

// Export pour utilisation dans aiService.js
module.exports = new OllamaService();