# Guide Complet de Configuration Production
## RDS Viewer Anecoop - Version 3.0.27

**Date de cr√©ation :** 2025-11-04  
**Environnement :** Production  
**Derni√®re mise √† jour :** 2025-11-04

---

## Table des Mati√®res

1. [Configuration Initiale de la Base de Donn√©es](#1-configuration-initiale-de-la-base-de-donn√©es)
2. [Configuration des Services IA](#2-configuration-des-services-ia)
3. [Configuration des Variables d'Environnement Production](#3-configuration-des-variables-denvironnement-production)
4. [Optimisations de Performance](#4-optimisations-de-performance)
5. [Configuration de la S√©curit√©](#5-configuration-de-la-s√©curit√©)
6. [Configuration des Sauvegardes Automatiques](#6-configuration-des-sauvegardes-automatiques)
7. [Configuration des Logs et Monitoring](#7-configuration-des-logs-et-monitoring)
8. [Configuration des Notifications et Alertes](#8-configuration-des-notifications-et-alertes)
9. [Checklist de D√©ploiement](#9-checklist-de-d√©ploiement)
10. [D√©pannage et Maintenance](#10-d√©pannage-et-maintenance)

---

## 1. Configuration Initiale de la Base de Donn√©es

### 1.1 Emplacement de la Base de Donn√©es

La base de donn√©es SQLite principale doit √™tre configur√©e dans un emplacement accessible et s√©curis√© :

```json
{
  "database": {
    "mode": "production",
    "path": "./data/docucortex.db",
    "backupPath": "./backups/",
    "maxConnections": 10
  }
}
```

**Recommandations d'emplacement :**

- **Production locale :** `./data/docucortex.db` (relatif √† l'application)
- **Production r√©seau :** Utiliser un chemin r√©seau partag√© si disponible
- **Permissions :** Acc√®s en lecture/√©criture pour l'utilisateur de l'application uniquement

### 1.2 Optimisations SQLite pour Production

#### Configuration dans `config/production.json`

```json
{
  "database": {
    "vacuumEnabled": true,
    "indexesEnabled": true,
    "maxConnections": 10
  }
}
```

#### Optimisations SQL √† Appliquer

Ex√©cuter le script `scripts/optimize-production.sql` lors du d√©ploiement initial :

```sql
-- Activer les optimisations de performance
PRAGMA journal_mode = WAL;
PRAGMA synchronous = NORMAL;
PRAGMA cache_size = 10000;
PRAGMA temp_store = MEMORY;
PRAGMA mmap_size = 268435456;

-- Optimisation du journal
PRAGMA wal_autocheckpoint = 1000;

-- Activer l'auto-vacuum incr√©mental
PRAGMA auto_vacuum = INCREMENTAL;
```

#### Script de Maintenance Automatique

Le fichier `scripts/optimize-database.js` doit √™tre ex√©cut√© p√©riodiquement :

```bash
# Ex√©cution manuelle
node scripts/optimize-database.js

# Ou via le syst√®me de monitoring (voir section 7)
```

### 1.3 Structure des Donn√©es

**R√©pertoires requis :**

```
./data/
‚îú‚îÄ‚îÄ docucortex.db          # Base principale
‚îú‚îÄ‚îÄ ai/                    # Cache AI et embeddings
‚îÇ   ‚îî‚îÄ‚îÄ cache/
‚îú‚îÄ‚îÄ cache/                 # Cache g√©n√©ral
‚îú‚îÄ‚îÄ ged/                   # Documents GED index√©s
‚îÇ   ‚îú‚îÄ‚îÄ index/
‚îÇ   ‚îî‚îÄ‚îÄ temp/
‚îî‚îÄ‚îÄ ocr/                   # R√©sultats OCR temporaires
    ‚îî‚îÄ‚îÄ temp/
```

**Cr√©ation des r√©pertoires :**

```bash
mkdir -p data/ai/cache
mkdir -p data/cache
mkdir -p data/ged/index
mkdir -p data/ged/temp
mkdir -p data/ocr/temp
mkdir -p backups
mkdir -p logs
```

---

## 2. Configuration des Services IA

### 2.1 Ollama Configuration

#### Installation d'Ollama

**Windows :**
```bash
# T√©l√©charger depuis https://ollama.ai
# Ou utiliser le script d'installation
node scripts/install-ollama.js
```

**Linux :**
```bash
curl -fsSL https://ollama.ai/install.sh | sh
```

#### Configuration du Service Ollama

```json
{
  "ai": {
    "provider": "ollama",
    "model": "llama3.2:3b",
    "maxTokens": 2048,
    "temperature": 0.7,
    "timeout": 30000,
    "cache": true,
    "cacheTTL": 3600
  }
}
```

#### D√©marrage d'Ollama

**En tant que service (recommand√©) :**
```bash
# Windows (PowerShell en administrateur)
ollama serve

# Linux (systemd)
sudo systemctl enable ollama
sudo systemctl start ollama
```

**Variables d'environnement Ollama :**

```bash
# .env.production
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODELS_PATH=C:/Users/[User]/.ollama/models  # Windows
# ou
OLLAMA_MODELS_PATH=/usr/share/ollama/models        # Linux
```

#### T√©l√©chargement des Mod√®les

```bash
# Mod√®le principal (recommand√© pour production)
ollama pull llama3.2:3b

# Mod√®les alternatifs (optionnels)
ollama pull mistral:7b
ollama pull phi3:mini
```

#### Test de Connexion

```bash
curl http://localhost:11434/api/generate -d '{
  "model": "llama3.2:3b",
  "prompt": "Test de connexion",
  "stream": false
}'
```

### 2.2 EasyOCR Configuration

#### Installation des D√©pendances

```bash
# Via npm (d√©j√† inclus dans package.json)
npm install easyocr-node
```

#### Configuration OCR

```json
{
  "ocr": {
    "enabled": true,
    "languages": ["fr", "en", "es"],
    "maxFileSize": 104857600,
    "timeout": 60000,
    "confidence": 0.8
  }
}
```

**Variables d'environnement :**

```bash
OCR_ENABLED=true
OCR_LANGUAGES=fr,en,es
OCR_MAX_FILE_SIZE=104857600  # 100MB
OCR_TIMEOUT=60000            # 60 secondes
OCR_CONFIDENCE=0.8           # Seuil de confiance minimum
```

#### Optimisations OCR

- **GPU :** Si disponible, EasyOCR utilisera automatiquement le GPU
- **M√©moire :** Pr√©voir au minimum 4GB de RAM pour OCR
- **Langues :** Limiter aux langues strictement n√©cessaires

### 2.3 DocuCortex Configuration

DocuCortex est le syst√®me de gestion documentaire int√©gr√©.

#### Configuration GED

```json
{
  "ged": {
    "enabled": true,
    "networkPath": "\\\\192.168.1.230\\Donnees",
    "workingDirectory": "./data/ged/",
    "autoIndex": true,
    "scanInterval": 30,
    "maxSearchResults": 10,
    "embeddingModel": "local",
    "supportedExtensions": [
      "pdf", "docx", "xlsx", "txt", "md", 
      "jpg", "png", "pptx"
    ]
  }
}
```

#### Configuration du Chemin R√©seau

**Windows :**
```bash
# Format UNC
GED_NETWORK_PATH=\\\\192.168.1.230\\Donnees

# Avec authentification (si n√©cessaire)
net use \\192.168.1.230\Donnees /user:DOMAIN\username password
```

**Linux (Samba) :**
```bash
# Monter le partage
sudo mkdir -p /mnt/ged
sudo mount -t cifs //192.168.1.230/Donnees /mnt/ged -o username=user,password=pass

# Configuration permanente dans /etc/fstab
//192.168.1.230/Donnees /mnt/ged cifs credentials=/root/.smbcredentials,uid=1000,gid=1000 0 0
```

#### Indexation Automatique

L'indexation se fait automatiquement toutes les 30 minutes (configurable via `scanInterval`).

**D√©clenchement manuel :**
```bash
# Via l'API
curl -X POST http://localhost:3001/api/ged/reindex
```

---

## 3. Configuration des Variables d'Environnement Production

### 3.1 Fichier .env.production

Cr√©er/modifier le fichier `.env.production` √† la racine du projet :

```bash
# ==================
# Configuration Serveur
# ==================
NODE_ENV=production
PORT=3001
HOST=localhost
MAX_CONNECTIONS=100
TIMEOUT=30000

# ==================
# Base de Donn√©es
# ==================
DB_PATH=./data/docucortex.db
DB_BACKUP_PATH=./backups/
DB_AUTO_BACKUP=true
DB_BACKUP_INTERVAL=24
DB_VACUUM_ENABLED=true
DB_INDEXES_ENABLED=true

# ==================
# IA et OCR
# ==================
AI_PROVIDER=ollama
AI_MODEL=llama3.2:3b
AI_MAX_TOKENS=2048
AI_TIMEOUT=30000
AI_CACHE=true
AI_CACHE_TTL=3600

OCR_ENABLED=true
OCR_LANGUAGES=fr,en,es
OCR_MAX_FILE_SIZE=104857600
OCR_TIMEOUT=60000
OCR_CONFIDENCE=0.8

# ==================
# GED
# ==================
GED_ENABLED=true
GED_NETWORK_PATH=\\\\192.168.1.230\\Donnees
GED_WORKING_DIR=./data/ged/
GED_AUTO_INDEX=true
GED_SCAN_INTERVAL=30
GED_MAX_SEARCH_RESULTS=10

# ==================
# S√©curit√©
# ==================
SESSION_SECRET=CHANGE_ME_IN_PRODUCTION_USE_STRONG_SECRET
JWT_SECRET=CHANGE_ME_IN_PRODUCTION_USE_STRONG_JWT_SECRET
SESSION_TIMEOUT=3600
MAX_LOGIN_ATTEMPTS=5
LOCKOUT_DURATION=300
PASSWORD_MIN_LENGTH=8
ENABLE_MFA=false
RATE_LIMITING_ENABLED=true

# ==================
# SSL/TLS (si activ√©)
# ==================
HTTPS_ENABLED=false
SSL_CERT_PATH=./certs/server.crt
SSL_KEY_PATH=./certs/server.key

# ==================
# Performance
# ==================
CACHE_ENABLED=true
CACHE_TTL=3600
CACHE_MAX_SIZE=104857600
COMPRESSION_ENABLED=true
GZIP_ENABLED=true
LAZY_LOADING=true
BUNDLE_OPTIMIZATION=true

# ==================
# Monitoring et Logs
# ==================
LOG_LEVEL=info
LOG_MAX_SIZE=10485760
LOG_RETENTION_DAYS=7
HEALTH_CHECK_ENABLED=true
HEALTH_CHECK_INTERVAL=30000

# ==================
# Application
# ==================
APP_NAME=RDS Viewer Anecoop
APP_VERSION=3.0.27
APP_ENV=production
```

### 3.2 S√©curisation des Variables

**‚ö†Ô∏è IMPORTANT : Ne jamais committer .env.production dans Git !**

Ajouter dans `.gitignore` :
```
.env.production
.env.local
.env.*.local
*.key
*.pem
*.crt
```

### 3.3 G√©n√©ration de Secrets S√©curis√©s

```bash
# G√©n√©rer un secret fort (Node.js)
node -e "console.log(require('crypto').randomBytes(64).toString('hex'))"

# Ou avec OpenSSL
openssl rand -hex 64
```

**Remplacer les secrets par d√©faut :**
```bash
SESSION_SECRET=[votre_secret_g√©n√©r√©_ici]
JWT_SECRET=[votre_jwt_secret_g√©n√©r√©_ici]
```

---

## 4. Optimisations de Performance

### 4.1 Configuration du Cache

#### Cache M√©moire

```json
{
  "performance": {
    "cache": {
      "enabled": true,
      "ttl": 3600,
      "maxSize": 104857600
    }
  }
}
```

**Strat√©gies de cache :**

- **Donn√©es statiques :** TTL de 3600s (1h)
- **Donn√©es dynamiques :** TTL de 300s (5min)
- **R√©sultats AI :** TTL de 3600s avec invalidation intelligente
- **R√©sultats OCR :** TTL de 86400s (24h)

#### Cache Disque

R√©pertoire : `./data/cache/`

**Nettoyage automatique :**
```javascript
// Configurer dans monitoring
const cacheCleanupInterval = 24 * 60 * 60 * 1000; // 24h
```

### 4.2 Optimisation M√©moire

#### Allocation M√©moire Node.js

```bash
# D√©marrage avec allocation m√©moire optimis√©e
node --max-old-space-size=4096 server/server.js
```

**Dans package.json :**
```json
{
  "scripts": {
    "start:prod": "NODE_ENV=production node --max-old-space-size=4096 server/server.js"
  }
}
```

#### Limites Recommand√©es

- **Minimum :** 2GB RAM
- **Recommand√© :** 4GB RAM
- **Optimal :** 8GB RAM (avec OCR et IA actifs)

### 4.3 Optimisation Processeurs

#### Workers Thread Pool

```javascript
// Configuration dans server.js
const os = require('os');
const numCPUs = os.cpus().length;

// Utiliser 75% des CPU disponibles
process.env.UV_THREADPOOL_SIZE = Math.max(4, Math.floor(numCPUs * 0.75));
```

#### Configuration Recommand√©e

- **CPU minimum :** 2 c≈ìurs
- **CPU recommand√© :** 4 c≈ìurs
- **CPU optimal :** 8+ c≈ìurs (pour AI et OCR parall√®les)

### 4.4 Compression et Optimisation R√©seau

```json
{
  "performance": {
    "compression": true,
    "gzip": true
  }
}
```

**Configuration Express :**
```javascript
const compression = require('compression');
app.use(compression({
  level: 6,
  threshold: 1024,
  filter: (req, res) => {
    if (req.headers['x-no-compression']) {
      return false;
    }
    return compression.filter(req, res);
  }
}));
```

### 4.5 Lazy Loading et Bundle Optimization

```json
{
  "performance": {
    "lazyLoading": true,
    "bundleOptimization": true
  }
}
```

**Webpack Configuration :**
```javascript
module.exports = {
  optimization: {
    splitChunks: {
      chunks: 'all',
      cacheGroups: {
        vendors: {
          test: /[\\/]node_modules[\\/]/,
          priority: -10
        }
      }
    }
  }
};
```

---

## 5. Configuration de la S√©curit√©

### 5.1 Configuration JWT

#### G√©n√©ration des Secrets

```bash
# G√©n√©rer une cl√© JWT s√©curis√©e
openssl rand -base64 64 > jwt-secret.key
```

#### Configuration JWT

```json
{
  "security": {
    "jwt": {
      "secret": "VOIR_.env.production",
      "expiresIn": "24h",
      "algorithm": "HS256",
      "issuer": "RDS-Viewer-Anecoop"
    }
  }
}
```

**Variables d'environnement :**
```bash
JWT_SECRET=votre_secret_jwt_ultra_securise_ici
JWT_EXPIRES_IN=24h
JWT_ALGORITHM=HS256
```

### 5.2 Configuration des Sessions

```json
{
  "security": {
    "sessionTimeout": 3600,
    "maxLoginAttempts": 5,
    "lockoutDuration": 300
  }
}
```

**Configuration Express-Session :**
```javascript
const session = require('express-session');
const SQLiteStore = require('connect-sqlite3')(session);

app.use(session({
  store: new SQLiteStore({
    db: 'sessions.db',
    dir: './data'
  }),
  secret: process.env.SESSION_SECRET,
  resave: false,
  saveUninitialized: false,
  cookie: {
    secure: process.env.HTTPS_ENABLED === 'true',
    httpOnly: true,
    maxAge: 3600000, // 1 heure
    sameSite: 'strict'
  }
}));
```

### 5.3 Configuration SSL/TLS

#### G√©n√©ration des Certificats (Auto-sign√©s pour test)

```bash
# Cr√©er le r√©pertoire des certificats
mkdir -p certs

# G√©n√©rer une cl√© priv√©e
openssl genrsa -out certs/server.key 2048

# G√©n√©rer un certificat auto-sign√©
openssl req -new -x509 -key certs/server.key -out certs/server.crt -days 365
```

#### Configuration HTTPS

```javascript
// server.js
const https = require('https');
const fs = require('fs');

if (process.env.HTTPS_ENABLED === 'true') {
  const httpsOptions = {
    key: fs.readFileSync(process.env.SSL_KEY_PATH),
    cert: fs.readFileSync(process.env.SSL_CERT_PATH)
  };
  
  const httpsServer = https.createServer(httpsOptions, app);
  httpsServer.listen(443, () => {
    console.log('‚úÖ Serveur HTTPS d√©marr√© sur le port 443');
  });
}
```

**Variables d'environnement :**
```bash
HTTPS_ENABLED=true
SSL_CERT_PATH=./certs/server.crt
SSL_KEY_PATH=./certs/server.key
```

### 5.4 Rate Limiting

```json
{
  "security": {
    "rateLimiting": {
      "enabled": true,
      "windowMs": 900000,
      "max": 100
    }
  }
}
```

**Impl√©mentation Express :**
```javascript
const rateLimit = require('express-rate-limit');

const limiter = rateLimit({
  windowMs: 15 * 60 * 1000, // 15 minutes
  max: 100, // limite de 100 requ√™tes par fen√™tre
  message: 'Trop de requ√™tes depuis cette IP, veuillez r√©essayer plus tard.',
  standardHeaders: true,
  legacyHeaders: false,
});

app.use('/api/', limiter);
```

### 5.5 S√©curit√© des Headers

```javascript
const helmet = require('helmet');

app.use(helmet({
  contentSecurityPolicy: {
    directives: {
      defaultSrc: ["'self'"],
      scriptSrc: ["'self'", "'unsafe-inline'"],
      styleSrc: ["'self'", "'unsafe-inline'"],
      imgSrc: ["'self'", "data:", "https:"],
    }
  },
  hsts: {
    maxAge: 31536000,
    includeSubDomains: true,
    preload: true
  }
}));
```

### 5.6 Protection des Mots de Passe

```javascript
const bcrypt = require('bcrypt');
const SALT_ROUNDS = 12;

async function hashPassword(password) {
  return await bcrypt.hash(password, SALT_ROUNDS);
}

async function verifyPassword(password, hash) {
  return await bcrypt.compare(password, hash);
}
```

**Configuration minimum :**
```bash
PASSWORD_MIN_LENGTH=8
PASSWORD_REQUIRE_UPPERCASE=true
PASSWORD_REQUIRE_LOWERCASE=true
PASSWORD_REQUIRE_NUMBERS=true
PASSWORD_REQUIRE_SPECIAL=true
```

---

## 6. Configuration des Sauvegardes Automatiques

### 6.1 Configuration des Sauvegardes

```json
{
  "database": {
    "backupPath": "./backups/",
    "autoBackup": true,
    "backupInterval": 24
  }
}
```

**Variables d'environnement :**
```bash
DB_BACKUP_PATH=./backups/
DB_AUTO_BACKUP=true
DB_BACKUP_INTERVAL=24  # Heures entre chaque sauvegarde
BACKUP_RETENTION_DAYS=30
BACKUP_COMPRESSION=true
```

### 6.2 Strat√©gie de Sauvegarde

#### Sauvegardes Automatiques Quotidiennes

**Planification :**
- **Quotidienne :** 02:00 AM (heure locale)
- **Hebdomadaire :** Dimanche 03:00 AM (copie compl√®te)
- **Mensuelle :** 1er du mois 04:00 AM (archivage)

#### Script de Sauvegarde

Cr√©er `scripts/backup-database.js` :

```javascript
const fs = require('fs');
const path = require('path');
const { execSync } = require('child_process');

function backupDatabase() {
  const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
  const dbPath = process.env.DB_PATH || './data/docucortex.db';
  const backupDir = process.env.DB_BACKUP_PATH || './backups/';
  const backupFile = path.join(backupDir, `docucortex-${timestamp}.db`);
  
  // Cr√©er le r√©pertoire de sauvegarde si n√©cessaire
  if (!fs.existsSync(backupDir)) {
    fs.mkdirSync(backupDir, { recursive: true });
  }
  
  // Copier la base de donn√©es
  fs.copyFileSync(dbPath, backupFile);
  
  // Compression (optionnel)
  if (process.env.BACKUP_COMPRESSION === 'true') {
    execSync(`gzip ${backupFile}`);
    console.log(`‚úÖ Sauvegarde cr√©√©e et compress√©e: ${backupFile}.gz`);
  } else {
    console.log(`‚úÖ Sauvegarde cr√©√©e: ${backupFile}`);
  }
  
  // Nettoyage des anciennes sauvegardes
  cleanupOldBackups(backupDir);
}

function cleanupOldBackups(backupDir) {
  const retentionDays = parseInt(process.env.BACKUP_RETENTION_DAYS || '30');
  const now = Date.now();
  const maxAge = retentionDays * 24 * 60 * 60 * 1000;
  
  const files = fs.readdirSync(backupDir);
  files.forEach(file => {
    const filePath = path.join(backupDir, file);
    const stats = fs.statSync(filePath);
    const age = now - stats.mtimeMs;
    
    if (age > maxAge) {
      fs.unlinkSync(filePath);
      console.log(`üóëÔ∏è  Sauvegarde supprim√©e (trop ancienne): ${file}`);
    }
  });
}

// Ex√©cution
backupDatabase();
```

### 6.3 Planification avec Cron (Linux)

```bash
# √âditer crontab
crontab -e

# Ajouter les t√¢ches de sauvegarde
0 2 * * * cd /path/to/rdp && node scripts/backup-database.js >> logs/backup.log 2>&1
0 3 * * 0 cd /path/to/rdp && node scripts/backup-database.js --full >> logs/backup.log 2>&1
```

### 6.4 Planification avec Task Scheduler (Windows)

```powershell
# Cr√©er une t√¢che planifi√©e
$action = New-ScheduledTaskAction -Execute "node" -Argument "scripts/backup-database.js" -WorkingDirectory "C:\path\to\rdp"
$trigger = New-ScheduledTaskTrigger -Daily -At 2am
$settings = New-ScheduledTaskSettingsSet -StartWhenAvailable
Register-ScheduledTask -TaskName "RDS Viewer Backup" -Action $action -Trigger $trigger -Settings $settings
```

### 6.5 Sauvegarde R√©seau

**Configuration :**
```bash
# Copier vers un emplacement r√©seau
BACKUP_NETWORK_PATH=\\\\192.168.1.230\\Backups\\RDS-Viewer
BACKUP_NETWORK_ENABLED=true
```

**Script de copie r√©seau :**
```javascript
function copyToNetworkBackup(localBackupFile) {
  const networkPath = process.env.BACKUP_NETWORK_PATH;
  if (process.env.BACKUP_NETWORK_ENABLED === 'true' && networkPath) {
    const fileName = path.basename(localBackupFile);
    const networkFile = path.join(networkPath, fileName);
    fs.copyFileSync(localBackupFile, networkFile);
    console.log(`‚úÖ Sauvegarde copi√©e sur le r√©seau: ${networkFile}`);
  }
}
```

### 6.6 Restauration de Sauvegarde

**Script de restauration :**
```javascript
// scripts/restore-database.js
function restoreDatabase(backupFile) {
  const dbPath = process.env.DB_PATH || './data/docucortex.db';
  
  // Cr√©er une sauvegarde de s√©curit√© avant restauration
  const safetyBackup = `${dbPath}.pre-restore.${Date.now()}`;
  if (fs.existsSync(dbPath)) {
    fs.copyFileSync(dbPath, safetyBackup);
    console.log(`‚úÖ Sauvegarde de s√©curit√© cr√©√©e: ${safetyBackup}`);
  }
  
  // Restaurer
  fs.copyFileSync(backupFile, dbPath);
  console.log(`‚úÖ Base de donn√©es restaur√©e depuis: ${backupFile}`);
}
```

---

## 7. Configuration des Logs et Monitoring

### 7.1 Configuration des Logs

```json
{
  "monitoring": {
    "enabled": true,
    "logLevel": "info",
    "maxLogSize": 10485760,
    "logRetention": 7
  }
}
```

**Variables d'environnement :**
```bash
LOG_LEVEL=info          # debug, info, warn, error
LOG_MAX_SIZE=10485760   # 10MB
LOG_RETENTION_DAYS=7
LOG_PATH=./logs/
```

### 7.2 Niveaux de Logs

**Hi√©rarchie des niveaux :**
1. **debug** - Informations d√©taill√©es de d√©bogage
2. **info** - Informations g√©n√©rales
3. **warn** - Avertissements
4. **error** - Erreurs critiques

**Environnements recommand√©s :**
- **Production :** `info` ou `warn`
- **D√©veloppement :** `debug`
- **Test :** `error`

### 7.3 Structure des Logs

```
./logs/
‚îú‚îÄ‚îÄ application.log         # Log g√©n√©ral de l'application
‚îú‚îÄ‚îÄ error.log              # Erreurs uniquement
‚îú‚îÄ‚îÄ access.log             # Logs d'acc√®s HTTP
‚îú‚îÄ‚îÄ database.log           # Op√©rations base de donn√©es
‚îú‚îÄ‚îÄ ai.log                 # Op√©rations IA
‚îú‚îÄ‚îÄ ocr.log                # Op√©rations OCR
‚îî‚îÄ‚îÄ security.log           # √âv√©nements de s√©curit√©
```

### 7.4 Impl√©mentation Winston

```javascript
// backend/utils/logger.js
const winston = require('winston');
const path = require('path');

const logFormat = winston.format.combine(
  winston.format.timestamp({ format: 'YYYY-MM-DD HH:mm:ss' }),
  winston.format.errors({ stack: true }),
  winston.format.printf(({ timestamp, level, message, stack }) => {
    return `${timestamp} [${level.toUpperCase()}]: ${message}${stack ? '\n' + stack : ''}`;
  })
);

const logger = winston.createLogger({
  level: process.env.LOG_LEVEL || 'info',
  format: logFormat,
  transports: [
    new winston.transports.File({ 
      filename: path.join(process.env.LOG_PATH || './logs', 'error.log'),
      level: 'error',
      maxsize: parseInt(process.env.LOG_MAX_SIZE || '10485760'),
      maxFiles: 5
    }),
    new winston.transports.File({ 
      filename: path.join(process.env.LOG_PATH || './logs', 'application.log'),
      maxsize: parseInt(process.env.LOG_MAX_SIZE || '10485760'),
      maxFiles: 5
    })
  ]
});

if (process.env.NODE_ENV !== 'production') {
  logger.add(new winston.transports.Console({
    format: winston.format.combine(
      winston.format.colorize(),
      logFormat
    )
  }));
}

module.exports = logger;
```

### 7.5 Rotation des Logs

**Configuration automatique :**
```javascript
const DailyRotateFile = require('winston-daily-rotate-file');

const transport = new DailyRotateFile({
  filename: 'logs/application-%DATE%.log',
  datePattern: 'YYYY-MM-DD',
  maxSize: '20m',
  maxFiles: '14d',
  zippedArchive: true
});

logger.add(transport);
```

### 7.6 Health Check et Monitoring

```json
{
  "monitoring": {
    "healthCheck": true,
    "healthInterval": 30000
  }
}
```

**Endpoint de Health Check :**
```javascript
// server/apiRoutes.js
app.get('/health', async (req, res) => {
  const health = {
    status: 'ok',
    timestamp: new Date().toISOString(),
    uptime: process.uptime(),
    memory: process.memoryUsage(),
    checks: {
      database: await checkDatabase(),
      ai: await checkAIService(),
      ocr: await checkOCRService(),
      ged: await checkGEDService()
    }
  };
  
  const allHealthy = Object.values(health.checks).every(c => c.status === 'ok');
  res.status(allHealthy ? 200 : 503).json(health);
});
```

### 7.7 M√©triques de Performance

**Collecte des m√©triques :**
```javascript
const metrics = {
  requests: {
    total: 0,
    success: 0,
    errors: 0
  },
  performance: {
    avgResponseTime: 0,
    maxResponseTime: 0
  },
  ai: {
    queries: 0,
    cacheHits: 0,
    cacheMisses: 0
  }
};

// Middleware de mesure
app.use((req, res, next) => {
  const startTime = Date.now();
  
  res.on('finish', () => {
    const duration = Date.now() - startTime;
    metrics.requests.total++;
    
    if (res.statusCode < 400) {
      metrics.requests.success++;
    } else {
      metrics.requests.errors++;
    }
    
    metrics.performance.avgResponseTime = 
      (metrics.performance.avgResponseTime + duration) / 2;
    metrics.performance.maxResponseTime = 
      Math.max(metrics.performance.maxResponseTime, duration);
  });
  
  next();
});

// Endpoint de m√©triques
app.get('/metrics', (req, res) => {
  res.json(metrics);
});
```

---

## 8. Configuration des Notifications et Alertes

### 8.1 Configuration des Notifications

Le syst√®me de notifications est g√©r√© par `backend/services/notificationService.js`.

```json
{
  "notifications": {
    "enabled": true,
    "channels": ["websocket", "email"],
    "priorities": {
      "critical": true,
      "warning": true,
      "info": false
    }
  }
}
```

### 8.2 Notifications WebSocket

**Configuration automatique via server.js :**
```javascript
// Les WebSocket sont configur√©s automatiquement
// Port: 3003 (par d√©faut)

function sendNotification(message, level = 'info') {
  const notification = {
    type: 'notification',
    level: level,
    message: message,
    timestamp: new Date().toISOString()
  };
  
  broadcast(notification);
}
```

### 8.3 Notifications Email (Optionnel)

**Installation :**
```bash
npm install nodemailer
```

**Configuration :**
```bash
# .env.production
EMAIL_ENABLED=true
EMAIL_HOST=smtp.gmail.com
EMAIL_PORT=587
EMAIL_SECURE=false
EMAIL_USER=votre.email@example.com
EMAIL_PASSWORD=votre_mot_de_passe_app
EMAIL_FROM=RDS Viewer <noreply@example.com>
EMAIL_TO=admin@example.com
```

**Impl√©mentation :**
```javascript
// backend/services/emailService.js
const nodemailer = require('nodemailer');

const transporter = nodemailer.createTransport({
  host: process.env.EMAIL_HOST,
  port: parseInt(process.env.EMAIL_PORT),
  secure: process.env.EMAIL_SECURE === 'true',
  auth: {
    user: process.env.EMAIL_USER,
    pass: process.env.EMAIL_PASSWORD
  }
});

async function sendEmail(subject, text, html) {
  if (process.env.EMAIL_ENABLED !== 'true') {
    return;
  }
  
  const mailOptions = {
    from: process.env.EMAIL_FROM,
    to: process.env.EMAIL_TO,
    subject: `[RDS Viewer] ${subject}`,
    text: text,
    html: html
  };
  
  try {
    await transporter.sendMail(mailOptions);
    console.log(`‚úÖ Email envoy√©: ${subject}`);
  } catch (error) {
    console.error(`‚ùå Erreur envoi email: ${error.message}`);
  }
}

module.exports = { sendEmail };
```

### 8.4 Alertes Syst√®me

**Types d'alertes :**

1. **Critique** - N√©cessite une action imm√©diate
   - √âchec de connexion base de donn√©es
   - Service IA indisponible
   - Espace disque critique
   - Erreurs de s√©curit√©

2. **Warning** - N√©cessite attention
   - Performance d√©grad√©e
   - Cache plein
   - Logs volumineux
   - Tentatives de connexion √©chou√©es

3. **Info** - Informations g√©n√©rales
   - Sauvegarde r√©ussie
   - Mise √† jour disponible
   - Statistiques quotidiennes

**Configuration des seuils :**
```javascript
const alertThresholds = {
  diskSpace: 10 * 1024 * 1024 * 1024, // 10GB minimum
  memoryUsage: 0.9, // 90% de la RAM
  cpuUsage: 0.85, // 85% du CPU
  responseTime: 5000, // 5 secondes
  errorRate: 0.05 // 5% d'erreurs
};
```

### 8.5 Monitoring Automatique

**Script de monitoring continu :**
```javascript
// scripts/monitor.js
const os = require('os');
const { sendEmail } = require('../backend/services/emailService');

async function monitorSystem() {
  // V√©rifier l'espace disque
  const diskSpace = await checkDiskSpace();
  if (diskSpace < alertThresholds.diskSpace) {
    sendAlert('CRITIQUE', `Espace disque faible: ${formatBytes(diskSpace)} restant`);
  }
  
  // V√©rifier la m√©moire
  const memUsage = (os.totalmem() - os.freemem()) / os.totalmem();
  if (memUsage > alertThresholds.memoryUsage) {
    sendAlert('WARNING', `Utilisation m√©moire √©lev√©e: ${(memUsage * 100).toFixed(1)}%`);
  }
  
  // V√©rifier les services
  const servicesStatus = await checkServices();
  Object.entries(servicesStatus).forEach(([service, status]) => {
    if (!status.healthy) {
      sendAlert('CRITIQUE', `Service ${service} indisponible: ${status.message}`);
    }
  });
}

function sendAlert(level, message) {
  console.log(`üö® [${level}] ${message}`);
  
  // Notification WebSocket
  sendNotification(message, level.toLowerCase());
  
  // Email pour alertes critiques
  if (level === 'CRITIQUE' && process.env.EMAIL_ENABLED === 'true') {
    sendEmail(`Alerte ${level}`, message, `<h2>${level}</h2><p>${message}</p>`);
  }
}

// Ex√©cuter toutes les 5 minutes
setInterval(monitorSystem, 5 * 60 * 1000);
```

---

## 9. Checklist de D√©ploiement

### 9.1 Pr√©-d√©ploiement

- [ ] **Configuration v√©rifi√©e**
  - [ ] `.env.production` cr√©√© et configur√©
  - [ ] `config/production.json` v√©rifi√©
  - [ ] Secrets JWT/Session g√©n√©r√©s et s√©curis√©s
  - [ ] Chemins r√©seau test√©s

- [ ] **Services externes**
  - [ ] Ollama install√© et mod√®les t√©l√©charg√©s
  - [ ] EasyOCR configur√©
  - [ ] Acc√®s r√©seau GED v√©rifi√©

- [ ] **Base de donn√©es**
  - [ ] R√©pertoires cr√©√©s (`data/`, `backups/`, `logs/`)
  - [ ] Scripts d'optimisation ex√©cut√©s
  - [ ] Permissions fichiers configur√©es

- [ ] **S√©curit√©**
  - [ ] Certificats SSL g√©n√©r√©s (si HTTPS)
  - [ ] Rate limiting configur√©
  - [ ] Headers de s√©curit√© activ√©s
  - [ ] Politique de mots de passe d√©finie

### 9.2 D√©ploiement

- [ ] **Installation**
  - [ ] D√©pendances install√©es (`npm install --production`)
  - [ ] Build production g√©n√©r√© (`npm run build`)
  - [ ] Tests ex√©cut√©s (`npm test`)

- [ ] **Configuration syst√®me**
  - [ ] Services Ollama d√©marr√©s
  - [ ] Permissions r√©seau configur√©es
  - [ ] Pare-feu configur√©

- [ ] **Lancement**
  - [ ] Application d√©marr√©e (`npm run start:prod`)
  - [ ] Health check v√©rifi√© (`curl http://localhost:3001/health`)
  - [ ] Logs v√©rifi√©s

### 9.3 Post-d√©ploiement

- [ ] **V√©rifications**
  - [ ] Connexion base de donn√©es OK
  - [ ] Services IA accessibles
  - [ ] OCR fonctionnel
  - [ ] GED accessible

- [ ] **Monitoring**
  - [ ] Logs actifs et lisibles
  - [ ] M√©triques collect√©es
  - [ ] Alertes configur√©es
  - [ ] Sauvegardes planifi√©es

- [ ] **Tests utilisateurs**
  - [ ] Authentification test√©e
  - [ ] Recherche test√©e
  - [ ] IA test√©e
  - [ ] OCR test√©

---

## 10. D√©pannage et Maintenance

### 10.1 Probl√®mes Courants

#### Base de Donn√©es Verrouill√©e

**Sympt√¥me :** `SQLITE_BUSY: database is locked`

**Solution :**
```bash
# V√©rifier les processus utilisant la DB
lsof | grep docucortex.db

# Red√©marrer l'application
npm run stop
npm run start:prod
```

#### Service Ollama Inaccessible

**Sympt√¥me :** `Error: connect ECONNREFUSED 127.0.0.1:11434`

**Solution :**
```bash
# V√©rifier si Ollama est en cours d'ex√©cution
curl http://localhost:11434/api/tags

# D√©marrer Ollama si n√©cessaire
ollama serve

# V√©rifier les logs
journalctl -u ollama -f  # Linux
Get-EventLog -LogName Application -Source Ollama  # Windows
```

#### Espace Disque Insuffisant

**Sympt√¥me :** Erreurs d'√©criture, sauvegardes √©chou√©es

**Solution :**
```bash
# Nettoyer les anciennes sauvegardes
node scripts/cleanup-backups.js

# Nettoyer le cache
rm -rf data/cache/*
rm -rf data/ocr/temp/*

# Vacuum la base de donn√©es
sqlite3 data/docucortex.db "VACUUM;"
```

#### Performance D√©grad√©e

**Sympt√¥me :** Requ√™tes lentes, timeouts

**Solution :**
```bash
# Optimiser la base de donn√©es
node scripts/optimize-database.js

# Vider le cache
curl -X POST http://localhost:3001/api/admin/clear-cache

# V√©rifier la m√©moire
node --max-old-space-size=8192 server/server.js
```

### 10.2 Maintenance R√©guli√®re

#### Quotidienne
- V√©rifier les logs d'erreurs
- V√©rifier l'√©tat des services (health check)
- V√©rifier l'espace disque

#### Hebdomadaire
- Analyser les m√©triques de performance
- V√©rifier les sauvegardes
- Nettoyer les fichiers temporaires

#### Mensuelle
- Mettre √† jour les d√©pendances (`npm update`)
- Vacuum complet de la base (`VACUUM FULL`)
- V√©rifier les certificats SSL
- Analyser les logs de s√©curit√©

#### Trimestrielle
- Audit de s√©curit√© complet
- Optimisation des index base de donn√©es
- R√©vision des permissions
- Mise √† jour des mod√®les IA

### 10.3 Scripts de Maintenance

**Cr√©er `scripts/maintenance.js` :**
```javascript
const tasks = {
  daily: [
    checkLogs,
    checkServices,
    checkDiskSpace
  ],
  weekly: [
    analyzeMetrics,
    verifyBackups,
    cleanTempFiles
  ],
  monthly: [
    updateDependencies,
    vacuumDatabase,
    checkCertificates,
    analyzeSecurityLogs
  ]
};

async function runMaintenance(frequency) {
  console.log(`üîß Ex√©cution de la maintenance ${frequency}...`);
  
  for (const task of tasks[frequency]) {
    try {
      await task();
      console.log(`‚úÖ ${task.name} termin√©`);
    } catch (error) {
      console.error(`‚ùå ${task.name} √©chou√©:`, error);
    }
  }
  
  console.log(`‚úÖ Maintenance ${frequency} termin√©e`);
}

module.exports = { runMaintenance };
```

### 10.4 Contact et Support

**Documentation :**
- Architecture : `docs/ARCHITECTURE_*.md`
- Tests : `docs/TESTS_*.md`
- D√©ploiement : `GUIDE_DEPLOIEMENT_PRODUCTION.md`

**Logs utiles :**
- Application : `logs/application.log`
- Erreurs : `logs/error.log`
- S√©curit√© : `logs/security.log`

**Commandes de diagnostic :**
```bash
# √âtat des services
npm run health-check

# V√©rifier la configuration
node scripts/check-config.js

# Tester les permissions
node scripts/check-permissions-structure.js

# Analyser les performances
node scripts/analyze-performance.js
```

---

## Annexes

### A. Variables d'Environnement Compl√®tes

Voir le fichier `.env.production` pour la liste compl√®te des variables disponibles.

### B. Ports Utilis√©s

| Service | Port | Description |
|---------|------|-------------|
| Backend API | 3001 | API REST principale |
| React Dev | 3000 | Interface utilisateur |
| API Routes | 3002 | Routes API additionnelles |
| WebSocket | 3003 | Communication temps r√©el |
| Ollama | 11434 | Service IA |

### C. Structure des Fichiers

```
rdp/
‚îú‚îÄ‚îÄ backend/          # Services backend
‚îú‚îÄ‚îÄ config/           # Fichiers de configuration
‚îú‚îÄ‚îÄ data/             # Donn√©es et cache
‚îú‚îÄ‚îÄ backups/          # Sauvegardes base de donn√©es
‚îú‚îÄ‚îÄ logs/             # Logs applicatifs
‚îú‚îÄ‚îÄ server/           # Serveur Express
‚îú‚îÄ‚îÄ src/              # Code source React
‚îú‚îÄ‚îÄ scripts/          # Scripts utilitaires
‚îú‚îÄ‚îÄ docs/             # Documentation
‚îî‚îÄ‚îÄ .env.production   # Variables d'environnement
```

### D. Ressources Syst√®me Recommand√©es

**Configuration Minimale :**
- CPU: 2 c≈ìurs
- RAM: 4 GB
- Disque: 20 GB
- R√©seau: 100 Mbps

**Configuration Recommand√©e :**
- CPU: 4 c≈ìurs
- RAM: 8 GB
- Disque: 50 GB SSD
- R√©seau: 1 Gbps

**Configuration Optimale :**
- CPU: 8+ c≈ìurs
- RAM: 16 GB
- Disque: 100 GB NVMe
- R√©seau: 1 Gbps+
- GPU: Recommand√© pour OCR

---

**Version du guide :** 1.0.0  
**Date de derni√®re mise √† jour :** 2025-11-04  
**Auteur :** √âquipe RDS Viewer Anecoop  
**License :** Propri√©taire - Usage interne uniquement

---

## Notes Importantes

‚ö†Ô∏è **S√âCURIT√â :** Ne jamais committer les fichiers `.env.production`, certificats, ou cl√©s priv√©es dans Git.

‚ö†Ô∏è **SAUVEGARDES :** V√©rifier r√©guli√®rement que les sauvegardes automatiques fonctionnent correctement.

‚ö†Ô∏è **MONITORING :** Configurer les alertes pour √™tre notifi√© imm√©diatement en cas de probl√®me critique.

‚ö†Ô∏è **MISES √Ä JOUR :** Tester toutes les mises √† jour dans un environnement de staging avant production.

---

*Pour toute question ou probl√®me, consulter d'abord la section D√©pannage et les logs applicatifs.*
