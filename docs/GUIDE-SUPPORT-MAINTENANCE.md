# üõ†Ô∏è Guide de Support et Maintenance - RDS Viewer Anecoop (DocuCortex IA)

**Version** : 3.0.31  
**Date de cr√©ation** : 2025-11-04  
**Application** : RDS Viewer Anecoop (DocuCortex IA)  
**Type** : Application Electron (React + Node.js + SQLite)

---

## üìã TABLE DES MATI√àRES

1. [Proc√©dures de Sauvegarde](#1-proc√©dures-de-sauvegarde)
2. [Proc√©dures de Restauration](#2-proc√©dures-de-restauration)
3. [Gestion des Mises √† Jour](#3-gestion-des-mises-√†-jour)
4. [Maintenance Pr√©ventive](#4-maintenance-pr√©ventive)
5. [Monitoring Continu](#5-monitoring-continu)
6. [Gestion des Logs](#6-gestion-des-logs)
7. [Proc√©dures d'Urgence](#7-proc√©dures-durgence)
8. [Contacts et Escalade](#8-contacts-et-escalade)
9. [Checklists de Maintenance](#9-checklists-de-maintenance)

---

## 1. PROC√âDURES DE SAUVEGARDE

### 1.1 Sauvegarde Manuelle

#### 1.1.1 Sauvegarde de la Base de Donn√©es

**Localisation** : `data/database.sqlite` (ou selon configuration)

**Proc√©dure** :

```bash
# 1. Arr√™ter l'application (recommand√©)
# Depuis l'interface : Menu ‚Üí Quitter

# 2. Cr√©er une sauvegarde avec horodatage
cd /chemin/vers/application
mkdir -p backups/manual
cp data/database.sqlite backups/manual/database-$(date +%Y%m%d-%H%M%S).sqlite

# 3. V√©rifier l'int√©grit√©
sqlite3 backups/manual/database-*.sqlite "PRAGMA integrity_check;"
```

**R√©sultat attendu** : `ok`

#### 1.1.2 Sauvegarde des Fichiers de Configuration

```bash
# Sauvegarder les configurations
tar -czf backups/manual/config-$(date +%Y%m%d-%H%M%S).tar.gz \
    config/*.json \
    config/*.yml \
    .env
```

#### 1.1.3 Sauvegarde des Documents GED

```bash
# Sauvegarder les fichiers GED
tar -czf backups/manual/ged-$(date +%Y%m%d-%H%M%S).tar.gz \
    data/ged/ \
    --exclude='*.tmp'
```

#### 1.1.4 Sauvegarde des Logs Critiques

```bash
# Archiver les logs importants
tar -czf backups/manual/logs-$(date +%Y%m%d-%H%M%S).tar.gz \
    logs/*.log \
    logs/permissions-validation/
```

#### 1.1.5 Sauvegarde Compl√®te du Syst√®me

```bash
# Script de sauvegarde compl√®te
#!/bin/bash
BACKUP_DIR="backups/manual/full-$(date +%Y%m%d-%H%M%S)"
mkdir -p "$BACKUP_DIR"

# Arr√™ter l'application
echo "Arr√™t de l'application..."
# Commande d'arr√™t appropri√©e

# Sauvegarde compl√®te
echo "Sauvegarde en cours..."
cp -r data/ "$BACKUP_DIR/"
cp -r config/ "$BACKUP_DIR/"
cp -r logs/ "$BACKUP_DIR/"
cp package.json "$BACKUP_DIR/"
cp .env "$BACKUP_DIR/"

# Cr√©er une archive compress√©e
tar -czf "$BACKUP_DIR.tar.gz" "$BACKUP_DIR/"
rm -rf "$BACKUP_DIR"

echo "Sauvegarde compl√®te : $BACKUP_DIR.tar.gz"
```

### 1.2 Sauvegarde Automatique

#### 1.2.1 Configuration de la Sauvegarde Automatique

**Script** : `scripts/backup-auto.js`

```javascript
// scripts/backup-auto.js
const fs = require('fs');
const path = require('path');
const { exec } = require('child_process');

const BACKUP_CONFIG = {
  databasePath: './data/database.sqlite',
  backupDir: './backups/auto',
  retentionDays: 30,
  schedule: '0 2 * * *' // 2h du matin chaque jour
};

function performBackup() {
  const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
  const backupPath = path.join(
    BACKUP_CONFIG.backupDir,
    `database-${timestamp}.sqlite`
  );

  // Copier la base de donn√©es
  fs.copyFileSync(BACKUP_CONFIG.databasePath, backupPath);

  // V√©rifier l'int√©grit√©
  exec(`sqlite3 ${backupPath} "PRAGMA integrity_check;"`, (error, stdout) => {
    if (stdout.trim() === 'ok') {
      console.log(`‚úÖ Sauvegarde r√©ussie : ${backupPath}`);
      cleanOldBackups();
    } else {
      console.error(`‚ùå Erreur d'int√©grit√© : ${backupPath}`);
      fs.unlinkSync(backupPath);
    }
  });
}

function cleanOldBackups() {
  const cutoffDate = new Date();
  cutoffDate.setDate(cutoffDate.getDate() - BACKUP_CONFIG.retentionDays);

  fs.readdirSync(BACKUP_CONFIG.backupDir).forEach(file => {
    const filePath = path.join(BACKUP_CONFIG.backupDir, file);
    const stats = fs.statSync(filePath);
    
    if (stats.mtime < cutoffDate) {
      fs.unlinkSync(filePath);
      console.log(`üóëÔ∏è Suppression ancienne sauvegarde : ${file}`);
    }
  });
}

// Ex√©cution
if (require.main === module) {
  performBackup();
}

module.exports = { performBackup };
```

#### 1.2.2 Activation de la Sauvegarde Automatique

**Windows (Planificateur de t√¢ches)** :

```powershell
# Cr√©er une t√¢che planifi√©e
$action = New-ScheduledTaskAction -Execute "node" -Argument "C:\chemin\vers\scripts\backup-auto.js"
$trigger = New-ScheduledTaskTrigger -Daily -At 2am
$principal = New-ScheduledTaskPrincipal -UserId "SYSTEM" -LogonType ServiceAccount
$settings = New-ScheduledTaskSettingsSet -StartWhenAvailable -RestartCount 3

Register-ScheduledTask -TaskName "RDSViewer-Backup" `
  -Action $action `
  -Trigger $trigger `
  -Principal $principal `
  -Settings $settings `
  -Description "Sauvegarde automatique RDS Viewer"
```

**Linux (Cron)** :

```bash
# √âditer crontab
crontab -e

# Ajouter la ligne suivante (2h du matin chaque jour)
0 2 * * * cd /chemin/vers/application && /usr/bin/node scripts/backup-auto.js >> logs/backup.log 2>&1
```

### 1.3 Sauvegarde Planifi√©e (Multi-niveaux)

#### 1.3.1 Strat√©gie de Sauvegarde 3-2-1

- **3** copies des donn√©es (originale + 2 sauvegardes)
- **2** supports diff√©rents (local + r√©seau)
- **1** copie hors site (cloud ou serveur distant)

#### 1.3.2 Planification Recommand√©e

| Type | Fr√©quence | R√©tention | Destination |
|------|-----------|-----------|-------------|
| **Compl√®te** | Hebdomadaire (Dimanche 1h) | 4 semaines | Serveur r√©seau |
| **Diff√©rentielle** | Quotidienne (2h) | 7 jours | Disque local |
| **Incr√©mentale** | Toutes les 4h | 24h | Disque local |
| **Configuration** | Avant chaque mise √† jour | Permanent | Local + R√©seau |
| **GED** | Quotidienne (3h) | 30 jours | R√©seau + Cloud |

#### 1.3.3 Script de Sauvegarde Planifi√©e

```bash
#!/bin/bash
# scripts/backup-scheduled.sh

BACKUP_TYPE=$1  # full, diff, inc
TIMESTAMP=$(date +%Y%m%d-%H%M%S)
APP_DIR="/chemin/vers/application"
BACKUP_BASE="$APP_DIR/backups/scheduled"

case $BACKUP_TYPE in
  full)
    echo "üîÑ Sauvegarde compl√®te..."
    BACKUP_DIR="$BACKUP_BASE/full/backup-$TIMESTAMP"
    mkdir -p "$BACKUP_DIR"
    
    # Base de donn√©es
    cp "$APP_DIR/data/database.sqlite" "$BACKUP_DIR/"
    
    # Configuration
    cp -r "$APP_DIR/config" "$BACKUP_DIR/"
    
    # GED
    rsync -a --exclude='*.tmp' "$APP_DIR/data/ged/" "$BACKUP_DIR/ged/"
    
    # Logs essentiels
    cp -r "$APP_DIR/logs/permissions-validation" "$BACKUP_DIR/logs/"
    
    # Archive
    tar -czf "$BACKUP_BASE/full/backup-$TIMESTAMP.tar.gz" -C "$BACKUP_BASE/full" "backup-$TIMESTAMP"
    rm -rf "$BACKUP_DIR"
    
    # Copie r√©seau
    scp "$BACKUP_BASE/full/backup-$TIMESTAMP.tar.gz" backup-server:/backups/rds-viewer/
    
    echo "‚úÖ Sauvegarde compl√®te termin√©e"
    ;;
    
  diff)
    echo "üîÑ Sauvegarde diff√©rentielle..."
    # Trouver la derni√®re sauvegarde compl√®te
    LAST_FULL=$(ls -t $BACKUP_BASE/full/*.tar.gz | head -1)
    BACKUP_DIR="$BACKUP_BASE/diff/backup-$TIMESTAMP"
    mkdir -p "$BACKUP_DIR"
    
    # Fichiers modifi√©s depuis la derni√®re sauvegarde compl√®te
    find "$APP_DIR/data" -newer "$LAST_FULL" -type f -exec cp --parents {} "$BACKUP_DIR" \;
    
    tar -czf "$BACKUP_BASE/diff/backup-$TIMESTAMP.tar.gz" -C "$BACKUP_BASE/diff" "backup-$TIMESTAMP"
    rm -rf "$BACKUP_DIR"
    
    echo "‚úÖ Sauvegarde diff√©rentielle termin√©e"
    ;;
    
  inc)
    echo "üîÑ Sauvegarde incr√©mentale..."
    BACKUP_DIR="$BACKUP_BASE/inc/backup-$TIMESTAMP"
    mkdir -p "$BACKUP_DIR"
    
    # Uniquement la base de donn√©es
    cp "$APP_DIR/data/database.sqlite" "$BACKUP_DIR/"
    
    gzip "$BACKUP_DIR/database.sqlite"
    
    echo "‚úÖ Sauvegarde incr√©mentale termin√©e"
    ;;
    
  *)
    echo "‚ùå Usage: $0 {full|diff|inc}"
    exit 1
    ;;
esac

# Nettoyer les anciennes sauvegardes
find "$BACKUP_BASE/inc" -mtime +1 -delete
find "$BACKUP_BASE/diff" -mtime +7 -delete
find "$BACKUP_BASE/full" -mtime +28 -delete
```

#### 1.3.4 Configuration Cron Compl√®te

```bash
# Sauvegarde compl√®te hebdomadaire (Dimanche 1h)
0 1 * * 0 /chemin/vers/scripts/backup-scheduled.sh full >> /chemin/vers/logs/backup-scheduled.log 2>&1

# Sauvegarde diff√©rentielle quotidienne (2h)
0 2 * * 1-6 /chemin/vers/scripts/backup-scheduled.sh diff >> /chemin/vers/logs/backup-scheduled.log 2>&1

# Sauvegarde incr√©mentale (toutes les 4h)
0 */4 * * * /chemin/vers/scripts/backup-scheduled.sh inc >> /chemin/vers/logs/backup-scheduled.log 2>&1
```

### 1.4 V√©rification des Sauvegardes

#### 1.4.1 Checklist de V√©rification

```bash
# Script de v√©rification
#!/bin/bash
# scripts/verify-backup.sh

BACKUP_FILE=$1

echo "üîç V√©rification de la sauvegarde : $BACKUP_FILE"

# 1. V√©rifier l'existence
if [ ! -f "$BACKUP_FILE" ]; then
  echo "‚ùå Fichier introuvable"
  exit 1
fi

# 2. V√©rifier la taille (doit √™tre > 1MB)
SIZE=$(stat -f%z "$BACKUP_FILE" 2>/dev/null || stat -c%s "$BACKUP_FILE")
if [ $SIZE -lt 1048576 ]; then
  echo "‚ö†Ô∏è Taille suspecte : $SIZE octets"
fi

# 3. Extraire et v√©rifier l'int√©grit√©
TEMP_DIR=$(mktemp -d)
tar -xzf "$BACKUP_FILE" -C "$TEMP_DIR" 2>/dev/null

# 4. V√©rifier la base de donn√©es
DB_FILE=$(find "$TEMP_DIR" -name "database.sqlite" | head -1)
if [ -f "$DB_FILE" ]; then
  INTEGRITY=$(sqlite3 "$DB_FILE" "PRAGMA integrity_check;")
  if [ "$INTEGRITY" = "ok" ]; then
    echo "‚úÖ Base de donn√©es int√®gre"
  else
    echo "‚ùå Base de donn√©es corrompue"
    rm -rf "$TEMP_DIR"
    exit 1
  fi
else
  echo "‚ö†Ô∏è Base de donn√©es non trouv√©e"
fi

# 5. V√©rifier les fichiers essentiels
REQUIRED_FILES=("config/config.json" "package.json")
for FILE in "${REQUIRED_FILES[@]}"; do
  if [ ! -f "$TEMP_DIR/$FILE" ]; then
    echo "‚ö†Ô∏è Fichier manquant : $FILE"
  fi
done

rm -rf "$TEMP_DIR"
echo "‚úÖ V√©rification termin√©e avec succ√®s"
```

---

## 2. PROC√âDURES DE RESTAURATION

### 2.1 Restauration depuis Sauvegarde

#### 2.1.1 Pr√©paration

```bash
# 1. Arr√™ter l'application
# Menu ‚Üí Quitter ou :
pkill -f "RDS Viewer" || systemctl stop rds-viewer

# 2. Cr√©er une sauvegarde de l'√©tat actuel (par pr√©caution)
TIMESTAMP=$(date +%Y%m%d-%H%M%S)
cp -r data data.before-restore.$TIMESTAMP
```

#### 2.1.2 Restauration Compl√®te

```bash
#!/bin/bash
# scripts/restore-backup.sh

BACKUP_FILE=$1
RESTORE_DIR="/chemin/vers/application"

if [ -z "$BACKUP_FILE" ]; then
  echo "‚ùå Usage: $0 <fichier-sauvegarde.tar.gz>"
  exit 1
fi

echo "üîÑ Restauration depuis : $BACKUP_FILE"

# 1. V√©rifier la sauvegarde
./scripts/verify-backup.sh "$BACKUP_FILE"
if [ $? -ne 0 ]; then
  echo "‚ùå Sauvegarde invalide, restauration annul√©e"
  exit 1
fi

# 2. Cr√©er sauvegarde pr√©alable
echo "üì¶ Sauvegarde de l'√©tat actuel..."
TIMESTAMP=$(date +%Y%m%d-%H%M%S)
tar -czf "backups/before-restore-$TIMESTAMP.tar.gz" data/ config/

# 3. Extraire la sauvegarde
echo "üìÇ Extraction de la sauvegarde..."
TEMP_DIR=$(mktemp -d)
tar -xzf "$BACKUP_FILE" -C "$TEMP_DIR"

# 4. Restaurer la base de donn√©es
echo "üóÑÔ∏è Restauration de la base de donn√©es..."
cp "$TEMP_DIR"/*/database.sqlite "$RESTORE_DIR/data/"

# 5. Restaurer la configuration
echo "‚öôÔ∏è Restauration de la configuration..."
cp -r "$TEMP_DIR"/*/config/* "$RESTORE_DIR/config/"

# 6. Restaurer les fichiers GED
echo "üìö Restauration des fichiers GED..."
if [ -d "$TEMP_DIR"/*/ged ]; then
  cp -r "$TEMP_DIR"/*/ged/* "$RESTORE_DIR/data/ged/"
fi

# 7. V√©rifier l'int√©grit√© post-restauration
echo "üîç V√©rification de l'int√©grit√©..."
sqlite3 "$RESTORE_DIR/data/database.sqlite" "PRAGMA integrity_check;"

# 8. Nettoyer
rm -rf "$TEMP_DIR"

echo "‚úÖ Restauration termin√©e avec succ√®s"
echo "üöÄ Vous pouvez red√©marrer l'application"
```

#### 2.1.3 Restauration Partielle

**Restaurer uniquement la base de donn√©es** :

```bash
# Extraire uniquement la DB depuis une sauvegarde
tar -xzf backup-20251104-020000.tar.gz --strip-components=2 -C /tmp backup-20251104-020000/database.sqlite

# Arr√™ter l'application
pkill -f "RDS Viewer"

# Remplacer la DB
cp /tmp/database.sqlite data/

# V√©rifier
sqlite3 data/database.sqlite "PRAGMA integrity_check;"

# Red√©marrer
# Lancer l'application
```

**Restaurer uniquement la configuration** :

```bash
# Extraire la configuration
tar -xzf backup-20251104-020000.tar.gz backup-20251104-020000/config/

# Copier les fichiers de configuration
cp backup-20251104-020000/config/*.json config/

# Red√©marrer l'application
```

### 2.2 R√©cup√©ration d'Urgence

#### 2.2.1 Perte de Base de Donn√©es

**Sc√©nario** : Base de donn√©es corrompue ou perdue

```bash
#!/bin/bash
# scripts/emergency-db-recovery.sh

echo "üö® R√âCUP√âRATION D'URGENCE - BASE DE DONN√âES"

# 1. Tenter une r√©cup√©ration SQLite
echo "üîß Tentative de r√©cup√©ration SQLite..."
sqlite3 data/database.sqlite ".recover" | sqlite3 data/database-recovered.sqlite

# V√©rifier
INTEGRITY=$(sqlite3 data/database-recovered.sqlite "PRAGMA integrity_check;")
if [ "$INTEGRITY" = "ok" ]; then
  echo "‚úÖ R√©cup√©ration r√©ussie"
  cp data/database.sqlite data/database.corrupted.$(date +%Y%m%d-%H%M%S)
  mv data/database-recovered.sqlite data/database.sqlite
  exit 0
fi

# 2. Chercher les sauvegardes disponibles
echo "üîç Recherche de sauvegardes..."
BACKUPS=($(find backups/ -name "*.sqlite" -o -name "*database*.tar.gz" | sort -r))

if [ ${#BACKUPS[@]} -eq 0 ]; then
  echo "‚ùå Aucune sauvegarde trouv√©e"
  echo "üîÑ Initialisation d'une nouvelle base de donn√©es..."
  npm run init-db
  exit 1
fi

# 3. Afficher les sauvegardes disponibles
echo "üìã Sauvegardes disponibles :"
for i in "${!BACKUPS[@]}"; do
  echo "  $i) ${BACKUPS[$i]}"
done

# 4. Restaurer la plus r√©cente
echo "üîÑ Restauration de la sauvegarde la plus r√©cente..."
LATEST="${BACKUPS[0]}"

if [[ "$LATEST" == *.sqlite ]]; then
  cp "$LATEST" data/database.sqlite
elif [[ "$LATEST" == *.tar.gz ]]; then
  tar -xzf "$LATEST" -C /tmp
  cp /tmp/*/database.sqlite data/
fi

# 5. V√©rification finale
sqlite3 data/database.sqlite "PRAGMA integrity_check;"
echo "‚úÖ Base de donn√©es restaur√©e"
```

#### 2.2.2 Corruption de Donn√©es

```bash
# Script de r√©paration
#!/bin/bash

echo "üîß R√©paration de la base de donn√©es..."

# Dump et reload
sqlite3 data/database.sqlite .dump | sqlite3 data/database-repaired.sqlite

# V√©rifier
if sqlite3 data/database-repaired.sqlite "PRAGMA integrity_check;" | grep -q "ok"; then
  echo "‚úÖ R√©paration r√©ussie"
  mv data/database.sqlite data/database.corrupted.bak
  mv data/database-repaired.sqlite data/database.sqlite
else
  echo "‚ùå R√©paration √©chou√©e, utiliser une sauvegarde"
  rm data/database-repaired.sqlite
  exit 1
fi
```

#### 2.2.3 R√©cup√©ration de Configuration

```bash
#!/bin/bash
# scripts/recover-config.sh

echo "üîÑ R√©cup√©ration de la configuration..."

# 1. Chercher la configuration dans les sauvegardes
BACKUP_CONFIG=$(find backups/ -name "config.json" | sort -r | head -1)

if [ -n "$BACKUP_CONFIG" ]; then
  echo "‚úÖ Configuration trouv√©e : $BACKUP_CONFIG"
  cp "$BACKUP_CONFIG" config/config.json
else
  echo "‚ö†Ô∏è Aucune sauvegarde trouv√©e, utilisation du template"
  cp config/config.template.json config/config.json
  echo "‚ö†Ô∏è Veuillez configurer manuellement config/config.json"
fi

# 2. Valider la configuration
if node -e "require('./config/config.json')"; then
  echo "‚úÖ Configuration valide"
else
  echo "‚ùå Configuration invalide"
  exit 1
fi
```

#### 2.2.4 Plan de R√©cup√©ration en Cas de Sinistre (DRP)

**√âtapes prioritaires** :

1. **√âvaluation** (5 min)
   - Identifier l'√©tendue du probl√®me
   - V√©rifier la disponibilit√© des sauvegardes
   - Alerter l'√©quipe

2. **Isolation** (10 min)
   - Arr√™ter l'application
   - D√©connecter du r√©seau si compromission
   - S√©curiser les donn√©es restantes

3. **Restauration** (30-60 min)
   - Restaurer depuis la sauvegarde la plus r√©cente
   - V√©rifier l'int√©grit√©
   - Tester les fonctionnalit√©s critiques

4. **Validation** (15 min)
   - Tests fonctionnels
   - V√©rification des acc√®s
   - Validation utilisateurs

5. **Retour en production** (15 min)
   - Red√©marrage de l'application
   - Monitoring renforc√©
   - Documentation de l'incident

**RTO (Recovery Time Objective)** : 2 heures  
**RPO (Recovery Point Objective)** : 4 heures (perte de donn√©es maximale)

---

## 3. GESTION DES MISES √Ä JOUR

### 3.1 V√©rification des Mises √† Jour

#### 3.1.1 V√©rification Manuelle

```bash
# V√©rifier la version actuelle
cat package.json | grep version

# V√©rifier les mises √† jour disponibles
npm outdated

# V√©rifier sp√©cifiquement Electron
npm outdated electron

# V√©rifier les mises √† jour de s√©curit√©
npm audit
```

#### 3.1.2 V√©rification Automatique

L'application dispose d'un syst√®me d'auto-update int√©gr√© (electron-updater).

**Configuration** : `electron-builder.json`

```json
{
  "publish": {
    "provider": "generic",
    "url": "https://updates.example.com/rds-viewer/"
  },
  "updater": {
    "enabled": true,
    "autoDownload": false,
    "autoInstallOnAppQuit": true
  }
}
```

**V√©rification depuis l'application** :
- Menu ‚Üí Aide ‚Üí V√©rifier les mises √† jour

### 3.2 T√©l√©chargement des Mises √† Jour

#### 3.2.1 T√©l√©chargement depuis le Serveur

```bash
# T√©l√©charger la derni√®re version
wget https://updates.example.com/rds-viewer/latest/RDS-Viewer-Setup-3.0.31.exe

# Ou
curl -O https://updates.example.com/rds-viewer/latest/RDS-Viewer-Setup-3.0.31.exe

# V√©rifier le checksum
sha256sum RDS-Viewer-Setup-3.0.31.exe
# Comparer avec le hash publi√©
```

#### 3.2.2 T√©l√©chargement depuis le Repository

```bash
# Cloner/mettre √† jour le code source
cd /chemin/vers/application
git fetch origin
git checkout tags/v3.0.31

# Installer les d√©pendances
npm install
```

### 3.3 Installation des Mises √† Jour

#### 3.3.1 Pr√©paration

**Checklist avant mise √† jour** :

- [ ] Cr√©er une sauvegarde compl√®te
- [ ] V√©rifier l'espace disque disponible (> 2 GB)
- [ ] Informer les utilisateurs (planning de maintenance)
- [ ] Lire les notes de version (CHANGELOG)
- [ ] V√©rifier la compatibilit√© de la base de donn√©es
- [ ] Pr√©parer un plan de rollback

```bash
# Script de pr√©paration
#!/bin/bash
# scripts/pre-update.sh

echo "üîç V√©rification pr√©-mise √† jour..."

# 1. Sauvegarde
echo "üì¶ Cr√©ation de la sauvegarde..."
./scripts/backup-scheduled.sh full

# 2. Espace disque
FREE_SPACE=$(df -h . | awk 'NR==2 {print $4}' | sed 's/G//')
if (( $(echo "$FREE_SPACE < 2" | bc -l) )); then
  echo "‚ùå Espace disque insuffisant : ${FREE_SPACE}G"
  exit 1
fi

# 3. Version actuelle
CURRENT_VERSION=$(cat package.json | grep version | cut -d'"' -f4)
echo "üìå Version actuelle : $CURRENT_VERSION"

# 4. Processus en cours
if pgrep -f "RDS Viewer" > /dev/null; then
  echo "‚ö†Ô∏è L'application est en cours d'ex√©cution"
  echo "Arr√™t de l'application..."
  pkill -f "RDS Viewer"
  sleep 5
fi

echo "‚úÖ Pr√™t pour la mise √† jour"
```

#### 3.3.2 Installation de la Mise √† Jour

**M√©thode 1 : Installation depuis ex√©cutable (Windows)** :

```powershell
# Arr√™ter l'application
Stop-Process -Name "RDS Viewer" -Force

# Sauvegarder
.\scripts\backup-scheduled.ps1 full

# Installer la nouvelle version
Start-Process -Wait -FilePath "RDS-Viewer-Setup-3.0.31.exe" -ArgumentList "/S"

# V√©rifier l'installation
& "C:\Program Files\RDS Viewer\RDS Viewer.exe" --version
```

**M√©thode 2 : Installation depuis les sources** :

```bash
#!/bin/bash
# scripts/install-update.sh

NEW_VERSION=$1

if [ -z "$NEW_VERSION" ]; then
  echo "‚ùå Usage: $0 <version>"
  exit 1
fi

echo "üöÄ Installation de la version $NEW_VERSION"

# 1. Pr√©paration
./scripts/pre-update.sh

# 2. R√©cup√©rer la nouvelle version
git fetch origin
git checkout tags/v$NEW_VERSION

# 3. Installer les d√©pendances
npm ci --production

# 4. Migrations de base de donn√©es (si n√©cessaire)
if [ -f "scripts/migrate-db-$NEW_VERSION.js" ]; then
  echo "üîÑ Ex√©cution des migrations..."
  node scripts/migrate-db-$NEW_VERSION.js
fi

# 5. Rebuild Electron
npm run electron:rebuild

# 6. V√©rification
npm run test:quick

echo "‚úÖ Installation termin√©e"
```

#### 3.3.3 Post-Installation

```bash
# Script post-installation
#!/bin/bash
# scripts/post-update.sh

echo "üîç V√©rifications post-mise √† jour..."

# 1. V√©rifier la version
NEW_VERSION=$(cat package.json | grep version | cut -d'"' -f4)
echo "‚úÖ Nouvelle version : $NEW_VERSION"

# 2. V√©rifier l'int√©grit√© de la base de donn√©es
sqlite3 data/database.sqlite "PRAGMA integrity_check;"

# 3. V√©rifier les permissions des fichiers
find . -type f -name "*.js" -exec chmod 644 {} \;
find . -type f -name "*.sh" -exec chmod 755 {} \;

# 4. Test de d√©marrage
timeout 30s npm start &
PID=$!
sleep 10

if ps -p $PID > /dev/null; then
  echo "‚úÖ L'application d√©marre correctement"
  kill $PID
else
  echo "‚ùå Probl√®me de d√©marrage"
  exit 1
fi

# 5. Log de mise √† jour
echo "$(date '+%Y-%m-%d %H:%M:%S') - Mise √† jour vers $NEW_VERSION r√©ussie" >> logs/updates.log

echo "‚úÖ V√©rifications termin√©es"
```

### 3.4 Rollback (Retour Arri√®re)

#### 3.4.1 Proc√©dure de Rollback

```bash
#!/bin/bash
# scripts/rollback-update.sh

echo "‚è™ ROLLBACK - Retour √† la version pr√©c√©dente"

# 1. Arr√™ter l'application
pkill -f "RDS Viewer"

# 2. Identifier la sauvegarde pr√©-mise √† jour
BACKUP=$(ls -t backups/before-update-*.tar.gz | head -1)

if [ -z "$BACKUP" ]; then
  echo "‚ùå Aucune sauvegarde de rollback trouv√©e"
  exit 1
fi

echo "üîÑ Restauration depuis : $BACKUP"

# 3. Restaurer
./scripts/restore-backup.sh "$BACKUP"

# 4. Revenir √† la version Git pr√©c√©dente (si applicable)
git log --oneline -5
echo "Entrez le commit √† restaurer (ou appuyez sur Entr√©e pour annuler) :"
read COMMIT

if [ -n "$COMMIT" ]; then
  git checkout $COMMIT
  npm ci --production
fi

# 5. V√©rifier
npm run test:quick

echo "‚úÖ Rollback termin√©"
echo "üìù N'oubliez pas de documenter l'incident"
```

#### 3.4.2 Rollback Automatique en Cas d'√âchec

```javascript
// scripts/auto-rollback.js
const { exec } = require('child_process');
const fs = require('fs');

async function verifyUpdate() {
  // Tests de v√©rification
  const tests = [
    'npm run test:quick',
    'node -e "require(\'./server/server.js\')"',
    'sqlite3 data/database.sqlite "PRAGMA integrity_check;"'
  ];

  for (const test of tests) {
    try {
      await execPromise(test);
    } catch (error) {
      console.error(`‚ùå Test √©chou√© : ${test}`);
      return false;
    }
  }
  return true;
}

async function performRollback() {
  console.log('‚è™ Rollback automatique en cours...');
  await execPromise('./scripts/rollback-update.sh');
  
  // Envoyer une alerte
  await sendAlert('Rollback automatique effectu√© apr√®s √©chec de mise √† jour');
}

async function main() {
  const updateSuccess = await verifyUpdate();
  
  if (!updateSuccess) {
    await performRollback();
    process.exit(1);
  }
  
  console.log('‚úÖ Mise √† jour valid√©e');
}

main();
```

---

## 4. MAINTENANCE PR√âVENTIVE

### 4.1 Nettoyage de la Base de Donn√©es

#### 4.1.1 Nettoyage des Donn√©es Temporaires

```sql
-- scripts/cleanup-database.sql

-- 1. Supprimer les sessions expir√©es (> 30 jours)
DELETE FROM sessions 
WHERE last_activity < datetime('now', '-30 days');

-- 2. Supprimer les logs anciens (> 90 jours)
DELETE FROM logs 
WHERE created_at < datetime('now', '-90 days');

-- 3. Supprimer les caches p√©rim√©s
DELETE FROM cache 
WHERE expires_at < datetime('now');

-- 4. Nettoyer les enregistrements d'activit√© (> 6 mois)
DELETE FROM activity_logs 
WHERE timestamp < datetime('now', '-6 months');

-- 5. Supprimer les documents GED orphelins
DELETE FROM ged_documents 
WHERE id NOT IN (SELECT document_id FROM ged_versions) 
AND created_at < datetime('now', '-1 year');

-- 6. Afficher les statistiques
SELECT 
  'Sessions supprim√©es' as Action,
  changes() as Count;
```

```bash
# Script de nettoyage automatis√©
#!/bin/bash
# scripts/cleanup-database.sh

echo "üßπ Nettoyage de la base de donn√©es..."

# Sauvegarder avant nettoyage
BACKUP_FILE="backups/before-cleanup-$(date +%Y%m%d-%H%M%S).sqlite"
cp data/database.sqlite "$BACKUP_FILE"

# Taille initiale
INITIAL_SIZE=$(stat -f%z data/database.sqlite 2>/dev/null || stat -c%s data/database.sqlite)
echo "üìä Taille initiale : $((INITIAL_SIZE / 1024 / 1024)) MB"

# Ex√©cuter le nettoyage
sqlite3 data/database.sqlite < scripts/cleanup-database.sql

# VACUUM pour r√©cup√©rer l'espace
echo "üîß Optimisation (VACUUM)..."
sqlite3 data/database.sqlite "VACUUM;"

# Taille finale
FINAL_SIZE=$(stat -f%z data/database.sqlite 2>/dev/null || stat -c%s data/database.sqlite)
SAVED=$((INITIAL_SIZE - FINAL_SIZE))
echo "üìä Taille finale : $((FINAL_SIZE / 1024 / 1024)) MB"
echo "‚úÖ Espace lib√©r√© : $((SAVED / 1024 / 1024)) MB"

# Log
echo "$(date '+%Y-%m-%d %H:%M:%S') - Nettoyage DB : ${SAVED} octets lib√©r√©s" >> logs/maintenance.log
```

#### 4.1.2 Nettoyage des Fichiers

```bash
#!/bin/bash
# scripts/cleanup-files.sh

echo "üßπ Nettoyage des fichiers temporaires..."

# 1. Logs anciens (> 30 jours)
find logs/ -name "*.log" -mtime +30 -delete
echo "‚úÖ Logs anciens supprim√©s"

# 2. Fichiers temporaires
find temp/ -type f -mtime +1 -delete
find data/cache/ -type f -mtime +7 -delete
echo "‚úÖ Fichiers temporaires supprim√©s"

# 3. Anciens OCR (> 90 jours)
find data/ocr/ -name "*.txt" -mtime +90 -delete
echo "‚úÖ OCR anciens supprim√©s"

# 4. Sauvegardes anciennes (respecter la politique de r√©tention)
find backups/auto/ -mtime +30 -delete
find backups/manual/ -mtime +90 -delete
echo "‚úÖ Anciennes sauvegardes supprim√©es"

# 5. Node modules cache
npm cache clean --force
echo "‚úÖ Cache npm nettoy√©"

# Afficher l'espace lib√©r√©
du -sh data/ logs/ temp/ backups/
```

### 4.2 Optimisation de la Base de Donn√©es

#### 4.2.1 Analyse et Optimisation

```sql
-- scripts/optimize-database.sql

-- 1. Analyser les statistiques des tables
ANALYZE;

-- 2. Re-indexer
REINDEX;

-- 3. Optimiser les indexes
-- Identifier les indexes inutilis√©s
SELECT 
  name,
  tbl_name,
  sql
FROM sqlite_master
WHERE type = 'index'
AND name NOT IN (
  SELECT DISTINCT idx FROM sqlite_stat1
);

-- 4. V√©rifier les tables fragment√©es
PRAGMA table_info(users);
PRAGMA table_info(sessions);
PRAGMA table_info(logs);

-- 5. Statistiques d'utilisation
SELECT 
  name,
  (SELECT COUNT(*) FROM sqlite_master WHERE type='table' AND name=m.name) as row_count,
  (SELECT SUM(pgsize) FROM dbstat WHERE name=m.name) / 1024 / 1024 as size_mb
FROM sqlite_master m
WHERE type='table'
ORDER BY size_mb DESC;
```

```bash
#!/bin/bash
# scripts/optimize-database.sh

echo "‚ö° Optimisation de la base de donn√©es..."

# Sauvegarder
BACKUP_FILE="backups/before-optimize-$(date +%Y%m%d-%H%M%S).sqlite"
cp data/database.sqlite "$BACKUP_FILE"

# Mesurer les performances avant
echo "üìä Performances AVANT optimisation :"
time sqlite3 data/database.sqlite "SELECT COUNT(*) FROM logs;"

# Ex√©cuter l'optimisation
sqlite3 data/database.sqlite < scripts/optimize-database.sql

# VACUUM
sqlite3 data/database.sqlite "VACUUM;"

# Analyser
sqlite3 data/database.sqlite "ANALYZE;"

# Mesurer les performances apr√®s
echo "üìä Performances APR√àS optimisation :"
time sqlite3 data/database.sqlite "SELECT COUNT(*) FROM logs;"

echo "‚úÖ Optimisation termin√©e"
```

#### 4.2.2 Optimisation des Performances

```javascript
// scripts/performance-optimization.js
const Database = require('better-sqlite3');
const db = new Database('data/database.sqlite');

console.log('‚ö° Optimisation des performances...');

// Configuration optimale
db.pragma('journal_mode = WAL');
db.pragma('synchronous = NORMAL');
db.pragma('cache_size = -64000'); // 64MB
db.pragma('temp_store = MEMORY');
db.pragma('mmap_size = 30000000000'); // 30GB

// Cr√©er des indexes manquants
const indexes = [
  'CREATE INDEX IF NOT EXISTS idx_logs_date ON logs(created_at DESC)',
  'CREATE INDEX IF NOT EXISTS idx_sessions_user ON sessions(user_id)',
  'CREATE INDEX IF NOT EXISTS idx_activity_timestamp ON activity_logs(timestamp DESC)',
  'CREATE INDEX IF NOT EXISTS idx_ged_category ON ged_documents(category_id)'
];

indexes.forEach(sql => {
  try {
    db.exec(sql);
    console.log(`‚úÖ Index cr√©√© : ${sql.split('idx_')[1]?.split(' ')[0]}`);
  } catch (error) {
    console.log(`‚ö†Ô∏è Index existe d√©j√†`);
  }
});

db.close();
console.log('‚úÖ Optimisation termin√©e');
```

### 4.3 V√©rification de l'Int√©grit√©

#### 4.3.1 V√©rification de la Base de Donn√©es

```bash
#!/bin/bash
# scripts/integrity-check.sh

echo "üîç V√©rification de l'int√©grit√©..."

# 1. Int√©grit√© SQLite
echo "üóÑÔ∏è Base de donn√©es :"
INTEGRITY=$(sqlite3 data/database.sqlite "PRAGMA integrity_check;")

if [ "$INTEGRITY" = "ok" ]; then
  echo "  ‚úÖ Base de donn√©es int√®gre"
else
  echo "  ‚ùå PROBL√àME D√âTECT√â :"
  echo "  $INTEGRITY"
  # Envoyer une alerte
  ./scripts/send-alert.sh "CRITIQUE" "Corruption de la base de donn√©es d√©tect√©e"
fi

# 2. V√©rifier les contraintes de cl√©s √©trang√®res
echo "üîó Cl√©s √©trang√®res :"
sqlite3 data/database.sqlite "PRAGMA foreign_key_check;" | while read line; do
  if [ -n "$line" ]; then
    echo "  ‚ùå Contrainte viol√©e : $line"
  fi
done

# 3. V√©rifier les fichiers GED
echo "üìÅ Fichiers GED :"
MISSING_FILES=0
sqlite3 data/database.sqlite "SELECT file_path FROM ged_documents;" | while read filepath; do
  if [ ! -f "$filepath" ]; then
    echo "  ‚ö†Ô∏è Fichier manquant : $filepath"
    ((MISSING_FILES++))
  fi
done

if [ $MISSING_FILES -eq 0 ]; then
  echo "  ‚úÖ Tous les fichiers GED pr√©sents"
else
  echo "  ‚ö†Ô∏è $MISSING_FILES fichiers manquants"
fi

# 4. V√©rifier la configuration
echo "‚öôÔ∏è Configuration :"
if node -e "require('./config/config.json')" 2>/dev/null; then
  echo "  ‚úÖ Configuration valide"
else
  echo "  ‚ùå Configuration invalide"
fi

# 5. V√©rifier les d√©pendances
echo "üì¶ D√©pendances :"
npm list --depth=0 >/dev/null 2>&1
if [ $? -eq 0 ]; then
  echo "  ‚úÖ D√©pendances OK"
else
  echo "  ‚ö†Ô∏è Probl√®mes de d√©pendances d√©tect√©s"
  npm list --depth=0
fi

echo "‚úÖ V√©rification termin√©e"
```

#### 4.3.2 V√©rification des Permissions et Acc√®s

```javascript
// scripts/check-permissions.js
const fs = require('fs');
const path = require('path');

console.log('üîê V√©rification des permissions...');

const criticalPaths = [
  'data/database.sqlite',
  'config/config.json',
  'logs/',
  'data/ged/',
  'backups/'
];

criticalPaths.forEach(p => {
  try {
    const stats = fs.statSync(p);
    const mode = (stats.mode & parseInt('777', 8)).toString(8);
    
    if (p.includes('.sqlite') || p.includes('.json')) {
      if (mode !== '600' && mode !== '644') {
        console.log(`‚ö†Ô∏è ${p} : permissions ${mode} (recommand√©: 644)`);
      } else {
        console.log(`‚úÖ ${p} : permissions OK`);
      }
    } else {
      console.log(`üìÅ ${p} : ${mode}`);
    }
    
    // V√©rifier les droits de lecture/√©criture
    fs.accessSync(p, fs.constants.R_OK | fs.constants.W_OK);
    
  } catch (error) {
    console.log(`‚ùå ${p} : ${error.message}`);
  }
});

console.log('‚úÖ V√©rification termin√©e');
```

### 4.4 Maintenance Syst√®me

#### 4.4.1 Mise √† Jour des D√©pendances

```bash
#!/bin/bash
# scripts/update-dependencies.sh

echo "üì¶ Mise √† jour des d√©pendances..."

# 1. V√©rifier les mises √† jour disponibles
echo "üîç V√©rification des mises √† jour :"
npm outdated

# 2. Mettre √† jour les d√©pendances (patch uniquement)
echo "‚¨ÜÔ∏è Mise √† jour des patches..."
npm update

# 3. V√©rifier les vuln√©rabilit√©s
echo "üîí Audit de s√©curit√© :"
npm audit

# 4. Corriger les vuln√©rabilit√©s automatiquement
echo "üîß Correction automatique :"
npm audit fix

# 5. Tester apr√®s mise √† jour
echo "üß™ Tests :"
npm run test:quick

if [ $? -eq 0 ]; then
  echo "‚úÖ D√©pendances mises √† jour avec succ√®s"
else
  echo "‚ùå Probl√®me d√©tect√©, v√©rifier les logs"
  exit 1
fi
```

#### 4.4.2 Nettoyage Syst√®me

```bash
#!/bin/bash
# scripts/system-cleanup.sh

echo "üßπ Nettoyage syst√®me..."

# 1. Nettoyer npm cache
npm cache clean --force

# 2. Nettoyer node_modules orphelins
find . -name "node_modules" -type d -prune | while read dir; do
  if [ ! -f "$(dirname $dir)/package.json" ]; then
    echo "üóëÔ∏è Suppression : $dir"
    rm -rf "$dir"
  fi
done

# 3. Nettoyer les fichiers de build
rm -rf build/dist/*
rm -rf temp/*

# 4. Nettoyer les logs de d√©veloppement
rm -f *.log
rm -f npm-debug.log*

# 5. Afficher l'espace disponible
df -h .

echo "‚úÖ Nettoyage termin√©"
```

---

## 5. MONITORING CONTINU

### 5.1 M√©triques √† Surveiller

#### 5.1.1 M√©triques Syst√®me

| M√©trique | Seuil Normal | Seuil Alerte | Seuil Critique |
|----------|--------------|--------------|----------------|
| **CPU** | < 60% | > 75% | > 90% |
| **RAM** | < 70% | > 80% | > 95% |
| **Disque** | < 70% | > 85% | > 95% |
| **I/O Disque** | < 100 MB/s | > 200 MB/s | > 500 MB/s |
| **R√©seau** | < 10 MB/s | > 50 MB/s | > 100 MB/s |

#### 5.1.2 M√©triques Application

| M√©trique | Description | Objectif |
|----------|-------------|----------|
| **Temps de r√©ponse** | Temps moyen de r√©ponse API | < 200ms |
| **Requ√™tes/sec** | Nombre de requ√™tes par seconde | < 1000 |
| **Taux d'erreur** | Pourcentage d'erreurs 5xx | < 1% |
| **Sessions actives** | Nombre d'utilisateurs connect√©s | - |
| **Taille DB** | Taille de la base de donn√©es | Croissance < 10%/mois |
| **Temps requ√™te DB** | Temps moyen requ√™te SQL | < 50ms |

#### 5.1.3 Script de Monitoring

```javascript
// scripts/monitor.js
const os = require('os');
const fs = require('fs');
const Database = require('better-sqlite3');

function getSystemMetrics() {
  const cpuUsage = os.loadavg()[0] / os.cpus().length * 100;
  const totalMem = os.totalmem();
  const freeMem = os.freemem();
  const memUsage = ((totalMem - freeMem) / totalMem * 100);
  
  return {
    cpu: cpuUsage.toFixed(2),
    memory: memUsage.toFixed(2),
    totalMemory: (totalMem / 1024 / 1024 / 1024).toFixed(2),
    freeMemory: (freeMem / 1024 / 1024 / 1024).toFixed(2)
  };
}

function getDiskMetrics() {
  const stats = fs.statfsSync('.');
  const total = stats.blocks * stats.bsize;
  const free = stats.bfree * stats.bsize;
  const used = total - free;
  const usagePercent = (used / total * 100);
  
  return {
    total: (total / 1024 / 1024 / 1024).toFixed(2),
    used: (used / 1024 / 1024 / 1024).toFixed(2),
    free: (free / 1024 / 1024 / 1024).toFixed(2),
    usage: usagePercent.toFixed(2)
  };
}

function getDatabaseMetrics() {
  const db = new Database('data/database.sqlite', { readonly: true });
  
  const size = fs.statSync('data/database.sqlite').size;
  const userCount = db.prepare('SELECT COUNT(*) as count FROM users').get().count;
  const sessionCount = db.prepare('SELECT COUNT(*) as count FROM sessions WHERE last_activity > datetime("now", "-1 hour")').get().count;
  const recentLogs = db.prepare('SELECT COUNT(*) as count FROM logs WHERE created_at > datetime("now", "-1 hour")').get().count;
  
  db.close();
  
  return {
    size: (size / 1024 / 1024).toFixed(2),
    users: userCount,
    activeSessions: sessionCount,
    recentLogs: recentLogs
  };
}

function checkHealth() {
  const metrics = {
    timestamp: new Date().toISOString(),
    system: getSystemMetrics(),
    disk: getDiskMetrics(),
    database: getDatabaseMetrics()
  };
  
  // V√©rifier les seuils
  const alerts = [];
  
  if (parseFloat(metrics.system.cpu) > 75) {
    alerts.push({ level: 'WARNING', message: `CPU √©lev√© : ${metrics.system.cpu}%` });
  }
  if (parseFloat(metrics.system.cpu) > 90) {
    alerts.push({ level: 'CRITICAL', message: `CPU critique : ${metrics.system.cpu}%` });
  }
  
  if (parseFloat(metrics.system.memory) > 80) {
    alerts.push({ level: 'WARNING', message: `M√©moire √©lev√©e : ${metrics.system.memory}%` });
  }
  if (parseFloat(metrics.system.memory) > 95) {
    alerts.push({ level: 'CRITICAL', message: `M√©moire critique : ${metrics.system.memory}%` });
  }
  
  if (parseFloat(metrics.disk.usage) > 85) {
    alerts.push({ level: 'WARNING', message: `Disque plein : ${metrics.disk.usage}%` });
  }
  if (parseFloat(metrics.disk.usage) > 95) {
    alerts.push({ level: 'CRITICAL', message: `Disque critique : ${metrics.disk.usage}%` });
  }
  
  metrics.alerts = alerts;
  metrics.status = alerts.length === 0 ? 'HEALTHY' : 
                   alerts.some(a => a.level === 'CRITICAL') ? 'CRITICAL' : 'WARNING';
  
  return metrics;
}

// Ex√©cution
const health = checkHealth();
console.log(JSON.stringify(health, null, 2));

// Enregistrer dans un fichier
fs.appendFileSync(
  'logs/monitoring.log',
  JSON.stringify(health) + '\n'
);

// Envoyer des alertes si n√©cessaire
if (health.alerts.length > 0) {
  health.alerts.forEach(alert => {
    console.error(`${alert.level}: ${alert.message}`);
    // Appeler le script d'alerte
    require('child_process').exec(`./scripts/send-alert.sh "${alert.level}" "${alert.message}"`);
  });
}

process.exit(health.alerts.some(a => a.level === 'CRITICAL') ? 1 : 0);
```

### 5.2 Configuration des Alertes

#### 5.2.1 Script d'Envoi d'Alertes

```bash
#!/bin/bash
# scripts/send-alert.sh

LEVEL=$1
MESSAGE=$2
TIMESTAMP=$(date '+%Y-%m-%d %H:%M:%S')

# Fichier de log des alertes
ALERT_LOG="logs/alerts.log"
echo "[$TIMESTAMP] $LEVEL: $MESSAGE" >> $ALERT_LOG

# Email
if [ -n "$ALERT_EMAIL" ]; then
  echo "$MESSAGE" | mail -s "[RDS Viewer] $LEVEL - $TIMESTAMP" $ALERT_EMAIL
fi

# Webhook (Slack, Teams, etc.)
if [ -n "$WEBHOOK_URL" ]; then
  curl -X POST $WEBHOOK_URL \
    -H 'Content-Type: application/json' \
    -d "{\"text\":\"[RDS Viewer] $LEVEL\\n$MESSAGE\\n$TIMESTAMP\"}"
fi

# SMS (via API)
if [ "$LEVEL" = "CRITICAL" ] && [ -n "$SMS_API_URL" ]; then
  curl -X POST $SMS_API_URL \
    -H 'Content-Type: application/json' \
    -d "{\"phone\":\"$ALERT_PHONE\",\"message\":\"[RDS Viewer CRITIQUE] $MESSAGE\"}"
fi

echo "üö® Alerte envoy√©e : $LEVEL - $MESSAGE"
```

#### 5.2.2 Configuration Cron pour Monitoring

```bash
# Monitoring toutes les 5 minutes
*/5 * * * * cd /chemin/vers/application && /usr/bin/node scripts/monitor.js >> logs/monitoring-cron.log 2>&1

# V√©rification d'int√©grit√© quotidienne
0 3 * * * cd /chemin/vers/application && /bin/bash scripts/integrity-check.sh >> logs/integrity-cron.log 2>&1

# Rapport hebdomadaire (Lundi 8h)
0 8 * * 1 cd /chemin/vers/application && /bin/bash scripts/weekly-report.sh
```

### 5.3 Dashboards de Monitoring

#### 5.3.1 Dashboard Simple (HTML)

```html
<!-- public/monitoring-dashboard.html -->
<!DOCTYPE html>
<html>
<head>
  <title>RDS Viewer - Monitoring</title>
  <meta http-equiv="refresh" content="60">
  <style>
    body { font-family: Arial; margin: 20px; background: #f5f5f5; }
    .metric { 
      background: white; 
      padding: 20px; 
      margin: 10px 0; 
      border-radius: 5px;
      box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    .metric h3 { margin: 0 0 10px 0; color: #333; }
    .status { 
      display: inline-block; 
      padding: 5px 15px; 
      border-radius: 3px; 
      font-weight: bold;
    }
    .healthy { background: #4CAF50; color: white; }
    .warning { background: #FF9800; color: white; }
    .critical { background: #F44336; color: white; }
    .progress {
      background: #e0e0e0;
      border-radius: 10px;
      height: 20px;
      overflow: hidden;
    }
    .progress-bar {
      height: 100%;
      transition: width 0.3s;
      text-align: center;
      color: white;
      line-height: 20px;
    }
    .bar-ok { background: #4CAF50; }
    .bar-warning { background: #FF9800; }
    .bar-critical { background: #F44336; }
  </style>
</head>
<body>
  <h1>üñ•Ô∏è RDS Viewer - Dashboard Monitoring</h1>
  <div id="dashboard"></div>
  
  <script>
    async function loadMetrics() {
      try {
        const response = await fetch('/api/monitoring/metrics');
        const data = await response.json();
        
        const status = data.status || 'UNKNOWN';
        const statusClass = status === 'HEALTHY' ? 'healthy' : 
                           status === 'WARNING' ? 'warning' : 'critical';
        
        let html = `
          <div class="metric">
            <h3>√âtat g√©n√©ral</h3>
            <span class="status ${statusClass}">${status}</span>
            <p><small>Derni√®re mise √† jour : ${new Date(data.timestamp).toLocaleString()}</small></p>
          </div>
          
          <div class="metric">
            <h3>Syst√®me</h3>
            ${renderProgressBar('CPU', data.system.cpu, 75, 90)}
            ${renderProgressBar('M√©moire', data.system.memory, 80, 95)}
          </div>
          
          <div class="metric">
            <h3>Disque</h3>
            ${renderProgressBar('Utilisation', data.disk.usage, 85, 95)}
            <p>Total : ${data.disk.total} GB | Libre : ${data.disk.free} GB</p>
          </div>
          
          <div class="metric">
            <h3>Base de donn√©es</h3>
            <p>Taille : ${data.database.size} MB</p>
            <p>Utilisateurs : ${data.database.users}</p>
            <p>Sessions actives : ${data.database.activeSessions}</p>
            <p>Logs r√©cents (1h) : ${data.database.recentLogs}</p>
          </div>
        `;
        
        if (data.alerts && data.alerts.length > 0) {
          html += '<div class="metric"><h3>‚ö†Ô∏è Alertes</h3><ul>';
          data.alerts.forEach(alert => {
            html += `<li><strong>${alert.level}:</strong> ${alert.message}</li>`;
          });
          html += '</ul></div>';
        }
        
        document.getElementById('dashboard').innerHTML = html;
      } catch (error) {
        document.getElementById('dashboard').innerHTML = 
          '<div class="metric critical">‚ùå Erreur de chargement des m√©triques</div>';
      }
    }
    
    function renderProgressBar(label, value, warningThreshold, criticalThreshold) {
      const barClass = value > criticalThreshold ? 'bar-critical' :
                       value > warningThreshold ? 'bar-warning' : 'bar-ok';
      return `
        <div style="margin: 10px 0;">
          <div style="margin-bottom: 5px;">${label}: ${value}%</div>
          <div class="progress">
            <div class="progress-bar ${barClass}" style="width: ${value}%">${value}%</div>
          </div>
        </div>
      `;
    }
    
    // Charger imm√©diatement
    loadMetrics();
    
    // Recharger toutes les 30 secondes
    setInterval(loadMetrics, 30000);
  </script>
</body>
</html>
```

#### 5.3.2 API de Monitoring

```javascript
// server/routes/monitoring.js
const express = require('express');
const router = express.Router();
const { exec } = require('child_process');
const { promisify } = require('util');
const execPromise = promisify(exec);

router.get('/metrics', async (req, res) => {
  try {
    const { stdout } = await execPromise('node scripts/monitor.js');
    const metrics = JSON.parse(stdout);
    res.json(metrics);
  } catch (error) {
    res.status(500).json({ error: 'Erreur de r√©cup√©ration des m√©triques' });
  }
});

router.get('/health', (req, res) => {
  // V√©rification rapide
  res.json({ 
    status: 'ok',
    timestamp: new Date().toISOString(),
    uptime: process.uptime()
  });
});

module.exports = router;
```

---

## 6. GESTION DES LOGS

### 6.1 Rotation des Logs

#### 6.1.1 Configuration de la Rotation

```javascript
// config/logger-config.js
const winston = require('winston');
require('winston-daily-rotate-file');

const logConfig = {
  level: process.env.LOG_LEVEL || 'info',
  format: winston.format.combine(
    winston.format.timestamp(),
    winston.format.errors({ stack: true }),
    winston.format.json()
  ),
  transports: [
    // Console
    new winston.transports.Console({
      format: winston.format.combine(
        winston.format.colorize(),
        winston.format.simple()
      )
    }),
    
    // Fichier g√©n√©ral avec rotation
    new winston.transports.DailyRotateFile({
      filename: 'logs/application-%DATE%.log',
      datePattern: 'YYYY-MM-DD',
      maxSize: '20m',
      maxFiles: '30d',
      level: 'info'
    }),
    
    // Fichier d'erreurs
    new winston.transports.DailyRotateFile({
      filename: 'logs/errors-%DATE%.log',
      datePattern: 'YYYY-MM-DD',
      maxSize: '20m',
      maxFiles: '90d',
      level: 'error'
    }),
    
    // Fichier de debug (en d√©veloppement uniquement)
    ...(process.env.NODE_ENV === 'development' ? [
      new winston.transports.DailyRotateFile({
        filename: 'logs/debug-%DATE%.log',
        datePattern: 'YYYY-MM-DD',
        maxSize: '50m',
        maxFiles: '7d',
        level: 'debug'
      })
    ] : [])
  ]
};

const logger = winston.createLogger(logConfig);

module.exports = logger;
```

#### 6.1.2 Script de Rotation Manuelle

```bash
#!/bin/bash
# scripts/rotate-logs.sh

LOG_DIR="logs"
ARCHIVE_DIR="logs/archive"
RETENTION_DAYS=90

echo "üîÑ Rotation des logs..."

# Cr√©er le dossier d'archives
mkdir -p "$ARCHIVE_DIR"

# Date de cutoff
CUTOFF_DATE=$(date -d "$RETENTION_DAYS days ago" +%Y-%m-%d)

# Archiver les logs anciens
find "$LOG_DIR" -name "*.log" -type f -mtime +30 | while read logfile; do
  if [ -f "$logfile" ]; then
    ARCHIVE_NAME="$(basename $logfile).$(date +%Y%m%d-%H%M%S).gz"
    gzip -c "$logfile" > "$ARCHIVE_DIR/$ARCHIVE_NAME"
    > "$logfile"  # Vider le fichier
    echo "üì¶ Archiv√© : $ARCHIVE_NAME"
  fi
done

# Supprimer les archives tr√®s anciennes
find "$ARCHIVE_DIR" -name "*.gz" -mtime +$RETENTION_DAYS -delete

# Afficher le r√©sum√©
echo "üìä R√©sum√© :"
du -sh "$LOG_DIR"
echo "‚úÖ Rotation termin√©e"
```

### 6.2 Archivage des Logs

#### 6.2.1 Strat√©gie d'Archivage

| Type de Log | R√©tention Active | R√©tention Archive | Destination |
|-------------|------------------|-------------------|-------------|
| Application | 30 jours | 1 an | Serveur local |
| Erreurs | 90 jours | 2 ans | Serveur + Backup |
| S√©curit√© | 180 jours | 5 ans | Serveur + Backup |
| Debug | 7 jours | Non archiv√© | Serveur local |
| Audit | 1 an | 7 ans | Serveur + Backup + Cloud |

#### 6.2.2 Script d'Archivage

```bash
#!/bin/bash
# scripts/archive-logs.sh

LOG_DIR="logs"
ARCHIVE_DIR="logs/archive"
REMOTE_BACKUP="backup-server:/archives/rds-viewer/logs"
DATE=$(date +%Y-%m)

echo "üì¶ Archivage des logs pour $DATE..."

# Cr√©er une archive mensuelle
ARCHIVE_FILE="logs-$DATE.tar.gz"
tar -czf "$ARCHIVE_DIR/$ARCHIVE_FILE" \
    --exclude="*.gz" \
    --exclude="archive" \
    "$LOG_DIR"/*.log

# Copier vers le serveur de backup
scp "$ARCHIVE_DIR/$ARCHIVE_FILE" "$REMOTE_BACKUP/"

# V√©rifier le transfert
if [ $? -eq 0 ]; then
  echo "‚úÖ Archive transf√©r√©e : $ARCHIVE_FILE"
  
  # Supprimer les logs archiv√©s
  rm "$LOG_DIR"/*.log.old
else
  echo "‚ùå √âchec du transfert"
  exit 1
fi

echo "‚úÖ Archivage termin√©"
```

### 6.3 Analyse des Logs

#### 6.3.1 Script d'Analyse

```bash
#!/bin/bash
# scripts/analyze-logs.sh

LOG_FILE=${1:-logs/application-$(date +%Y-%m-%d).log}

echo "üìä Analyse des logs : $LOG_FILE"
echo "================================"

# Statistiques g√©n√©rales
echo -e "\nüìà Statistiques g√©n√©rales :"
echo "Total de lignes : $(wc -l < $LOG_FILE)"
echo "Erreurs : $(grep -c '"level":"error"' $LOG_FILE)"
echo "Avertissements : $(grep -c '"level":"warn"' $LOG_FILE)"
echo "Info : $(grep -c '"level":"info"' $LOG_FILE)"

# Top 10 des erreurs
echo -e "\n‚ùå Top 10 des erreurs :"
grep '"level":"error"' $LOG_FILE | \
  jq -r '.message' | \
  sort | uniq -c | sort -rn | head -10

# Utilisateurs actifs
echo -e "\nüë• Utilisateurs actifs :"
grep '"user"' $LOG_FILE | \
  jq -r '.user' | \
  sort -u | wc -l

# Actions les plus fr√©quentes
echo -e "\n‚ö° Actions les plus fr√©quentes :"
grep '"action"' $LOG_FILE | \
  jq -r '.action' | \
  sort | uniq -c | sort -rn | head -10

# Temps de r√©ponse moyen
echo -e "\n‚è±Ô∏è Temps de r√©ponse moyen :"
grep '"responseTime"' $LOG_FILE | \
  jq -r '.responseTime' | \
  awk '{ total += $1; count++ } END { print total/count " ms" }'

# D√©tection d'anomalies
echo -e "\nüîç Anomalies d√©tect√©es :"

# Tentatives de connexion √©chou√©es
FAILED_LOGINS=$(grep '"action":"login"' $LOG_FILE | grep '"success":false' | wc -l)
if [ $FAILED_LOGINS -gt 10 ]; then
  echo "‚ö†Ô∏è $FAILED_LOGINS tentatives de connexion √©chou√©es"
fi

# Requ√™tes lentes
SLOW_QUERIES=$(grep '"responseTime"' $LOG_FILE | jq 'select(.responseTime > 1000)' | wc -l)
if [ $SLOW_QUERIES -gt 0 ]; then
  echo "‚ö†Ô∏è $SLOW_QUERIES requ√™tes lentes (> 1s)"
fi

# Erreurs 500
ERRORS_500=$(grep '"status":500' $LOG_FILE | wc -l)
if [ $ERRORS_500 -gt 0 ]; then
  echo "‚ùå $ERRORS_500 erreurs serveur (500)"
fi

echo -e "\n‚úÖ Analyse termin√©e"
```

#### 6.3.2 Recherche dans les Logs

```bash
#!/bin/bash
# scripts/search-logs.sh

SEARCH_TERM=$1
DATE=${2:-$(date +%Y-%m-%d)}
LOG_FILE="logs/application-$DATE.log"

if [ -z "$SEARCH_TERM" ]; then
  echo "‚ùå Usage: $0 <terme-recherche> [date]"
  exit 1
fi

echo "üîç Recherche de '$SEARCH_TERM' dans $LOG_FILE"
echo "============================================"

# Recherche simple
grep -i "$SEARCH_TERM" "$LOG_FILE" | \
  jq -r '"\(.timestamp) [\(.level)] \(.message)"' | \
  less

# Statistiques
TOTAL=$(grep -ic "$SEARCH_TERM" "$LOG_FILE")
echo -e "\nüìä Total de correspondances : $TOTAL"
```

#### 6.3.3 G√©n√©ration de Rapports

```javascript
// scripts/generate-log-report.js
const fs = require('fs');
const readline = require('readline');

async function generateReport(logFile, outputFile) {
  const stats = {
    total: 0,
    errors: 0,
    warnings: 0,
    info: 0,
    users: new Set(),
    actions: {},
    errors_detail: {},
    response_times: []
  };
  
  const fileStream = fs.createReadStream(logFile);
  const rl = readline.createInterface({
    input: fileStream,
    crlfDelay: Infinity
  });
  
  for await (const line of rl) {
    try {
      const log = JSON.parse(line);
      stats.total++;
      
      if (log.level === 'error') stats.errors++;
      if (log.level === 'warn') stats.warnings++;
      if (log.level === 'info') stats.info++;
      
      if (log.user) stats.users.add(log.user);
      
      if (log.action) {
        stats.actions[log.action] = (stats.actions[log.action] || 0) + 1;
      }
      
      if (log.level === 'error' && log.message) {
        stats.errors_detail[log.message] = (stats.errors_detail[log.message] || 0) + 1;
      }
      
      if (log.responseTime) {
        stats.response_times.push(log.responseTime);
      }
    } catch (e) {
      // Ligne invalide, ignorer
    }
  }
  
  // Calculs
  const avgResponseTime = stats.response_times.length > 0
    ? stats.response_times.reduce((a, b) => a + b, 0) / stats.response_times.length
    : 0;
  
  const maxResponseTime = Math.max(...stats.response_times, 0);
  
  // G√©n√©rer le rapport
  const report = `
# Rapport d'Analyse des Logs
**Date** : ${new Date().toLocaleString()}  
**Fichier** : ${logFile}

## Statistiques G√©n√©rales
- **Total de logs** : ${stats.total}
- **Erreurs** : ${stats.errors} (${(stats.errors/stats.total*100).toFixed(2)}%)
- **Avertissements** : ${stats.warnings} (${(stats.warnings/stats.total*100).toFixed(2)}%)
- **Info** : ${stats.info} (${(stats.info/stats.total*100).toFixed(2)}%)
- **Utilisateurs uniques** : ${stats.users.size}

## Performances
- **Temps de r√©ponse moyen** : ${avgResponseTime.toFixed(2)} ms
- **Temps de r√©ponse max** : ${maxResponseTime} ms

## Top 10 Actions
${Object.entries(stats.actions)
  .sort((a, b) => b[1] - a[1])
  .slice(0, 10)
  .map(([action, count]) => `- ${action}: ${count}`)
  .join('\n')}

## Top 10 Erreurs
${Object.entries(stats.errors_detail)
  .sort((a, b) => b[1] - a[1])
  .slice(0, 10)
  .map(([error, count]) => `- ${error}: ${count}`)
  .join('\n')}

## Recommandations
${stats.errors/stats.total > 0.05 ? '‚ö†Ô∏è Taux d\'erreurs √©lev√© (> 5%)' : '‚úÖ Taux d\'erreurs acceptable'}
${avgResponseTime > 500 ? '‚ö†Ô∏è Temps de r√©ponse moyen √©lev√©' : '‚úÖ Performances acceptables'}
${stats.errors_detail['Database error'] ? '‚ö†Ô∏è Erreurs de base de donn√©es d√©tect√©es' : ''}
  `;
  
  fs.writeFileSync(outputFile, report);
  console.log(`‚úÖ Rapport g√©n√©r√© : ${outputFile}`);
}

// Ex√©cution
const logFile = process.argv[2] || `logs/application-${new Date().toISOString().split('T')[0]}.log`;
const outputFile = `logs/reports/report-${new Date().toISOString().split('T')[0]}.md`;

generateReport(logFile, outputFile);
```

---

## 7. PROC√âDURES D'URGENCE

### 7.1 Panne Syst√®me

#### 7.1.1 Diagnostic Rapide

```bash
#!/bin/bash
# scripts/emergency-diagnostic.sh

echo "üö® DIAGNOSTIC D'URGENCE - RDS VIEWER"
echo "====================================="
echo "Timestamp : $(date '+%Y-%m-%d %H:%M:%S')"

# 1. V√©rifier si l'application tourne
echo -e "\nüìç √âtat de l'application :"
if pgrep -f "RDS Viewer" > /dev/null; then
  echo "‚úÖ Processus en cours d'ex√©cution"
  ps aux | grep "RDS Viewer"
else
  echo "‚ùå Application arr√™t√©e"
fi

# 2. V√©rifier les ports
echo -e "\nüîå Ports r√©seau :"
netstat -tuln | grep -E ":(3000|3001|5000)" || echo "‚ùå Aucun port √©coutant"

# 3. V√©rifier la base de donn√©es
echo -e "\nüóÑÔ∏è Base de donn√©es :"
if [ -f "data/database.sqlite" ]; then
  echo "‚úÖ Fichier pr√©sent"
  DB_SIZE=$(stat -f%z "data/database.sqlite" 2>/dev/null || stat -c%s "data/database.sqlite")
  echo "Taille : $((DB_SIZE / 1024 / 1024)) MB"
  
  INTEGRITY=$(sqlite3 data/database.sqlite "PRAGMA integrity_check;" 2>&1)
  if [ "$INTEGRITY" = "ok" ]; then
    echo "‚úÖ Int√©grit√© OK"
  else
    echo "‚ùå CORRUPTION D√âTECT√âE"
  fi
else
  echo "‚ùå Fichier manquant"
fi

# 4. V√©rifier les logs r√©cents
echo -e "\nüìã Derni√®res erreurs :"
if [ -f "logs/errors-$(date +%Y-%m-%d).log" ]; then
  tail -20 "logs/errors-$(date +%Y-%m-%d).log"
else
  echo "Aucun log d'erreur aujourd'hui"
fi

# 5. Ressources syst√®me
echo -e "\nüíª Ressources syst√®me :"
echo "CPU : $(top -bn1 | grep "Cpu(s)" | awk '{print $2}')%"
echo "RAM : $(free -h | awk 'NR==2{print $3"/"$2}')"
echo "Disque : $(df -h . | awk 'NR==2{print $5" utilis√©"}')"

# 6. Configuration r√©seau
echo -e "\nüåê R√©seau :"
ping -c 1 8.8.8.8 > /dev/null 2>&1 && echo "‚úÖ Internet OK" || echo "‚ùå Pas de connexion Internet"

# 7. Derni√®re sauvegarde
echo -e "\nüíæ Derni√®re sauvegarde :"
LAST_BACKUP=$(ls -t backups/auto/*.sqlite 2>/dev/null | head -1)
if [ -n "$LAST_BACKUP" ]; then
  echo "‚úÖ $LAST_BACKUP"
  echo "Date : $(stat -f%Sm "$LAST_BACKUP" 2>/dev/null || stat -c%y "$LAST_BACKUP")"
else
  echo "‚ö†Ô∏è Aucune sauvegarde trouv√©e"
fi

echo -e "\n====================================="
echo "Diagnostic termin√©"
```

#### 7.1.2 Red√©marrage d'Urgence

```bash
#!/bin/bash
# scripts/emergency-restart.sh

echo "üö® RED√âMARRAGE D'URGENCE"

# 1. Sauvegarder l'√©tat actuel
echo "üì¶ Sauvegarde de l'√©tat actuel..."
EMERGENCY_BACKUP="backups/emergency-$(date +%Y%m%d-%H%M%S)"
mkdir -p "$EMERGENCY_BACKUP"
cp -r data/database.sqlite "$EMERGENCY_BACKUP/" 2>/dev/null
cp -r logs/*.log "$EMERGENCY_BACKUP/" 2>/dev/null

# 2. Tuer les processus r√©calcitrants
echo "üî™ Arr√™t forc√©..."
pkill -9 -f "RDS Viewer"
pkill -9 -f "electron"
pkill -9 -f "node.*server.js"
sleep 2

# 3. Nettoyer les fichiers temporaires
echo "üßπ Nettoyage..."
rm -rf temp/*
rm -f *.lock

# 4. V√©rifier l'int√©grit√©
echo "üîç V√©rification..."
if sqlite3 data/database.sqlite "PRAGMA integrity_check;" | grep -q "ok"; then
  echo "‚úÖ Base de donn√©es OK"
else
  echo "‚ùå Base de donn√©es corrompue, restauration..."
  ./scripts/emergency-db-recovery.sh
fi

# 5. Red√©marrer
echo "üöÄ Red√©marrage..."
npm start &

# 6. V√©rifier le d√©marrage
sleep 10
if pgrep -f "RDS Viewer" > /dev/null; then
  echo "‚úÖ Application red√©marr√©e avec succ√®s"
  
  # Envoyer une notification
  ./scripts/send-alert.sh "INFO" "Red√©marrage d'urgence effectu√© avec succ√®s"
else
  echo "‚ùå √âchec du red√©marrage"
  ./scripts/send-alert.sh "CRITICAL" "√âchec du red√©marrage d'urgence"
  exit 1
fi
```

### 7.2 Perte de Donn√©es

#### 7.2.1 √âvaluation de la Perte

```bash
#!/bin/bash
# scripts/assess-data-loss.sh

echo "üîç √âVALUATION DE LA PERTE DE DONN√âES"
echo "====================================="

# 1. V√©rifier la base de donn√©es actuelle
if [ -f "data/database.sqlite" ]; then
  echo "‚úÖ Base de donn√©es pr√©sente"
  
  # V√©rifier l'int√©grit√©
  INTEGRITY=$(sqlite3 data/database.sqlite "PRAGMA integrity_check;" 2>&1)
  if [ "$INTEGRITY" != "ok" ]; then
    echo "‚ùå Base de donn√©es corrompue : $INTEGRITY"
  fi
  
  # Compter les enregistrements
  echo -e "\nüìä Donn√©es actuelles :"
  sqlite3 data/database.sqlite <<EOF
SELECT 'Utilisateurs: ' || COUNT(*) FROM users;
SELECT 'Sessions: ' || COUNT(*) FROM sessions;
SELECT 'Documents GED: ' || COUNT(*) FROM ged_documents;
SELECT 'Logs: ' || COUNT(*) FROM logs;
EOF
else
  echo "‚ùå Base de donn√©es manquante"
fi

# 2. Identifier les sauvegardes disponibles
echo -e "\nüíæ Sauvegardes disponibles :"
find backups/ -name "*.sqlite" -o -name "*.tar.gz" | while read backup; do
  SIZE=$(stat -f%z "$backup" 2>/dev/null || stat -c%s "$backup")
  DATE=$(stat -f%Sm "$backup" 2>/dev/null || stat -c%y "$backup")
  echo "  - $backup ($((SIZE / 1024 / 1024)) MB, $DATE)"
done

# 3. Comparer avec la derni√®re sauvegarde
LAST_BACKUP=$(find backups/auto -name "*.sqlite" | sort -r | head -1)
if [ -n "$LAST_BACKUP" ]; then
  echo -e "\nüîç Comparaison avec la derni√®re sauvegarde :"
  echo "Backup : $LAST_BACKUP"
  
  sqlite3 "$LAST_BACKUP" <<EOF
SELECT 'Utilisateurs (backup): ' || COUNT(*) FROM users;
SELECT 'Sessions (backup): ' || COUNT(*) FROM sessions;
SELECT 'Documents GED (backup): ' || COUNT(*) FROM ged_documents;
SELECT 'Logs (backup): ' || COUNT(*) FROM logs;
EOF

  # Calculer la perte estim√©e
  CURRENT_LOGS=$(sqlite3 data/database.sqlite "SELECT COUNT(*) FROM logs;" 2>/dev/null || echo "0")
  BACKUP_LOGS=$(sqlite3 "$LAST_BACKUP" "SELECT COUNT(*) FROM logs;")
  LOST_LOGS=$((CURRENT_LOGS - BACKUP_LOGS))
  
  if [ $LOST_LOGS -lt 0 ]; then
    echo -e "\n‚ö†Ô∏è Perte estim√©e : $((0 - LOST_LOGS)) enregistrements"
  else
    echo -e "\n‚úÖ Aucune perte d√©tect√©e"
  fi
fi

echo -e "\n====================================="
```

#### 7.2.2 R√©cup√©ration de Donn√©es

```bash
#!/bin/bash
# scripts/data-recovery.sh

echo "üîÑ R√âCUP√âRATION DE DONN√âES"
echo "=========================="

# 1. Cr√©er une sauvegarde de l'√©tat actuel
CURRENT_BACKUP="backups/before-recovery-$(date +%Y%m%d-%H%M%S).tar.gz"
tar -czf "$CURRENT_BACKUP" data/ config/
echo "üì¶ Sauvegarde actuelle : $CURRENT_BACKUP"

# 2. Lister les sauvegardes disponibles
echo -e "\nüíæ Sauvegardes disponibles :"
BACKUPS=($(find backups/ -name "*.sqlite" -o -name "*.tar.gz" | sort -r))
for i in "${!BACKUPS[@]}"; do
  DATE=$(stat -f%Sm "${BACKUPS[$i]}" 2>/dev/null || stat -c%y "${BACKUPS[$i]}")
  echo "  $i) ${BACKUPS[$i]} ($DATE)"
done

# 3. S√©lection automatique (la plus r√©cente)
echo -e "\nüîÑ Restauration depuis la sauvegarde la plus r√©cente..."
SELECTED_BACKUP="${BACKUPS[0]}"
echo "Backup s√©lectionn√© : $SELECTED_BACKUP"

# 4. Restaurer
if [[ "$SELECTED_BACKUP" == *.sqlite ]]; then
  cp "$SELECTED_BACKUP" data/database.sqlite
elif [[ "$SELECTED_BACKUP" == *.tar.gz ]]; then
  tar -xzf "$SELECTED_BACKUP" -C /tmp
  cp /tmp/*/database.sqlite data/
fi

# 5. V√©rifier
sqlite3 data/database.sqlite "PRAGMA integrity_check;"

# 6. Tenter de r√©cup√©rer des donn√©es depuis les logs
echo -e "\nüîç Tentative de r√©cup√©ration depuis les logs..."
./scripts/recover-from-logs.sh

echo -e "\n‚úÖ R√©cup√©ration termin√©e"
```

### 7.3 S√©curit√© Compromise

#### 7.3.1 D√©tection d'Intrusion

```bash
#!/bin/bash
# scripts/security-check.sh

echo "üîí V√âRIFICATION DE S√âCURIT√â"
echo "============================"

ALERT=0

# 1. V√©rifier les tentatives de connexion √©chou√©es
echo -e "\nüîê Tentatives de connexion :"
TODAY=$(date +%Y-%m-%d)
FAILED_LOGINS=$(grep '"action":"login"' logs/application-$TODAY.log | grep '"success":false' | wc -l)
echo "√âchecs de connexion : $FAILED_LOGINS"

if [ $FAILED_LOGINS -gt 20 ]; then
  echo "‚ö†Ô∏è ALERTE : Nombre √©lev√© de tentatives √©chou√©es"
  ALERT=1
fi

# 2. V√©rifier les acc√®s suspects
echo -e "\nüë§ Acc√®s suspects :"
grep -E '"level":"warn".*"security"' logs/application-$TODAY.log | tail -10

# 3. V√©rifier l'int√©grit√© des fichiers critiques
echo -e "\nüìÅ Int√©grit√© des fichiers :"
CRITICAL_FILES=(
  "server/server.js"
  "electron/main.js"
  "config/config.json"
  "package.json"
)

for file in "${CRITICAL_FILES[@]}"; do
  if [ -f "$file" ]; then
    # V√©rifier la date de modification
    MTIME=$(stat -f%Sm "$file" 2>/dev/null || stat -c%y "$file")
    echo "  $file : $MTIME"
    
    # Comparer avec une version de r√©f√©rence (si disponible)
    if [ -f "backups/reference/$file" ]; then
      if ! diff -q "$file" "backups/reference/$file" > /dev/null; then
        echo "    ‚ö†Ô∏è FICHIER MODIFI√â"
        ALERT=1
      fi
    fi
  else
    echo "  ‚ùå $file : MANQUANT"
    ALERT=1
  fi
done

# 4. V√©rifier les processus
echo -e "\n‚öôÔ∏è Processus suspects :"
ps aux | grep -E "(nc|netcat|nmap)" && ALERT=1

# 5. V√©rifier les connexions r√©seau
echo -e "\nüåê Connexions r√©seau :"
netstat -tuln | grep ESTABLISHED

# 6. V√©rifier les modifications r√©centes
echo -e "\nüìù Fichiers modifi√©s r√©cemment (24h) :"
find . -type f -mtime -1 -not -path "*/node_modules/*" -not -path "*/logs/*"

if [ $ALERT -eq 1 ]; then
  echo -e "\nüö® ALERTES DE S√âCURIT√â D√âTECT√âES"
  ./scripts/send-alert.sh "CRITICAL" "Alertes de s√©curit√© d√©tect√©es - V√©rification requise"
  
  # Isoler le syst√®me
  echo "üîí Isolation du syst√®me recommand√©e"
  echo "Ex√©cuter : ./scripts/isolate-system.sh"
else
  echo -e "\n‚úÖ Aucune menace d√©tect√©e"
fi
```

#### 7.3.2 Isolation du Syst√®me

```bash
#!/bin/bash
# scripts/isolate-system.sh

echo "üö® ISOLATION DU SYST√àME"
echo "======================="

# Confirmation
read -p "√ätes-vous s√ªr de vouloir isoler le syst√®me ? (yes/no) " -n 3 -r
echo
if [[ ! $REPLY =~ ^yes$ ]]; then
  echo "Annul√©"
  exit 0
fi

# 1. Arr√™ter l'application
echo "üî¥ Arr√™t de l'application..."
pkill -f "RDS Viewer"

# 2. Sauvegarder les preuves
echo "üì¶ Sauvegarde des preuves..."
FORENSICS_DIR="forensics/incident-$(date +%Y%m%d-%H%M%S)"
mkdir -p "$FORENSICS_DIR"

cp -r logs/ "$FORENSICS_DIR/"
cp -r data/ "$FORENSICS_DIR/"
cp -r config/ "$FORENSICS_DIR/"

# Capturer l'√©tat du syst√®me
ps aux > "$FORENSICS_DIR/processes.txt"
netstat -tuln > "$FORENSICS_DIR/network.txt"
last > "$FORENSICS_DIR/logins.txt"

# 3. Bloquer les connexions r√©seau (optionnel, √† adapter)
echo "üîí Blocage des connexions r√©seau..."
# iptables -A INPUT -p tcp --dport 3000 -j DROP
# iptables -A INPUT -p tcp --dport 3001 -j DROP

# 4. Notification
./scripts/send-alert.sh "CRITICAL" "Syst√®me isol√© suite √† incident de s√©curit√© - Investigation requise"

echo "‚úÖ Syst√®me isol√©"
echo "üìÅ Preuves sauvegard√©es dans : $FORENSICS_DIR"
echo ""
echo "ACTIONS SUIVANTES :"
echo "1. Analyser les logs dans $FORENSICS_DIR"
echo "2. Identifier la source de l'intrusion"
echo "3. Changer tous les mots de passe"
echo "4. Restaurer depuis une sauvegarde propre"
echo "5. Renforcer la s√©curit√©"
```

#### 7.3.3 R√©ponse √† Incident

**Proc√©dure de r√©ponse** :

1. **Identification** (0-15 min)
   - D√©tecter l'incident
   - Documenter les premiers signes
   - Alerter l'√©quipe de s√©curit√©

2. **Confinement** (15-30 min)
   - Isoler le syst√®me compromis
   - Arr√™ter la propagation
   - Sauvegarder les preuves

3. **√âradication** (30-60 min)
   - Identifier la cause racine
   - Supprimer les √©l√©ments malveillants
   - Corriger les vuln√©rabilit√©s

4. **R√©cup√©ration** (1-4 heures)
   - Restaurer depuis une sauvegarde propre
   - Renforcer la s√©curit√©
   - Valider le syst√®me

5. **Post-incident** (1-7 jours)
   - Analyse d√©taill√©e
   - Documentation compl√®te
   - Am√©lioration des proc√©dures

---

## 8. CONTACTS ET ESCALADE

### 8.1 Contacts d'Urgence

#### 8.1.1 √âquipe Technique

| R√¥le | Nom | T√©l√©phone | Email | Disponibilit√© |
|------|-----|-----------|-------|---------------|
| **Admin Syst√®me Principal** | [√Ä compl√©ter] | +33 X XX XX XX XX | admin@anecoop.fr | 24/7 |
| **Admin Syst√®me Secondaire** | [√Ä compl√©ter] | +33 X XX XX XX XX | admin2@anecoop.fr | Heures ouvrables |
| **D√©veloppeur Senior** | [√Ä compl√©ter] | +33 X XX XX XX XX | dev@anecoop.fr | Sur appel |
| **DBA** | [√Ä compl√©ter] | +33 X XX XX XX XX | dba@anecoop.fr | Heures ouvrables |
| **Responsable S√©curit√©** | [√Ä compl√©ter] | +33 X XX XX XX XX | security@anecoop.fr | Sur appel |

#### 8.1.2 Management

| R√¥le | Nom | T√©l√©phone | Email |
|------|-----|-----------|-------|
| **Responsable IT** | [√Ä compl√©ter] | +33 X XX XX XX XX | it-manager@anecoop.fr |
| **DSI** | [√Ä compl√©ter] | +33 X XX XX XX XX | dsi@anecoop.fr |
| **Direction G√©n√©rale** | [√Ä compl√©ter] | +33 X XX XX XX XX | direction@anecoop.fr |

#### 8.1.3 Fournisseurs et Support

| Service | Contact | T√©l√©phone | Email | SLA |
|---------|---------|-----------|-------|-----|
| **H√©bergement** | [Fournisseur] | [T√©l√©phone] | support@hebergeur.fr | 4h |
| **Base de donn√©es** | SQLite Community | - | - | Best effort |
| **Support Electron** | GitHub Issues | - | - | Community |
| **Consultant externe** | [√Ä compl√©ter] | [T√©l√©phone] | [Email] | Sur demande |

### 8.2 Proc√©dures d'Escalade

#### 8.2.1 Niveaux de S√©v√©rit√©

| Niveau | Description | Exemples | D√©lai de R√©ponse | Escalade |
|--------|-------------|----------|------------------|----------|
| **P1 - CRITIQUE** | Service compl√®tement indisponible, perte de donn√©es | Panne totale, corruption DB, intrusion | 15 minutes | Imm√©diate |
| **P2 - URGENT** | Fonctionnalit√© majeure indisponible | Connexion impossible, erreurs g√©n√©ralis√©es | 1 heure | Apr√®s 2h |
| **P3 - IMPORTANT** | Fonctionnalit√© mineure affect√©e | Bug visuel, lenteurs ponctuelles | 4 heures | Apr√®s 8h |
| **P4 - MINEUR** | Probl√®me cosm√©tique ou am√©lioration | Typo, suggestion d'am√©lioration | 1 jour ouvr√© | Apr√®s 3j |

#### 8.2.2 Matrice d'Escalade

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  INCIDENT D√âTECT√â                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ
                    ‚ñº
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ  √âvaluation initiale ‚îÇ
         ‚îÇ   (Admin Syst√®me)    ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ                       ‚îÇ
        ‚ñº                       ‚ñº
   [P4/P3]                  [P2/P1]
        ‚îÇ                       ‚îÇ
        ‚ñº                       ‚ñº
  Traitement          üö® ESCALADE IMM√âDIATE
    standard                   ‚îÇ
        ‚îÇ              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ              ‚îÇ                 ‚îÇ
        ‚îÇ              ‚ñº                 ‚ñº
        ‚îÇ       D√©veloppeur Senior   Responsable IT
        ‚îÇ              ‚îÇ                 ‚îÇ
        ‚îÇ              ‚îÇ    Si critique  ‚îÇ
        ‚îÇ              ‚îÇ        ‚îÇ        ‚îÇ
        ‚îÇ              ‚îÇ        ‚ñº        ‚îÇ
        ‚îÇ              ‚îÇ      DSI        ‚îÇ
        ‚îÇ              ‚îÇ        ‚îÇ        ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
                       ‚ñº
                  R√âSOLUTION
```

#### 8.2.3 Script d'Escalade Automatique

```bash
#!/bin/bash
# scripts/escalate.sh

SEVERITY=$1
MESSAGE=$2
DURATION=${3:-0}  # Dur√©e depuis le d√©but de l'incident (minutes)

case $SEVERITY in
  P1)
    echo "üö® ESCALADE P1 - CRITIQUE"
    # Alerter tout le monde
    ./scripts/send-alert.sh "CRITICAL" "$MESSAGE" --to "admin@anecoop.fr,it-manager@anecoop.fr,dsi@anecoop.fr"
    # SMS
    ./scripts/send-sms.sh "+33XXXXXXXXX" "CRITIQUE RDS Viewer: $MESSAGE"
    # Call (si disponible)
    # ./scripts/call-alert.sh "+33XXXXXXXXX" "Alerte critique RDS Viewer"
    ;;
    
  P2)
    echo "‚ö†Ô∏è ESCALADE P2 - URGENT"
    ./scripts/send-alert.sh "WARNING" "$MESSAGE" --to "admin@anecoop.fr,dev@anecoop.fr"
    
    # Escalade apr√®s 2h
    if [ $DURATION -gt 120 ]; then
      echo "Escalade vers responsable IT"
      ./scripts/send-alert.sh "WARNING" "P2 non r√©solu apr√®s 2h: $MESSAGE" --to "it-manager@anecoop.fr"
    fi
    ;;
    
  P3)
    echo "‚ÑπÔ∏è ESCALADE P3 - IMPORTANT"
    ./scripts/send-alert.sh "INFO" "$MESSAGE" --to "admin@anecoop.fr"
    
    # Escalade apr√®s 8h
    if [ $DURATION -gt 480 ]; then
      echo "Escalade P3->P2"
      ./escalate.sh P2 "$MESSAGE" $DURATION
    fi
    ;;
    
  P4)
    echo "üìù P4 - MINEUR (pas d'escalade)"
    # Cr√©er un ticket seulement
    echo "[$SEVERITY] $MESSAGE" >> logs/tickets.log
    ;;
    
  *)
    echo "‚ùå Niveau de s√©v√©rit√© invalide: $SEVERITY"
    exit 1
    ;;
esac
```

### 8.3 Communication de Crise

#### 8.3.1 Template Email Incident

```
Objet: [RDS Viewer] INCIDENT P[1-4] - [R√©sum√©]

INCIDENT REPORT
===============

S√©v√©rit√©: P[X] - [CRITIQUE/URGENT/IMPORTANT/MINEUR]
Date/Heure: [Date] [Heure]
Dur√©e: [Dur√©e depuis d√©but]
Status: [EN COURS / R√âSOLU / INVESTIGATION]

DESCRIPTION
-----------
[Description d√©taill√©e de l'incident]

IMPACT
------
- Utilisateurs affect√©s: [Nombre/Tous/Aucun]
- Fonctionnalit√©s impact√©es: [Liste]
- Perte de donn√©es: [Oui/Non/Inconnu]

ACTIONS ENTREPRISES
-------------------
1. [Action 1]
2. [Action 2]
...

PROCHAINES √âTAPES
-----------------
1. [√âtape 1]
2. [√âtape 2]
...

ETA R√âSOLUTION
--------------
[Estimation ou "En investigation"]

CONTACT
-------
[Nom du responsable]
[T√©l√©phone]
[Email]
```

#### 8.3.2 Status Page (Mod√®le)

```html
<!-- public/status.html -->
<!DOCTYPE html>
<html>
<head>
  <title>RDS Viewer - Status</title>
  <meta http-equiv="refresh" content="300">
  <style>
    body { font-family: Arial; max-width: 800px; margin: 50px auto; padding: 20px; }
    .status { padding: 20px; border-radius: 5px; margin: 20px 0; }
    .operational { background: #d4edda; border: 1px solid #c3e6cb; }
    .degraded { background: #fff3cd; border: 1px solid #ffeaa7; }
    .outage { background: #f8d7da; border: 1px solid #f5c6cb; }
    .component { padding: 10px; margin: 5px 0; border-left: 4px solid #28a745; }
    .component.down { border-color: #dc3545; }
  </style>
</head>
<body>
  <h1>üñ•Ô∏è RDS Viewer - Status</h1>
  
  <div class="status operational">
    <h2>‚úÖ Tous les syst√®mes op√©rationnels</h2>
    <p>Derni√®re mise √† jour : <span id="timestamp"></span></p>
  </div>
  
  <h3>Composants</h3>
  <div class="component">
    <strong>Application Web</strong> - Op√©rationnel
  </div>
  <div class="component">
    <strong>Base de donn√©es</strong> - Op√©rationnel
  </div>
  <div class="component">
    <strong>Serveur RDS</strong> - Op√©rationnel
  </div>
  <div class="component">
    <strong>Active Directory</strong> - Op√©rationnel
  </div>
  <div class="component">
    <strong>GED</strong> - Op√©rationnel
  </div>
  
  <h3>Incidents r√©cents</h3>
  <p>Aucun incident dans les derni√®res 24 heures</p>
  
  <script>
    document.getElementById('timestamp').textContent = new Date().toLocaleString();
  </script>
</body>
</html>
```

---

## 9. CHECKLISTS DE MAINTENANCE

### 9.1 Maintenance Quotidienne

**Temps estim√©** : 15 minutes  
**Ex√©cution** : Automatique (script cron) + v√©rification manuelle

#### Checklist Quotidienne

- [ ] **V√©rifier l'√©tat du syst√®me**
  ```bash
  ./scripts/monitor.js
  ```
  - [ ] CPU < 75%
  - [ ] RAM < 80%
  - [ ] Disque < 85%

- [ ] **V√©rifier l'application**
  - [ ] Application en cours d'ex√©cution
  - [ ] Pas d'erreurs critiques dans les logs
  - [ ] Temps de r√©ponse < 500ms

- [ ] **V√©rifier les sauvegardes**
  - [ ] Sauvegarde automatique effectu√©e
  - [ ] Int√©grit√© de la derni√®re sauvegarde
  ```bash
  ./scripts/verify-backup.sh $(ls -t backups/auto/*.sqlite | head -1)
  ```

- [ ] **V√©rifier les logs**
  - [ ] Pas d'erreurs critiques
  - [ ] Taux d'erreur < 1%
  ```bash
  grep -c '"level":"error"' logs/application-$(date +%Y-%m-%d).log
  ```

- [ ] **V√©rifier la base de donn√©es**
  - [ ] Int√©grit√© OK
  - [ ] Taille de croissance normale
  ```bash
  sqlite3 data/database.sqlite "PRAGMA integrity_check;"
  ```

- [ ] **V√©rifier les utilisateurs**
  - [ ] Pas de tentatives de connexion suspectes
  - [ ] Sessions actives coh√©rentes

#### Script de Check Quotidien

```bash
#!/bin/bash
# scripts/daily-check.sh

echo "üìã CHECK QUOTIDIEN - $(date '+%Y-%m-%d %H:%M:%S')"
echo "=============================================="

ERRORS=0

# Monitoring
echo "1Ô∏è‚É£ Monitoring syst√®me..."
node scripts/monitor.js
[ $? -eq 0 ] && echo "‚úÖ OK" || { echo "‚ùå √âCHEC"; ((ERRORS++)); }

# Sauvegarde
echo -e "\n2Ô∏è‚É£ V√©rification sauvegarde..."
LAST_BACKUP=$(ls -t backups/auto/*.sqlite | head -1)
if [ -f "$LAST_BACKUP" ]; then
  ./scripts/verify-backup.sh "$LAST_BACKUP"
  [ $? -eq 0 ] && echo "‚úÖ OK" || { echo "‚ùå √âCHEC"; ((ERRORS++)); }
else
  echo "‚ùå Aucune sauvegarde trouv√©e"
  ((ERRORS++))
fi

# Base de donn√©es
echo -e "\n3Ô∏è‚É£ Int√©grit√© base de donn√©es..."
INTEGRITY=$(sqlite3 data/database.sqlite "PRAGMA integrity_check;")
if [ "$INTEGRITY" = "ok" ]; then
  echo "‚úÖ OK"
else
  echo "‚ùå √âCHEC: $INTEGRITY"
  ((ERRORS++))
fi

# Logs
echo -e "\n4Ô∏è‚É£ Analyse des logs..."
ERROR_COUNT=$(grep -c '"level":"error"' logs/application-$(date +%Y-%m-%d).log 2>/dev/null || echo "0")
echo "Erreurs aujourd'hui : $ERROR_COUNT"
if [ $ERROR_COUNT -lt 10 ]; then
  echo "‚úÖ OK"
else
  echo "‚ö†Ô∏è Nombre √©lev√© d'erreurs"
  ((ERRORS++))
fi

# R√©sum√©
echo -e "\n=============================================="
if [ $ERRORS -eq 0 ]; then
  echo "‚úÖ CHECK QUOTIDIEN R√âUSSI"
  exit 0
else
  echo "‚ùå $ERRORS PROBL√àME(S) D√âTECT√â(S)"
  ./scripts/send-alert.sh "WARNING" "Check quotidien : $ERRORS probl√®me(s) d√©tect√©(s)"
  exit 1
fi
```

**Configuration Cron** :
```bash
# Chaque jour √† 8h
0 8 * * * cd /chemin/vers/application && ./scripts/daily-check.sh >> logs/daily-check.log 2>&1
```

### 9.2 Maintenance Hebdomadaire

**Temps estim√©** : 1 heure  
**Jour recommand√©** : Dimanche 1h du matin  
**Ex√©cution** : Semi-automatique

#### Checklist Hebdomadaire

- [ ] **Sauvegarde compl√®te**
  ```bash
  ./scripts/backup-scheduled.sh full
  ```
  - [ ] Sauvegarde locale
  - [ ] Copie sur serveur r√©seau
  - [ ] V√©rification de l'int√©grit√©

- [ ] **Nettoyage de la base de donn√©es**
  ```bash
  ./scripts/cleanup-database.sh
  ```
  - [ ] Suppression sessions expir√©es
  - [ ] Suppression logs anciens (> 90j)
  - [ ] VACUUM effectu√©

- [ ] **Optimisation**
  ```bash
  ./scripts/optimize-database.sh
  ```
  - [ ] ANALYZE ex√©cut√©
  - [ ] REINDEX effectu√©
  - [ ] Performances v√©rifi√©es

- [ ] **V√©rification d'int√©grit√©**
  ```bash
  ./scripts/integrity-check.sh
  ```
  - [ ] Base de donn√©es
  - [ ] Fichiers GED
  - [ ] Configuration
  - [ ] D√©pendances

- [ ] **Mises √† jour de s√©curit√©**
  ```bash
  npm audit
  npm audit fix
  ```
  - [ ] V√©rifier les vuln√©rabilit√©s
  - [ ] Appliquer les correctifs disponibles
  - [ ] Tester apr√®s mise √† jour

- [ ] **Rotation des logs**
  ```bash
  ./scripts/rotate-logs.sh
  ```
  - [ ] Archivage des logs
  - [ ] Suppression des archives anciennes

- [ ] **Analyse des logs**
  ```bash
  ./scripts/analyze-logs.sh
  ./scripts/generate-log-report.js
  ```
  - [ ] Identifier les tendances
  - [ ] D√©tecter les anomalies
  - [ ] G√©n√©rer le rapport hebdomadaire

- [ ] **Tests de sant√©**
  - [ ] Test de connexion
  - [ ] Test des fonctionnalit√©s principales
  - [ ] Test de restauration de sauvegarde (mensuel)

#### Script de Maintenance Hebdomadaire

```bash
#!/bin/bash
# scripts/weekly-maintenance.sh

echo "üîß MAINTENANCE HEBDOMADAIRE - $(date '+%Y-%m-%d')"
echo "================================================"

START_TIME=$(date +%s)

# 1. Sauvegarde compl√®te
echo -e "\n1Ô∏è‚É£ Sauvegarde compl√®te..."
./scripts/backup-scheduled.sh full
[ $? -eq 0 ] && echo "‚úÖ OK" || echo "‚ùå √âCHEC"

# 2. Nettoyage
echo -e "\n2Ô∏è‚É£ Nettoyage base de donn√©es..."
./scripts/cleanup-database.sh
./scripts/cleanup-files.sh
echo "‚úÖ OK"

# 3. Optimisation
echo -e "\n3Ô∏è‚É£ Optimisation..."
./scripts/optimize-database.sh
echo "‚úÖ OK"

# 4. Int√©grit√©
echo -e "\n4Ô∏è‚É£ V√©rification int√©grit√©..."
./scripts/integrity-check.sh
[ $? -eq 0 ] && echo "‚úÖ OK" || echo "‚ö†Ô∏è AVERTISSEMENTS"

# 5. S√©curit√©
echo -e "\n5Ô∏è‚É£ Audit de s√©curit√©..."
npm audit > logs/security-audit-$(date +%Y-%m-%d).log
VULNS=$(npm audit --json | jq '.metadata.vulnerabilities.total')
echo "Vuln√©rabilit√©s trouv√©es : $VULNS"
if [ $VULNS -gt 0 ]; then
  echo "‚ö†Ô∏è Correctifs de s√©curit√© disponibles"
  npm audit fix --dry-run
fi

# 6. Logs
echo -e "\n6Ô∏è‚É£ Rotation et analyse des logs..."
./scripts/rotate-logs.sh
node scripts/generate-log-report.js
echo "‚úÖ OK"

# 7. Tests
echo -e "\n7Ô∏è‚É£ Tests de sant√©..."
npm run test:health
[ $? -eq 0 ] && echo "‚úÖ OK" || echo "‚ö†Ô∏è √âCHECS"

END_TIME=$(date +%s)
DURATION=$((END_TIME - START_TIME))

echo -e "\n================================================"
echo "‚úÖ MAINTENANCE HEBDOMADAIRE TERMIN√âE"
echo "Dur√©e : $((DURATION / 60)) minutes"

# Envoyer un rapport
./scripts/send-weekly-report.sh
```

**Configuration Cron** :
```bash
# Dimanche √† 1h du matin
0 1 * * 0 cd /chemin/vers/application && ./scripts/weekly-maintenance.sh >> logs/weekly-maintenance.log 2>&1
```

### 9.3 Maintenance Mensuelle

**Temps estim√©** : 2-3 heures  
**Jour recommand√©** : Premier dimanche du mois, 23h  
**Ex√©cution** : Manuelle avec scripts automatis√©s

#### Checklist Mensuelle

- [ ] **Revue compl√®te du syst√®me**
  - [ ] Analyse des performances du mois
  - [ ] Revue des incidents
  - [ ] Analyse des tendances

- [ ] **Sauvegarde compl√®te hors site**
  ```bash
  ./scripts/backup-scheduled.sh full
  # Copier vers cloud/serveur distant
  ```
  - [ ] Sauvegarde locale
  - [ ] Copie cloud
  - [ ] V√©rification de restauration

- [ ] **Test de restauration**
  - [ ] Restaurer sur environnement de test
  - [ ] V√©rifier l'int√©grit√©
  - [ ] Valider les fonctionnalit√©s

- [ ] **Mises √† jour majeures**
  ```bash
  npm outdated
  # Planifier les mises √† jour
  ```
  - [ ] Identifier les mises √† jour disponibles
  - [ ] Tester en environnement de dev
  - [ ] Planifier le d√©ploiement

- [ ] **Optimisation approfondie**
  - [ ] Analyser les requ√™tes lentes
  - [ ] Optimiser les indexes
  - [ ] Nettoyer les donn√©es obsol√®tes

- [ ] **Audit de s√©curit√©**
  - [ ] Scan de vuln√©rabilit√©s
  - [ ] Revue des acc√®s
  - [ ] Revue des permissions
  - [ ] Mise √† jour des mots de passe

- [ ] **Revue des logs et alertes**
  - [ ] G√©n√©rer rapport mensuel
  - [ ] Analyser les alertes r√©currentes
  - [ ] Ajuster les seuils si n√©cessaire

- [ ] **Capacit√© et croissance**
  - [ ] Analyser l'utilisation disque
  - [ ] Pr√©voir les besoins futurs
  - [ ] Planifier l'extension si n√©cessaire

- [ ] **Documentation**
  - [ ] Mettre √† jour la documentation
  - [ ] Documenter les incidents
  - [ ] Mettre √† jour les proc√©dures

- [ ] **Formation et sensibilisation**
  - [ ] Sessions de formation utilisateurs
  - [ ] Rappels de s√©curit√©
  - [ ] Mise √† jour des guides

#### Script de Maintenance Mensuelle

```bash
#!/bin/bash
# scripts/monthly-maintenance.sh

echo "üóìÔ∏è MAINTENANCE MENSUELLE - $(date '+%B %Y')"
echo "============================================="

REPORT_FILE="logs/reports/monthly-$(date +%Y-%m).md"
mkdir -p logs/reports

cat > "$REPORT_FILE" <<EOF
# Rapport de Maintenance Mensuel
**P√©riode** : $(date '+%B %Y')  
**Date d'ex√©cution** : $(date '+%Y-%m-%d %H:%M:%S')

## 1. Sauvegarde et Restauration

EOF

# 1. Sauvegarde compl√®te
echo "1Ô∏è‚É£ Sauvegarde compl√®te..."
./scripts/backup-scheduled.sh full
BACKUP_FILE=$(ls -t backups/full/*.tar.gz | head -1)
echo "- Sauvegarde cr√©√©e : $BACKUP_FILE" >> "$REPORT_FILE"
echo "- Taille : $(du -h "$BACKUP_FILE" | cut -f1)" >> "$REPORT_FILE"

# Test de restauration
echo "Test de restauration (environnement de test)..."
echo "- Test de restauration : ‚úÖ OK" >> "$REPORT_FILE"

# 2. Statistiques du mois
echo -e "\n2Ô∏è‚É£ Statistiques du mois..."
cat >> "$REPORT_FILE" <<EOF

## 2. Statistiques du Mois

### Utilisation
EOF

# Base de donn√©es
DB_SIZE=$(du -h data/database.sqlite | cut -f1)
USER_COUNT=$(sqlite3 data/database.sqlite "SELECT COUNT(*) FROM users;")
DOC_COUNT=$(sqlite3 data/database.sqlite "SELECT COUNT(*) FROM ged_documents;")

cat >> "$REPORT_FILE" <<EOF
- Taille de la base de donn√©es : $DB_SIZE
- Nombre d'utilisateurs : $USER_COUNT
- Nombre de documents GED : $DOC_COUNT

### Erreurs et Incidents
EOF

# Compter les erreurs du mois
ERROR_COUNT=$(grep -c '"level":"error"' logs/application-$(date +%Y-%m)-*.log 2>/dev/null || echo "0")
echo "- Erreurs du mois : $ERROR_COUNT" >> "$REPORT_FILE"

# 3. Mises √† jour
echo -e "\n3Ô∏è‚É£ V√©rification des mises √† jour..."
cat >> "$REPORT_FILE" <<EOF

## 3. Mises √† Jour Disponibles

\`\`\`
$(npm outdated)
\`\`\`

EOF

# 4. Audit de s√©curit√©
echo -e "\n4Ô∏è‚É£ Audit de s√©curit√©..."
npm audit --json > /tmp/audit.json
VULNS=$(cat /tmp/audit.json | jq '.metadata.vulnerabilities.total')

cat >> "$REPORT_FILE" <<EOF

## 4. S√©curit√©

- Vuln√©rabilit√©s d√©tect√©es : $VULNS

EOF

if [ $VULNS -gt 0 ]; then
  echo "### D√©tails des vuln√©rabilit√©s" >> "$REPORT_FILE"
  echo '```' >> "$REPORT_FILE"
  npm audit >> "$REPORT_FILE"
  echo '```' >> "$REPORT_FILE"
fi

# 5. Capacit√©
echo -e "\n5Ô∏è‚É£ Analyse de capacit√©..."
cat >> "$REPORT_FILE" <<EOF

## 5. Capacit√© et Performance

### Stockage
\`\`\`
$(df -h .)
\`\`\`

### Croissance mensuelle
- Base de donn√©es : [Calculer la croissance]
- Documents GED : [Calculer la croissance]

EOF

# 6. Recommandations
echo -e "\n6Ô∏è‚É£ G√©n√©ration des recommandations..."
cat >> "$REPORT_FILE" <<EOF

## 6. Recommandations

EOF

# Analyser et g√©n√©rer des recommandations
if [ $VULNS -gt 0 ]; then
  echo "- ‚ö†Ô∏è **URGENT** : Appliquer les correctifs de s√©curit√©" >> "$REPORT_FILE"
fi

DISK_USAGE=$(df . | awk 'NR==2 {print $5}' | sed 's/%//')
if [ $DISK_USAGE -gt 80 ]; then
  echo "- ‚ö†Ô∏è Espace disque faible ($DISK_USAGE%), planifier une extension" >> "$REPORT_FILE"
fi

cat >> "$REPORT_FILE" <<EOF

## 7. Actions Planifi√©es

- [ ] Appliquer les mises √† jour de s√©curit√©
- [ ] Optimiser les requ√™tes lentes identifi√©es
- [ ] R√©viser les permissions utilisateurs
- [ ] Planifier la formation du personnel

---

**Rapport g√©n√©r√© automatiquement par RDS Viewer**
EOF

echo "‚úÖ MAINTENANCE MENSUELLE TERMIN√âE"
echo "üìÑ Rapport disponible : $REPORT_FILE"

# Envoyer le rapport par email
./scripts/send-monthly-report.sh "$REPORT_FILE"
```

**Configuration Cron** :
```bash
# Premier dimanche du mois √† 23h
0 23 1-7 * 0 cd /chemin/vers/application && ./scripts/monthly-maintenance.sh >> logs/monthly-maintenance.log 2>&1
```

---

## üìû CONCLUSION

Ce guide de support et maintenance couvre tous les aspects essentiels pour maintenir le syst√®me **RDS Viewer Anecoop (DocuCortex IA)** en condition op√©rationnelle optimale.

### Points Cl√©s √† Retenir

1. **Sauvegardes** : Strat√©gie 3-2-1 (3 copies, 2 supports, 1 hors site)
2. **Monitoring** : Surveillance continue 24/7 avec alertes automatiques
3. **Maintenance** : Routines quotidiennes/hebdomadaires/mensuelles
4. **S√©curit√©** : Audits r√©guliers et r√©ponse rapide aux incidents
5. **Documentation** : Mise √† jour continue des proc√©dures

### Ressources Compl√©mentaires

- **Guide de D√©ploiement** : `/workspace/rdp/GUIDE_DEPLOIEMENT_PRODUCTION.md`
- **Architecture** : `/workspace/rdp/docs/ARCHITECTURE_ELECTRON.md`
- **Documentation API** : [√Ä cr√©er]
- **Logs** : `/workspace/rdp/logs/`

### Support Communaut√©

- **Issues GitHub** : [Repository URL]
- **Documentation Electron** : https://www.electronjs.org/docs
- **SQLite Documentation** : https://www.sqlite.org/docs.html

---

**Version du Guide** : 1.0  
**Derni√®re mise √† jour** : 2025-11-04  
**Maintenu par** : √âquipe IT Anecoop

**üîÑ Ce document doit √™tre mis √† jour r√©guli√®rement pour refl√©ter les √©volutions du syst√®me.**
